In Figure \ref{fig:percentage_distribution_concept_occurrences} we can see that, depending on the dataset, between 75\% to 90\% of all node labels occur only once per dataset.
This is also common in texts where most words also only occur once per dataset.
 
\begin{figure}[htb!]
    \centering{\includegraphics[width=\linewidth]{assets/figures/tmp/percentage_distribution_concept_occurrences.pdf}}
    \caption[Statistics: Distribution concept occurrence]{Concept map node label occurrences per dataset. $|n_v| = i$ stands for the percentage of labels with $i$ occurrences in the dataset, eg. when $|n_v| = 1$ has 50\%, it would mean that 50\% of all unique concepts only occur once per dataset.}\label{fig:percentage_distribution_concept_occurrences}
\end{figure}

In text-based approaches, infrequent words are either ignored or filtered out to reduce the vocabulary and subsequently the dimension of the feature vector
Yet, for our approach, infrequent node labels might pose a far greater problem.
As noted before, in our work, we capitalize on the Weisfeiler-Lehman graph kernel to extract useful features for subsequent classification.
In the context of WL, infrequent node labels might become a problem since a match becomes less likely with fewer occurring words, or a match even becomes impossible as in the case of node labels which occur only once.
When simply creating a feature vector by counting the node labels in each graph, infrequent node labels would not pose a problem.
WL on the other hand relies on exact matches of neighborhoods.
Thus, a node label which only occurs once would ``taint" its neighborhood, effectively making matches in its neighborhoods impossible.

In Table \ref{table:results_infrequent_nodes} we see the results of removing infrequent labels.

\begin{table}[htb!]
    \centering
    \begin{tabular}{lrrr}
\toprule
        &  \multicolumn{2}{c}{F1 macro} &  \\
         &  Plain &  Removed &  $p$-value \\
        \midrule
           ling-spam       & 0.8160 & 0.8035 & 0.3215 \\
           ng20            & *0.4188 & 0.3565 & 0.0001 \\
           nyt\_200         & 0.7436 & 0.7741 & 0.1089 \\
           r8              & *0.6772 & 0.6327 & 0.0113 \\
           review\_polarity & 0.6094 & 0.6068 & 0.9349 \\
           rotten\_imdb     & *0.6346 & 0.5514 & 0.0001 \\
           ted\_talks       & 0.2436 & *0.3637 & 0.0092 \\
        \bottomrule
    \end{tabular}
    \caption[Results: Remove infrequent node labels]{Classification results with infrequent nodes removed.}\label{table:results_infrequent_nodes}
\end{table}

As we can see, removing infrequent node labels results in a lower score for most datasets, except for the \textit{ted\_talks} corpus.

\answersummary{
	Removing infrequent node labels results in lower scores, apart on the \textit{ted\_talks} dataset.
	Interestingly, as we have seen in the answer for Question 1, when removing the infrequent labels and then combining the resulting WL features with text features, removing the infrequent labels actually resulted in the highest scores on two datasets.
	This once more shows that observations made on graph-only classification might not hold when combining the graph- with text features.
}