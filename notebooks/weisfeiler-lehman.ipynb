{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.sparse import lil_matrix, csr_matrix, vstack\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1010.,    11.],\n",
       "       [   11.,  1010.]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def WL_compute(ad_list, node_label, h, DEBUG = False):\n",
    "    # Total number of graphs in the dataset\n",
    "    n = len(ad_list)\n",
    "    \n",
    "    # Total number of nodes in dataset: initialized as zero\n",
    "    tot_nodes = 0\n",
    "\n",
    "\n",
    "    # list of kernel matrices\n",
    "    K = [0]*(h+1)\n",
    "    # list of feature mtrices\n",
    "    phi_list = [0] * (h+1)\n",
    "\n",
    "    #total number of nodes in the dataset\n",
    "    for i in range(n):\n",
    "        tot_nodes = tot_nodes + int(len(ad_list[i]))\n",
    "\n",
    "    \n",
    "    #each column of phi will be the explicit feature representation for the graph j\n",
    "    phi = lil_matrix((tot_nodes, n), dtype = np.uint32)\n",
    "\n",
    "    # labels will be used to store the new labels\n",
    "    labels = [0] * n\n",
    "\n",
    "    #label lookup is a dictionary which will contain the mapping\n",
    "    # from multiset labels (strings) to short labels (integers)\n",
    "    label_lookup = {}\n",
    "\n",
    "    # counter to create possibly new labels in the update step\n",
    "    label_counter = 0\n",
    "\n",
    "    # Note: here we are just renaming the node labels from 0,..,num_labels\n",
    "    # for each graph\n",
    "    for i in range(n):\n",
    "\n",
    "        # copy the original labels\n",
    "        l_aux = np.copy(node_label[i])\n",
    "\n",
    "        # will be used to store the new labels\n",
    "        labels[i] = np.zeros(len(l_aux), dtype = np.int32)\n",
    "\n",
    "        # for each label in graph\n",
    "        for j in range(len(l_aux)):\n",
    "            l_aux_str = str(l_aux[j])\n",
    "\n",
    "            # If the string do not already exist\n",
    "            # then create a new short label\n",
    "            if not l_aux_str in label_lookup:\n",
    "                label_lookup[l_aux_str] = label_counter\n",
    "                labels[i][j] = label_counter                                                              \n",
    "                label_counter += 1\n",
    "            else:\n",
    "                labels[i][j] = label_lookup[l_aux_str]\n",
    "\n",
    "            # node histograph of the new labels\n",
    "            phi[labels[i][j],i] += 1\n",
    "\n",
    "    L = label_counter\n",
    "    if DEBUG: print('Number of original labels %d' %L)\n",
    "\n",
    "    #####################\n",
    "    # --- Main code --- #\n",
    "    #####################\n",
    "\n",
    "    # Now we are starting with the first iteration of WL\n",
    "\n",
    "    # features obtained from the original node (renamed) labels\n",
    "    phi_list[0] = phi\n",
    "\n",
    "    # Kernel matrix based on original features\n",
    "    K[0] = phi.transpose().dot(phi).toarray().astype(np.float32)\n",
    "    \n",
    "    if DEBUG: print(\"K original is computed\")\n",
    "    \n",
    "    # Initialize iterations to 0\n",
    "    it = 0\n",
    "\n",
    "    # copy of the original labels: will stored the new labels\n",
    "    new_labels = np.copy(labels)\n",
    "    \n",
    "    # until the number of iterations is less than h\n",
    "    while it < h:\n",
    "\n",
    "        # Initialize dictionary and counter \n",
    "        # (same meaning as before)        \n",
    "        label_lookup = {}\n",
    "        label_counter = 0\n",
    "\n",
    "        # Initialize phi as a sparse matrix\n",
    "        phi = lil_matrix((tot_nodes, n), dtype = np.int32)\n",
    "        # convert it to array\n",
    "        phi = phi.toarray()\n",
    "\n",
    "        if DEBUG: print(\"Iteration %d: phi is computed\" % it)\n",
    "\n",
    "        # for each graph in the dataset\n",
    "        for i in range(n):\n",
    "\n",
    "            # will store the multilabel string\n",
    "            l_aux_long = np.copy(labels[i])\n",
    "\n",
    "            # for each node in graph\n",
    "            for v in range(len(ad_list[i])):\n",
    "\n",
    "                # the new labels convert to tuple\n",
    "                new_node_label = tuple([l_aux_long[v]]) \n",
    "\n",
    "                # form a multiset label of the node neighbors \n",
    "                new_ad = np.zeros(len(ad_list[i][v]))\n",
    "                for j in range(len(ad_list[i][v])):\n",
    "                    new_ad[j] = ad_list[i][v][j]\n",
    "\n",
    "                ad_aux = tuple([l_aux_long[int(j)] for j in new_ad])\n",
    "\n",
    "                # long labels: original node plus sorted neughbors\n",
    "                long_label = tuple(tuple(new_node_label)+tuple(sorted(ad_aux)))\n",
    "            \n",
    "                # if the multiset label has not yet occurred , add\n",
    "                # it to the lookup table and assign a number to it\n",
    "                if not long_label in label_lookup:\n",
    "                    label_lookup[long_label] = str(label_counter)\n",
    "                    new_labels[i][v] = str(label_counter)\n",
    "                    label_counter += 1\n",
    "\n",
    "                # else assign it the already existing number\n",
    "                else:\n",
    "                    new_labels[i][v] = label_lookup[long_label]\n",
    "\n",
    "            # count the node label frequencies\n",
    "            aux = np.bincount(new_labels[i]) \n",
    "            phi[new_labels[i],i] += aux[new_labels[i]]\n",
    "        \n",
    "        L = label_counter\n",
    "        if DEBUG: print('Number of compressed labels %d' %L)\n",
    "\n",
    "        # create phi for iteration it+1\n",
    "        phi_sparse = lil_matrix(phi)\n",
    "        phi_list[it+1] = phi_sparse\n",
    "\n",
    "        if DEBUG: print(\"Itaration %d: phi sparse saved\" % it)\n",
    "\n",
    "        # create K at iteration it+1\n",
    "        K[it+1] = K[it] + phi_sparse.transpose().dot(phi_sparse).toarray().astype(np.float32)\n",
    "        \n",
    "        if DEBUG: print(\"Iteration %d: K is computed\" % it)\n",
    "\n",
    "        # Initialize labels for the next iteration as the new just computed\n",
    "        labels = copy.deepcopy(new_labels)\n",
    "\n",
    "        # increment the iteration\n",
    "        it = it + 1 \n",
    "\n",
    "    return K, phi_list\n",
    "\n",
    "adjs, nodes = [], []\n",
    "for i in range(2):\n",
    "    g =  nx.erdos_renyi_graph(10, 0.5)\n",
    "    adjs.append(nx.adjacency_matrix(g).toarray())\n",
    "    nodes.append(g.nodes())\n",
    "    \n",
    "\n",
    "#adjs[-1][0][1] = adjs[-1][1][0] = 1\n",
    "    \n",
    "K, phi_list = WL_compute(adjs, nodes, 100)\n",
    "#print(phi_list[-1].todense())\n",
    "K[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-7-651ac810ad41>\u001b[0m(113)\u001b[0;36m<listcomp>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    111 \u001b[0;31m                    \u001b[0mnew_ad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mad_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    112 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 113 \u001b[0;31m                \u001b[0mad_aux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml_aux_long\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_ad\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    114 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    115 \u001b[0;31m                \u001b[0;31m# long labels: original node plus sorted neughbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> l_aux_long\n",
      "array([0, 1, 2, 3, 4], dtype=int32)\n",
      "ipdb> new_ad\n",
      "*** NameError: name 'new_ad' is not defined\n",
      "ipdb> new_ad\n",
      "*** NameError: name 'new_ad' is not defined\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
