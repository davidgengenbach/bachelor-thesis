{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import helper\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import w2v_d2v\n",
    "import dataset_helper\n",
    "import preprocessing\n",
    "import classifier_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== ling-spam      #docs 2893\n",
      "Currently training classifier: PassiveAggressiveClassifier    (5/5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidgengenbach/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MostFrequentLabel</th>\n",
       "      <td>0.454802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.924161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.975232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.993704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveClassifier</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 test\n",
       "MostFrequentLabel            0.454802\n",
       "LogisticRegression           0.924161\n",
       "Perceptron                   0.975232\n",
       "SGDClassifier                0.993704\n",
       "PassiveAggressiveClassifier  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clfs = classifier_baseline.get_classifiers(iterations=5)\n",
    "\n",
    "def allowed_dataset(dataset_name):\n",
    "    return dataset_name == 'ling-spam'\n",
    "\n",
    "#clfs = {clf_name: clf for clf_name, clf in clfs.items() if clf_name == 'Doc2VecClassifier'}\n",
    "for dataset_name, (X, Y) in datasets.items():\n",
    "    if not allowed_dataset(dataset_name): continue\n",
    "    #if not dataset_name.startswith('web'): continue\n",
    "    print('{} {:<14} #docs {}'.format('=' * 30, dataset_name, len(X)))\n",
    "    data_train_X, data_test_X, data_train_Y, data_test_Y = dataset_helper.split_dataset(X, Y)\n",
    "    vectors_trans_train, vectors_trans_test = classifier_baseline.vectorize_text(data_train_X, data_test_X)\n",
    "    pred_results = classifier_baseline.get_predictions_for_classifiers(vectors_trans_train, vectors_trans_test, data_train_Y, data_test_Y, data_train_X, data_test_X, clfs = clfs)\n",
    "    results = classifier_baseline.get_f1_score_for_clfs(pred_results, data_train_Y, data_test_Y)\n",
    "    display(pd.DataFrame(results).T.test.to_frame().sort_values('test'))\n",
    "    #print('{}>    Best for dataset: {} is classifier: {} with F1-score of {}'.format('=' * 10, dataset_name, best_clf, best_clf_score['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV] clf__class_weight=balanced, clf__n_iter=100, preprocessing=None, count_vectorizer__stop_words=english \n",
      "[CV]  clf__class_weight=balanced, clf__n_iter=100, preprocessing=None, count_vectorizer__stop_words=english, score=0.994423, total=   2.0s\n",
      "[CV] clf__class_weight=balanced, clf__n_iter=100, preprocessing=None, count_vectorizer__stop_words=english \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=balanced, clf__n_iter=100, preprocessing=None, count_vectorizer__stop_words=english, score=0.986651, total=   2.0s\n",
      "[CV] clf__class_weight=balanced, clf__n_iter=100, preprocessing=None, count_vectorizer__stop_words=english \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=balanced, clf__n_iter=100, preprocessing=None, count_vectorizer__stop_words=english, score=0.992543, total=   1.9s\n",
      "[CV] clf__class_weight=balanced, clf__n_iter=100, preprocessing=PreProcessingTransformer(only_nouns=True, return_text=True), count_vectorizer__stop_words=english \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    9.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=balanced, clf__n_iter=100, preprocessing=PreProcessingTransformer(only_nouns=True, return_text=True), count_vectorizer__stop_words=english, score=0.979550, total=  21.1s\n",
      "[CV] clf__class_weight=balanced, clf__n_iter=100, preprocessing=PreProcessingTransformer(only_nouns=True, return_text=True), count_vectorizer__stop_words=english \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   43.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=balanced, clf__n_iter=100, preprocessing=PreProcessingTransformer(only_nouns=True, return_text=True), count_vectorizer__stop_words=english, score=0.975080, total=  19.4s\n",
      "[CV] clf__class_weight=balanced, clf__n_iter=100, preprocessing=PreProcessingTransformer(only_nouns=True, return_text=True), count_vectorizer__stop_words=english \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__class_weight=balanced, clf__n_iter=100, preprocessing=PreProcessingTransformer(only_nouns=True, return_text=True), count_vectorizer__stop_words=english, score=0.987047, total=  20.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('preprocessing', None), ('count_vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor... n_iter=100, n_jobs=1,\n",
      "              random_state=None, shuffle=True, verbose=0, warm_start=False))]) {'split0_train_score': array([ 1.,  1.]), 'param_count_vectorizer__stop_words': masked_array(data = ['english' 'english'],\n",
      "             mask = [False False],\n",
      "       fill_value = ?)\n",
      ", 'split1_test_score': array([ 0.98665071,  0.97507989]), 'split1_train_score': array([ 1.,  1.]), 'split2_test_score': array([ 0.99254349,  0.98704736]), 'param_preprocessing': masked_array(data = [None PreProcessingTransformer(only_nouns=True, return_text=True)],\n",
      "             mask = [False False],\n",
      "       fill_value = ?)\n",
      ", 'mean_score_time': array([ 0.55083807,  6.86513535]), 'rank_test_score': array([1, 2], dtype=int32), 'split2_train_score': array([ 1.,  1.]), 'std_fit_time': array([ 0.00937125,  0.68892533]), 'std_test_score': array([ 0.00331087,  0.00493674]), 'param_clf__n_iter': masked_array(data = [100 100],\n",
      "             mask = [False False],\n",
      "       fill_value = ?)\n",
      ", 'mean_fit_time': array([  1.38727021,  13.57631771]), 'mean_test_score': array([ 0.99120672,  0.9805586 ]), 'mean_train_score': array([ 1.,  1.]), 'std_train_score': array([ 0.,  0.]), 'param_clf__class_weight': masked_array(data = ['balanced' 'balanced'],\n",
      "             mask = [False False],\n",
      "       fill_value = ?)\n",
      ", 'params': ({'clf__class_weight': 'balanced', 'clf__n_iter': 100, 'preprocessing': None, 'count_vectorizer__stop_words': 'english'}, {'clf__class_weight': 'balanced', 'clf__n_iter': 100, 'preprocessing': PreProcessingTransformer(only_nouns=True, return_text=True), 'count_vectorizer__stop_words': 'english'}), 'split0_test_score': array([ 0.99442262,  0.97954961]), 'std_score_time': array([ 0.01332306,  0.05646586])}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from transformers.wl_graph_kernel_transformer import WLGraphKernelTransformer\n",
    "from transformers.preprocessing_transformer import PreProcessingTransformer\n",
    "import graph_helper\n",
    "import dataset_helper\n",
    "import wl\n",
    "import os\n",
    "\n",
    "for dataset_name in dataset_helper.get_all_available_dataset_names():\n",
    "    if dataset_name != 'ling-spam': continue\n",
    "        \n",
    "    X, Y = dataset_helper.get_dataset(dataset_name, use_cached= True)\n",
    "    \n",
    "    p = Pipeline([\n",
    "        ('preprocessing', None),\n",
    "        ('count_vectorizer', sklearn.feature_extraction.text.CountVectorizer()),\n",
    "        ('TfidfTransformer', sklearn.feature_extraction.text.TfidfTransformer()),\n",
    "        ('clf', sklearn.linear_model.PassiveAggressiveClassifier())\n",
    "    ])\n",
    "    \n",
    "    param_grid = dict(\n",
    "        preprocessing = [None, PreProcessingTransformer(only_nouns = True)],\n",
    "        count_vectorizer__stop_words = ['english'],\n",
    "        clf__n_iter = [100],\n",
    "        clf__class_weight = ['balanced']\n",
    "    )\n",
    "\n",
    "    cv = sklearn.model_selection.StratifiedKFold(n_splits = 3, random_state= 42, shuffle= True)\n",
    "    gscv = GridSearchCV(estimator = p, param_grid=param_grid, cv=cv, scoring = 'f1_macro', n_jobs=1, verbose = 11)\n",
    "    gscv_result = gscv.fit(X, Y)\n",
    "    print(gscv_result.best_estimator_, gscv_result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_clf__class_weight</th>\n",
       "      <th>param_clf__n_iter</th>\n",
       "      <th>param_count_vectorizer__stop_words</th>\n",
       "      <th>param_preprocessing</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.387270</td>\n",
       "      <td>0.550838</td>\n",
       "      <td>0.991207</td>\n",
       "      <td>1.0</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>english</td>\n",
       "      <td>None</td>\n",
       "      <td>{'clf__class_weight': 'balanced', 'clf__n_iter...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994423</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.992543</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>0.013323</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.576318</td>\n",
       "      <td>6.865135</td>\n",
       "      <td>0.980559</td>\n",
       "      <td>1.0</td>\n",
       "      <td>balanced</td>\n",
       "      <td>100</td>\n",
       "      <td>english</td>\n",
       "      <td>PreProcessingTransformer(only_nouns=True, retu...</td>\n",
       "      <td>{'clf__class_weight': 'balanced', 'clf__n_iter...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.979550</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.975080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.987047</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.688925</td>\n",
       "      <td>0.056466</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       1.387270         0.550838         0.991207               1.0   \n",
       "1      13.576318         6.865135         0.980559               1.0   \n",
       "\n",
       "  param_clf__class_weight param_clf__n_iter  \\\n",
       "0                balanced               100   \n",
       "1                balanced               100   \n",
       "\n",
       "  param_count_vectorizer__stop_words  \\\n",
       "0                            english   \n",
       "1                            english   \n",
       "\n",
       "                                 param_preprocessing  \\\n",
       "0                                               None   \n",
       "1  PreProcessingTransformer(only_nouns=True, retu...   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0  {'clf__class_weight': 'balanced', 'clf__n_iter...                1   \n",
       "1  {'clf__class_weight': 'balanced', 'clf__n_iter...                2   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.994423                 1.0           0.986651   \n",
       "1           0.979550                 1.0           0.975080   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0                 1.0           0.992543                 1.0      0.009371   \n",
       "1                 1.0           0.987047                 1.0      0.688925   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.013323        0.003311              0.0  \n",
       "1        0.056466        0.004937              0.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(gscv_result.cv_results_)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Doc2Vec and Word2Vec classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process docs for d2v and w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_data_train = [w2v_d2v.w2v_preproess(doc) for doc in data_train_X]\n",
    "w2v_data_test = [w2v_d2v.w2v_preproess(doc) for doc in data_test_X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_d2v = w2v_d2v.train_d2v(w2v_data_train, data_train_Y, iterations = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred train vectors\n",
      "Inferred test vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidgengenbach/anaconda3/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scores = w2v_d2v.score_d2v(clfs, data_train_Y, data_test_Y, model_d2v, w2v_data_train, w2v_data_test, steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': {'test': 0.43375480433862312,\n",
       "  'train': 0.46532463660461809},\n",
       " 'MostFrequentLabel': {'test': 0.0046355498721227621,\n",
       "  'train': 0.0045970578829549087},\n",
       " 'PassiveAggressiveClassifier': {'test': 0.26940955676406886,\n",
       "  'train': 0.30912823359685837},\n",
       " 'Perceptron': {'test': 0.006102700076132176, 'train': 0.010673521739491008},\n",
       " 'SGDClassifier': {'test': 0.35247761491407559, 'train': 0.38979592547038749}}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "251px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
