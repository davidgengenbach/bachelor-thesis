{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "EXPORT_DPI = 100\n",
    "EXPORT_FIG_SIZE = (8, 4)\n",
    "EXPORT_FIG_SIZE_BIG = (10, 7)\n",
    "EXPORT_FIG_WIDTH, EXPORT_FIG_HEIGHT = EXPORT_FIG_SIZE\n",
    "EXPORT_FIG_WIDTH_BIG, EXPORT_FIG_HEIGHT_BIG = EXPORT_FIG_SIZE_BIG\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = 80\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = -1\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set('notebook', 'whitegrid', palette = 'deep')\n",
    "plt.rcParams['figure.figsize'] = EXPORT_FIG_SIZE_BIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import graph_helper, dataset_helper\n",
    "import networkx as nx\n",
    "from transformers import fast_wl_pipeline, text_pipeline\n",
    "from transformers.tuple_selector import TupleSelector\n",
    "import sklearn\n",
    "from sklearn import pipeline\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_classifier():\n",
    "    graph_fast_wl_grid_params = {\n",
    "        'fast_wl__h': [1],\n",
    "        'fast_wl__phi_dim': [None],\n",
    "        'fast_wl__round_to_decimals': [10],\n",
    "        'phi_picker__return_iteration': ['stacked'],\n",
    "        'phi_picker__use_zeroth': [False]\n",
    "    }\n",
    "\n",
    "    grid_params_combined = dict({\n",
    "        'classifier': []\n",
    "    }, **dict({'features__fast_wl_pipeline__feature_extraction__' + k: val for k, val in\n",
    "               graph_fast_wl_grid_params.items()}, **dict(\n",
    "        features__fast_wl_pipeline__feature_extraction__fast_wl__phi_dim=[]\n",
    "    )))\n",
    "\n",
    "    combined_features = sklearn.pipeline.FeatureUnion([\n",
    "        ('tfidf', sklearn.pipeline.Pipeline([\n",
    "            ('selector', TupleSelector(tuple_index=1)),\n",
    "            ('tfidf', text_pipeline.get_pipeline()),\n",
    "        ])),\n",
    "        ('fast_wl_pipeline', sklearn.pipeline.Pipeline([\n",
    "            ('selector', TupleSelector(tuple_index=0, v_stack=False)),\n",
    "            ('feature_extraction', fast_wl_pipeline.get_pipeline()),\n",
    "            ('scaler', sklearn.preprocessing.MaxAbsScaler())\n",
    "        ]))\n",
    "    ], transformer_weights = dict(\n",
    "        tfidf=1,\n",
    "        fast_wl_pipeline=1\n",
    "    ))\n",
    "\n",
    "    pipeline = sklearn.pipeline.Pipeline([\n",
    "        ('features', combined_features),\n",
    "        ('classifier', None)\n",
    "    ])\n",
    "    \n",
    "    return pipeline, grid_params_combined\n",
    "\n",
    "cv = sklearn.model_selection.StratifiedKFold(\n",
    "    n_splits=3,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "for graph_cache_file in dataset_helper.get_all_cached_graph_datasets('ng20'):\n",
    "    if 'concept' not in graph_cache_file or 'v2' not in graph_cache_file: continue\n",
    "    print(graph_cache_file)\n",
    "    X_combined, Y_combined = graph_helper.get_filtered_text_graph_dataset(graph_cache_file)\n",
    "\n",
    "    graphs = [g for (g, _, _) in X_combined]\n",
    "    empty_graphs = len([1 for g in graphs if nx.number_of_nodes(g) == 0 or nx.number_of_edges(g) == 0])\n",
    "    num_vertices = sum([nx.number_of_nodes(g) for g in graphs]) + empty_graphs\n",
    "    fast_wl_pipeline.convert_graphs_to_tuples(graphs)\n",
    "    X_combined = [(graph, text) for (graph, text, _) in X_combined]\n",
    "    \n",
    "    clfs, params = get_classifier()\n",
    "    #clf = sklearn.linear_model.PassiveAggressiveClassifier(class_weight = 'balanced', max_iter = 10000, verbose = 1, tol = 1e-6)\n",
    "    clf = sklearn.svm.LinearSVC(class_weight = 'balanced', max_iter = 10000, verbose = 1, tol = 1e-6)\n",
    "    params['classifier'] = [clf]\n",
    "    params['features__fast_wl_pipeline__feature_extraction__fast_wl__phi_dim'] = [num_vertices]\n",
    "    grid = sklearn.model_selection.ParameterGrid(params)\n",
    "    for params_ in grid:\n",
    "        print('Fitting: {}'.format(params))\n",
    "        clfs.set_params(**params_)\n",
    "\n",
    "    scores = []\n",
    "    for train, test in cv.split(X_combined, Y_combined):\n",
    "        X_train, Y_train, X_test, Y_test = np.array(X_combined)[train], np.array(Y_combined)[train], np.array(X_combined)[test], np.array(Y_combined)[test]\n",
    "        \n",
    "        clfs.fit(X_train, Y_train)\n",
    "        clf_ = clfs.named_steps['classifier']\n",
    "        \n",
    "        Y_pred = clfs.predict(X_test)\n",
    "        f1 = sklearn.metrics.f1_score(y_true= Y_test, y_pred=Y_pred, average = 'macro')\n",
    "        scores.append(f1)\n",
    "        print(f1)\n",
    "        coefs = clf_.coef_\n",
    "    print('mean', np.array(scores).mean())\n",
    "    num_text_features = len(clfs.named_steps['features'].transformer_list[0][1].named_steps['tfidf'].named_steps['TfidfTransformer'].vocabulary_.keys())\n",
    "    num_graph_features = coefs.shape[1] - num_text_features\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_coefficients(classifier, feature_names, top_features=20):\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "\n",
    "    sorted_coefs_graphs = np.argsort(coef[num_text_features:])\n",
    "    top_positive_graph_coefs = sorted_coefs_graphs[-top_features:]\n",
    "    top_negative_graph_coefs = sorted_coefs_graphs[:top_features]\n",
    "    top_graph_coefs = np.hstack([top_negative_graph_coefs, top_positive_graph_coefs])\n",
    "    # create plot\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    colors = ['r' if c < 0 else 'b' for c in coef[top_coefficients]]\n",
    "    plt.bar(np.arange(2 * top_features), coef[top_graph_coefs + num_text_features], color=colors)\n",
    "    plt.title('Graph features')\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "    plt.title('All features')\n",
    "    #plt.xticks(top_coefficients, rotation=60, ha='right')\n",
    "    if feature_names is not None:\n",
    "        feature_names = np.array(feature_names)\n",
    "        plt.xticks(np.arange(0, 2 * top_features), [feature_names[x] if x < len(feature_names) else '..' for x in top_coefficients], rotation=60, ha='right')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print('#text features: {}, #graph features: {}'.format(num_text_features, num_graph_features))\n",
    "    \n",
    "coefs = clf_.coef_.ravel()\n",
    "text_features = coefs[:num_text_features]\n",
    "graph_features = coefs[num_text_features:]\n",
    "tfidf_transformer = clfs.named_steps['features'].transformer_list[0][1].named_steps['tfidf'].named_steps['TfidfTransformer']\n",
    "fast_wl_transformer = clfs.named_steps['features'].transformer_list[0]\n",
    "text_feature_names = tfidf_transformer.get_feature_names()\n",
    "\n",
    "plot_coefficients(clf_, text_feature_names, top_features=50)\n",
    "#clfs.named_steps['features'].transformer_list[1][1].named_steps['feature_extraction'].named_steps['phi_picker'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'coefs': coefs})\n",
    "df_graphs = df[df.index >= num_text_features]\n",
    "df_texts = df[df.index < num_text_features]\n",
    "df['type'] = df.index.map(lambda x: 'text' if x < num_text_features else 'graph')\n",
    "fig, ax = plt.subplots()\n",
    "for type_, df_ in df.groupby('type'):\n",
    "    df_.coefs.plot(kind = 'hist', logy = True, bins = 100, ax = ax, label = type_, alpha = 0.8)\n",
    "ax.legend()\n",
    "#df_graphs.plot(kind = 'hist', logy = True, bins = 100)\n",
    "#df_texts.plot(kind = 'hist', logy = True, bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type_, df_ in df.groupby('type'):\n",
    "    pos_sum = df_[df_.coefs > 0].coefs.sum() / len(df_[df_.coefs > 0])\n",
    "    neg_sum = df_[df_.coefs <= 0].coefs.sum() / len(df_[df_.coefs <= 0])\n",
    "    print(type_,'\\t', pos_sum, neg_sum)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
