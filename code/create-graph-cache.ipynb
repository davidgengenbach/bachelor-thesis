{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### dataset_graph_cooccurrence_1_no-nouns_cade-ana.npy\n",
      "#################### dataset_graph_cooccurrence_1_no-nouns_ling-spam.npy\n",
      "\tAlready calculated phi: data/CACHE/dataset_graph_cooccurrence_1_no-nouns_ling-spam.phi.npy\n",
      "#################### dataset_graph_cooccurrence_1_no-nouns_mini20-ana.npy\n",
      "\tAlready calculated phi: data/CACHE/dataset_graph_cooccurrence_1_no-nouns_mini20-ana.phi.npy\n",
      "#################### dataset_graph_cooccurrence_1_no-nouns_ng20-ana.npy\n",
      "\tAlready calculated phi: data/CACHE/dataset_graph_cooccurrence_1_no-nouns_ng20-ana.phi.npy\n",
      "#################### dataset_graph_cooccurrence_1_no-nouns_ng20.npy\n",
      "\tAlready calculated phi: data/CACHE/dataset_graph_cooccurrence_1_no-nouns_ng20.phi.npy\n",
      "#################### dataset_graph_cooccurrence_1_no-nouns_r52-ana.npy\n",
      "\tAlready calculated phi: data/CACHE/dataset_graph_cooccurrence_1_no-nouns_r52-ana.phi.npy\n",
      "#################### dataset_graph_cooccurrence_1_no-nouns_r8-ana.npy\n",
      "\tAlready calculated phi: data/CACHE/dataset_graph_cooccurrence_1_no-nouns_r8-ana.phi.npy\n",
      "#################### dataset_graph_cooccurrence_1_no-nouns_r8.npy\n",
      "\tAlready calculated phi: data/CACHE/dataset_graph_cooccurrence_1_no-nouns_r8.phi.npy\n",
      "#################### dataset_graph_cooccurrence_1_no-nouns_reuters-21578.npy\n",
      "\tAlready calculated phi: data/CACHE/dataset_graph_cooccurrence_1_no-nouns_reuters-21578.phi.npy\n",
      "#################### dataset_graph_cooccurrence_1_no-nouns_webkb-ana.npy\n",
      "\tAlready calculated phi: data/CACHE/dataset_graph_cooccurrence_1_no-nouns_webkb-ana.phi.npy\n",
      "#################### dataset_graph_cooccurrence_1_no-nouns_webkb.npy\n",
      "\tAlready calculated phi: data/CACHE/dataset_graph_cooccurrence_1_no-nouns_webkb.phi.npy\n",
      "#################### dataset_graph_cooccurrence_1_with-nouns_cade-ana.npy\n",
      "#################### dataset_graph_cooccurrence_1_with-nouns_ling-spam.npy\n",
      "\tAlready calculated phi: data/CACHE/dataset_graph_cooccurrence_1_with-nouns_ling-spam.phi.npy\n",
      "#################### dataset_graph_cooccurrence_1_with-nouns_mini20-ana.npy\n",
      "\tAlready calculated phi: data/CACHE/dataset_graph_cooccurrence_1_with-nouns_mini20-ana.phi.npy\n",
      "#################### dataset_graph_cooccurrence_1_with-nouns_ng20-ana.npy\n",
      "\tAlready calculated phi: data/CACHE/dataset_graph_cooccurrence_1_with-nouns_ng20-ana.phi.npy\n",
      "#################### dataset_graph_cooccurrence_1_with-nouns_ng20.npy\n",
      "\tAlready calculated phi: data/CACHE/dataset_graph_cooccurrence_1_with-nouns_ng20.phi.npy\n",
      "#################### dataset_graph_cooccurrence_1_with-nouns_r52-ana.npy\n",
      "WLGraphKernelTransformer.fit: len(X)=9100, H=1\n",
      "WLGraphKernelTransformer.fit: Found empty graphs in training set: 0\n",
      "Number of original labels 25941\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 25941\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 25941\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 25941\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 25941\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 25941\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 25941\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/100\n",
      "\tGraph         50/100\n",
      "#################### dataset_graph_cooccurrence_1_with-nouns_r8-ana.npy\n",
      "WLGraphKernelTransformer.fit: len(X)=7674, H=1\n",
      "WLGraphKernelTransformer.fit: Found empty graphs in training set: 0\n",
      "Number of original labels 23261\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 23261\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 23261\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 23261\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 23261\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 23261\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/174\n",
      "\tGraph         87/174\n",
      "#################### dataset_graph_cooccurrence_1_with-nouns_r8.npy\n",
      "WLGraphKernelTransformer.fit: len(X)=6333, H=1\n",
      "WLGraphKernelTransformer.fit: Found empty graphs in training set: 0\n",
      "Number of original labels 41036\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 41036\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 41036\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 41036\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 41036\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/333\n",
      "\tGraph        166/333\n",
      "\tGraph        332/333\n",
      "#################### dataset_graph_cooccurrence_1_with-nouns_reuters-21578.npy\n",
      "WLGraphKernelTransformer.fit: len(X)=13328, H=1\n",
      "WLGraphKernelTransformer.fit: Found empty graphs in training set: 0\n",
      "Number of original labels 60625\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 60625\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 60625\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 60625\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 60625\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n",
      "Number of original labels 60625\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "\tGraph          0/1500\n",
      "\tGraph        750/1500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-243b79287146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"import os\\nimport dataset_helper\\nimport graph_helper\\nimport gc\\nimport pickle\\nfrom transformers.wl_graph_kernel_transformer import WLGraphKernelTransformer\\n\\ngc.collect()\\nfor graph_cache_file in dataset_helper.get_all_cached_graph_datasets():\\n    phi_graph_cache_file = graph_cache_file.replace('.npy', '.phi.npy')\\n    print('{} {}'.format('#' * 20, graph_cache_file.split('/')[-1]))\\n    if os.path.exists(phi_graph_cache_file):\\n        print('\\\\tAlready calculated phi: {}'.format(phi_graph_cache_file))\\n        continue\\n    if 'cade' in graph_cache_file or '.phi.' in graph_cache_file: continue\\n    X, Y = dataset_helper.get_dataset_cached(graph_cache_file)\\n    transformer = WLGraphKernelTransformer(H=1, remove_missing_labels=True, n_jobs = 1)\\n    transformer.fit(X)\\n    \\n    with open(phi_graph_cache_file, 'wb') as f:\\n        pickle.dump((transformer.phi_list.T, Y), f)\\n    \\n    del X, Y, transformer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/davidgengenbach/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/davidgengenbach/anaconda3/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidgengenbach/anaconda3/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1185\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/davidgengenbach/Documents/Projekte/bachelor-thesis/code/transformers/wl_graph_kernel_transformer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# TODO: do this in batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         phi_list, label_lookups, label_counters = wl.WL_compute_batched(\n\u001b[0;32m---> 55\u001b[0;31m             adjs = ad_list, node_label = node_label, h = self.H, all_nodes=self.all_nodes, compute_k=False, DEBUG=True)\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidgengenbach/Documents/Projekte/bachelor-thesis/code/wl.py\u001b[0m in \u001b[0;36mWL_compute_batched\u001b[0;34m(adjs, node_label, all_nodes, h, initial_label_counters, initial_label_lookups, phi_dim, batch_size, keep_phi_history, gc_after_each, **wl_params)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_elements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_label_lookups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_label_counters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWL_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_label_counters\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcurrent_label_counters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_label_lookups\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcurrent_label_lookups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_phi_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeep_phi_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mwl_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mphi_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mphi_lists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidgengenbach/Documents/Projekte/bachelor-thesis/code/wl.py\u001b[0m in \u001b[0;36mWL_compute\u001b[0;34m(ad_list, node_label, h, all_nodes, compute_k, initial_label_lookups, initial_label_counters, phi_dim, keep_phi_history, DEBUG)\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;31m# the new labels convert to tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0mlong_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml_aux_long\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mad_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                     \u001b[0mlong_label\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml_aux_long\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidgengenbach/anaconda3/lib/python3.5/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;31m# [i, 1:2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_row_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0;31m# [i, [1, 2]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0missequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidgengenbach/anaconda3/lib/python3.5/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m_get_row_slice\u001b[0;34m(self, i, cslice)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0;31m# for stride == 1, _get_submatrix is ~30% faster than below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mrow_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_submatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davidgengenbach/anaconda3/lib/python3.5/site-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m_get_submatrix\u001b[0;34m(self, row_slice, col_slice)\u001b[0m\n\u001b[1;32m    450\u001b[0m         indptr, indices, data = get_csr_submatrix(M, N,\n\u001b[1;32m    451\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m                 int(i0), int(i1), int(j0), int(j1))\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mj0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import dataset_helper\n",
    "import graph_helper\n",
    "import gc\n",
    "import pickle\n",
    "from transformers.wl_graph_kernel_transformer import WLGraphKernelTransformer\n",
    "\n",
    "gc.collect()\n",
    "for graph_cache_file in dataset_helper.get_all_cached_graph_datasets():\n",
    "    phi_graph_cache_file = graph_cache_file.replace('.npy', '.phi.npy')\n",
    "    print('{} {}'.format('#' * 20, graph_cache_file.split('/')[-1]))\n",
    "    if os.path.exists(phi_graph_cache_file):\n",
    "        print('\\tAlready calculated phi: {}'.format(phi_graph_cache_file))\n",
    "        continue\n",
    "    if 'cade' in graph_cache_file or '.phi.' in graph_cache_file: continue\n",
    "    X, Y = dataset_helper.get_dataset_cached(graph_cache_file)\n",
    "    transformer = WLGraphKernelTransformer(H=1, remove_missing_labels=True, n_jobs = 1)\n",
    "    transformer.fit(X)\n",
    "    \n",
    "    with open(phi_graph_cache_file, 'wb') as f:\n",
    "        pickle.dump((transformer.phi_list.T, Y), f)\n",
    "    \n",
    "    del X, Y, transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV] clf__n_iter=100, clf__class_weight=balanced .....................\n",
      "[CV]  clf__n_iter=100, clf__class_weight=balanced, score=0.808247, total=   0.2s\n",
      "[CV] clf__n_iter=100, clf__class_weight=balanced .....................\n",
      "[CV]  clf__n_iter=100, clf__class_weight=balanced, score=0.772770, total=   0.2s\n",
      "[CV] clf__n_iter=100, clf__class_weight=balanced .....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__n_iter=100, clf__class_weight=balanced, score=0.818619, total=   0.2s\n",
      "[CV] clf__n_iter=100, clf__class_weight=balanced .....................\n",
      "[CV]  clf__n_iter=100, clf__class_weight=balanced, score=0.824145, total=   0.2s\n",
      "[CV] clf__n_iter=100, clf__class_weight=balanced .....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__n_iter=100, clf__class_weight=balanced, score=0.754364, total=   0.2s\n",
      "[CV] clf__n_iter=100, clf__class_weight=balanced .....................\n",
      "[CV]  clf__n_iter=100, clf__class_weight=balanced, score=0.776275, total=   0.2s\n",
      "[CV] clf__n_iter=100, clf__class_weight=balanced .....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__n_iter=100, clf__class_weight=balanced, score=0.872099, total=   0.2s\n",
      "[CV] clf__n_iter=100, clf__class_weight=balanced .....................\n",
      "[CV]  clf__n_iter=100, clf__class_weight=balanced, score=0.753803, total=   0.2s\n",
      "[CV] clf__n_iter=100, clf__class_weight=balanced .....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    1.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    1.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__n_iter=100, clf__class_weight=balanced, score=0.729986, total=   0.2s\n",
      "[CV] clf__n_iter=100, clf__class_weight=balanced .....................\n",
      "[CV]  clf__n_iter=100, clf__class_weight=balanced, score=0.800000, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 0.18243082]),\n",
       " 'mean_score_time': array([ 0.0014642]),\n",
       " 'mean_test_score': array([ 0.79103652]),\n",
       " 'mean_train_score': array([ 1.]),\n",
       " 'param_clf__class_weight': masked_array(data = ['balanced'],\n",
       "              mask = [False],\n",
       "        fill_value = ?),\n",
       " 'param_clf__n_iter': masked_array(data = [100],\n",
       "              mask = [False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'clf__class_weight': 'balanced', 'clf__n_iter': 100},),\n",
       " 'rank_test_score': array([1], dtype=int32),\n",
       " 'split0_test_score': array([ 0.80824742]),\n",
       " 'split0_train_score': array([ 1.]),\n",
       " 'split1_test_score': array([ 0.77277026]),\n",
       " 'split1_train_score': array([ 1.]),\n",
       " 'split2_test_score': array([ 0.81861925]),\n",
       " 'split2_train_score': array([ 1.]),\n",
       " 'split3_test_score': array([ 0.82414507]),\n",
       " 'split3_train_score': array([ 1.]),\n",
       " 'split4_test_score': array([ 0.75436417]),\n",
       " 'split4_train_score': array([ 1.]),\n",
       " 'split5_test_score': array([ 0.77627505]),\n",
       " 'split5_train_score': array([ 1.]),\n",
       " 'split6_test_score': array([ 0.87209874]),\n",
       " 'split6_train_score': array([ 1.]),\n",
       " 'split7_test_score': array([ 0.75380309]),\n",
       " 'split7_train_score': array([ 1.]),\n",
       " 'split8_test_score': array([ 0.72998623]),\n",
       " 'split8_train_score': array([ 1.]),\n",
       " 'split9_test_score': array([ 0.8]),\n",
       " 'split9_train_score': array([ 1.]),\n",
       " 'std_fit_time': array([ 0.00483404]),\n",
       " 'std_score_time': array([ 0.00019245]),\n",
       " 'std_test_score': array([ 0.03975086]),\n",
       " 'std_train_score': array([ 0.])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from transformers.wl_graph_kernel_transformer import WLGraphKernelTransformer\n",
    "import graph_helper\n",
    "import dataset_helper\n",
    "import wl\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "X, Y = dataset_helper.get_dataset_cached(dataset_helper.CACHE_PATH + '/dataset_graph_cooccurrence_1_no-nouns_ling-spam.phi.npy')\n",
    "\n",
    "p = Pipeline([\n",
    "    ('clf', sklearn.linear_model.PassiveAggressiveClassifier())\n",
    "])\n",
    "\n",
    "param_grid = dict(\n",
    "    clf__n_iter=[100],\n",
    "    clf__class_weight = ['balanced']\n",
    ")\n",
    "\n",
    "cv = GridSearchCV(estimator = p, param_grid=param_grid, cv=10, scoring = 'f1_macro', n_jobs=1, verbose = 11)\n",
    "gscv_result = cv.fit(X, Y)\n",
    "    #gscv_result.best_estimator_, gscv_result.cv_results_"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "4px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
