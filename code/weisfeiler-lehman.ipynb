{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.sparse import lil_matrix, csr_matrix, vstack\n",
    "import copy\n",
    "import os\n",
    "import helper\n",
    "from wl import *\n",
    "from joblib import Parallel, delayed\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import math\n",
    "import pandas as pd\n",
    "import collections\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "import psutil\n",
    "import pickle\n",
    "import functools\n",
    "from matplotlib import cm\n",
    "from IPython.display import display\n",
    "from sklearn import utils\n",
    "import dataset_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(l, as_set = False):\n",
    "    return functools.reduce(lambda acc, x: acc | set(x) if as_set else acc + list(x), l, set() if as_set else list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve graphs from Tobias' concept-graph extraction library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET = 'ling-spam'\n",
    "#cache_file = dataset_helper.CACHE_PATH + '/dataset_graph_gml_{}-single.npy'.format(DATASET)\n",
    "cache_file = dataset_helper.CACHE_PATH + '/dataset_graph_gml_{}-single.npy'.format(DATASET)\n",
    "X, Y = dataset_helper.get_dataset(DATASET, use_cached = True, cache_file = cache_file)\n",
    "#X, Y = dataset_helper.get_subset_with_most_frequent_classes(X, Y, num_classes_to_keep = 3)\n",
    "assert len(X) and len(Y), 'Dataset is empty: {}'.format(DATASET)\n",
    "assert len(X) == len(Y)\n",
    "graphs_per_topic = dataset_helper.get_dataset_dict(X, Y)\n",
    "#graphs_per_topic = get_graphs(GRAPH_DIR, undirected = False, verbose = False, limit_elements = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics about the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graphs_per_topic = pd.DataFrame([(topic, len(graphs), [len(x.nodes()) for x in graphs], [len(x.edges()) for x in graphs]) for topic, graphs in graphs_per_topic.items()], columns = ['topic', 'num_graphs', 'num_nodes', 'num_edges']).set_index(['topic']).sort_values(by = 'num_graphs')\n",
    "ax = df_graphs_per_topic.plot.barh(title = 'Graphs per topic', legend = False, figsize = (14, 8))\n",
    "ax.set_xlabel('# graphs')\n",
    "plt.show()\n",
    "\n",
    "def get_range_of(df, column):\n",
    "    return df[column].apply(lambda x: min(x)).min(), df[column].apply(lambda x: max(x)).max()\n",
    "\n",
    "nodes_range = get_range_of(df_graphs_per_topic, 'num_nodes')\n",
    "edges_range = get_range_of(df_graphs_per_topic, 'num_edges')\n",
    "\n",
    "if False:\n",
    "    num_classes = len(set(Y))\n",
    "    ncols, nrows = (2, max(2, math.ceil(num_classes / 2)))\n",
    "    fig, axes = plt.subplots(ncols=ncols, nrows=nrows, figsize = (14, 20))\n",
    "    fig_, axes_ = plt.subplots(ncols=ncols, nrows=nrows, figsize = (14, 20))\n",
    "    for idx, (topic, (num_graphs, num_nodes, num_edges)) in enumerate(df_graphs_per_topic.iterrows()):\n",
    "        row = int(idx / ncols)\n",
    "        col = idx % ncols\n",
    "        print(row, col)\n",
    "        ax = axes[row][col]\n",
    "        ax_ = axes_[row][col]\n",
    "\n",
    "        # \n",
    "        ax.set_title(\"{}\".format(topic))\n",
    "        ax.set_xlabel('# nodes')\n",
    "        ax.hist(num_nodes, bins=40, normed = True, range = nodes_range)\n",
    "\n",
    "        #\n",
    "        ax_.set_title(\"{}\".format(topic))\n",
    "        ax_.set_xlabel('# edges')\n",
    "        ax_.hist(num_edges, bins=40, normed = True, range = edges_range)\n",
    "    fig.tight_layout()\n",
    "    fig_.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graphs_per_topic['avg_nodes'] = df_graphs_per_topic.num_nodes.apply(lambda x: np.mean(x))\n",
    "df_graphs_per_topic['avg_edges'] = df_graphs_per_topic.num_edges.apply(lambda x: np.mean(x))\n",
    "df_graphs_per_topic.plot(kind = 'barh', y = ['avg_nodes', 'avg_edges'], figsize = (14, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REMOVE_CATEGORIES = ['misc.forsale', 'comp.graphics']\n",
    "REMOVE_CATEGORIES = []\n",
    "graphs = graphs_per_topic.copy()\n",
    "if len(REMOVE_CATEGORIES):\n",
    "    for cat in REMOVE_CATEGORIES:\n",
    "        del graphs[cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_graphs = flatten(graphs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_nodes = set()\n",
    "for g in all_graphs:\n",
    "    all_nodes |= set(g.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#graphs:\\t\\t{}'.format(len(all_graphs)))\n",
    "print('Unique tokens found:\\t{}'.format(len(all_nodes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: This should be done with dataset_helper.split_dataset(..)\n",
    "def get_train_test_split(topic_graphs, train_split_ratio = 0.8):\n",
    "    train = []\n",
    "    test = []\n",
    "    num_elements = {}\n",
    "    for topic, graphs in topic_graphs.items():\n",
    "        num_elements_train = int(len(graphs) * train_split_ratio)\n",
    "        train += [(topic, x) for x in graphs[:num_elements_train]]\n",
    "        test += [(topic, x) for x in graphs[num_elements_train:]]\n",
    "    return train, test\n",
    "train, test = get_train_test_split(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#graphs\\n\\ttrain:\\t{}\\n\\ttest:\\t{}'.format(len(train), len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_ in [train, test]:\n",
    "    X, Y = [x for label, x in set_], [label for label, x in set_]\n",
    "    dataset_helper.plot_dataset_class_distribution(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate phi and gram-matrix of WL kernel for training instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for set_ in [train, test]:\n",
    "    for topic, graph in set_:\n",
    "        if nx.number_of_edges(graph) == 0: set_.remove((topic, graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adjs = []\n",
    "nodes = []\n",
    "for topic, graph in train:\n",
    "    sorted_nodes = sorted(graph.nodes())\n",
    "    factor = nx.number_of_nodes(graph)\n",
    "    adjs.append(nx.adjacency_matrix(graph, nodelist = sorted_nodes) / factor)\n",
    "    nodes.append(sorted_nodes)\n",
    "    \n",
    "print('Calculating WL_train: start')\n",
    "K_train, phi_list_train, label_lookup_train, label_counters_train = WL_compute(adjs, nodes, H, all_nodes = all_nodes, DEBUG = True, compute_k = False)\n",
    "print('Calculating WL_train: end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classifier with the phi s of the training instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn.linear_model.Perceptron(n_iter = 500, verbose = False, n_jobs = -1, class_weight='balanced')\n",
    "X = phi_list_train[-1].T\n",
    "Y = [topic for topic, graphs in train]\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions for test instances\n",
    "\n",
    "### Calculate phi for each test instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def get_prediction(topic, graph):\n",
    "    phi = compute_phi(graph, phi_list_train[0].shape, label_lookup_train, label_counters_train, h = H)[-1]\n",
    "    return phi\n",
    "    return phi / phi.sum()\n",
    "\n",
    "USED_SET = test\n",
    "PARALLEL_PREDICTION_JOBS = 1\n",
    "print('Starting prediction')\n",
    "\n",
    "if PARALLEL_PREDICTION_JOBS > 1:\n",
    "    phi_test = Parallel(n_jobs=PARALLEL_PREDICTION_JOBS)(delayed(get_prediction)(*d) for d in list(USED_SET))\n",
    "else:\n",
    "    phi_test = [get_prediction(*d) for d in USED_SET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_nums = sum([nx.number_of_nodes(graph) for topic, graph in train])\n",
    "nodes_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def calculate_batches(l, fn, num_batches = 10, print_every = 5):\n",
    "    elements = []\n",
    "    num_elements_per_batch = math.ceil(len(l) / num_batches)\n",
    "    print('Starting: #elements: {}, #batches: {}, #elements per Batch: {}'.format(len(l), num_batches, num_elements_per_batch))\n",
    "    for idx in range(num_batches):\n",
    "        start = idx * num_elements_per_batch\n",
    "        end = min(len(l), start + num_elements_per_batch)\n",
    "        if idx % print_every == 0: print('\\tIteration: {:>4}/{}'.format(idx, num_batches))\n",
    "        if end - start <= 0:\n",
    "            break\n",
    "        elements += fn(l[start:end]).tolist()\n",
    "    return elements\n",
    "predicted = calculate_batches(phi_test, clf.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_real = [topic for topic,graph in USED_SET]\n",
    "Y_pred = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About sparsity of test phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_phi_test_non_zero_elements = pd.DataFrame(list(zip(Y_real, Y_pred, [np.count_nonzero(x) for x in phi_test])), columns = ['real_topic', 'pred_topic', 'num_phi_non_zero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(df_phi_test_non_zero_elements.groupby(by = 'real_topic').describe())\n",
    "display(df_phi_test_non_zero_elements.groupby(by = 'pred_topic').describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_ = 0\n",
    "vals_over_1 = 0\n",
    "for i in phi_test:\n",
    "    vals = i[i > 1]\n",
    "    if not len(vals): continue\n",
    "    vals_over_1 += 1\n",
    "    m = max(vals)\n",
    "    if m > max_:\n",
    "        max_ = m\n",
    "        print(max_)\n",
    "print(vals_over_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cf_mat = sklearn.metrics.confusion_matrix(Y_real, Y_pred)\n",
    "classes = min(len(set(Y_real)) * 2, 30)\n",
    "fig = plt.figure(figsize=(classes, classes))\n",
    "helper.plot_confusion_matrix(cf_mat, clf.classes_, normalize = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.f1_score(Y_real, Y_pred, average='macro')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "4px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
