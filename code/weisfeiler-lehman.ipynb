{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.sparse import lil_matrix, csr_matrix, vstack\n",
    "import copy\n",
    "import os\n",
    "from wl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 0 == 1:\n",
    "    for start, end in [(0, 7)]:\n",
    "        print(\"# YES\", test_graph_names[start:end])\n",
    "        k, _, label_lookup = get_wl_for_graph_names(test_graph_names[start:end], fn = WL_compute)\n",
    "        k_org, _ = get_wl_for_graph_names(test_graph_names[start:end], fn = WL_compute_original)\n",
    "        print(k_org[-1] == k[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve graphs from Tobias' concept-graph extraction library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found empty graph: extract-concept-graphs/code/data/ng20/test_graphs/rec.sport.baseball/ng-20.graph.gml\n",
      "Found empty graph: extract-concept-graphs/code/data/ng20/test_graphs/sci.med/ng-20.graph.gml\n",
      "Found empty graph: extract-concept-graphs/code/data/ng20/test_graphs/sci.space/ng-20.graph.gml\n",
      "Found empty graph: extract-concept-graphs/code/data/ng20/test_graphs/talk.politics.guns/ng-20.graph.gml\n",
      "Found empty graph: extract-concept-graphs/code/data/ng20/test_graphs/talk.politics.misc/ng-20.graph.gml\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "GRAPH_DIR = 'extract-concept-graphs/code/data/ng20/{}_graphs'\n",
    "\n",
    "def get_graphs(directory):\n",
    "    graphs = {}\n",
    "    for topic in os.listdir(directory):\n",
    "        graph_dir = os.path.join(directory, topic)\n",
    "        if not os.path.isdir(graph_dir): continue\n",
    "        graph_file = glob(os.path.join(graph_dir, '*.gml'))[0]\n",
    "        with open(graph_file) as f:\n",
    "            graph = f.read().split('\\n')\n",
    "        for idx, line in enumerate(graph):\n",
    "            if line.startswith('label'):\n",
    "                next_line = graph[idx + 1]\n",
    "                label = next_line.replace('name', 'label')\n",
    "                graph[idx] = label\n",
    "        new_graph_file = graph_file.replace('.gml', '.renamed.gml')\n",
    "        with open(new_graph_file, 'w') as f:\n",
    "            f.write('\\n'.join(graph))\n",
    "        graph = nx.read_gml(new_graph_file, label = 'label')\n",
    "        if graph.number_of_nodes() > 0 and graph.number_of_edges() > 0:\n",
    "            graphs[topic] = graph\n",
    "        else:\n",
    "            graphs[topic] = None\n",
    "            print(\"Found empty graph: {}\".format(graph_file))\n",
    "    return graphs\n",
    "graphs_test_docs = get_graphs(GRAPH_DIR.format('test'))\n",
    "graphs_train_docs = get_graphs(GRAPH_DIR.format('train'))\n",
    "assert graphs_test_docs.keys() == graphs_train_docs.keys()\n",
    "assert len(graphs_test_docs.keys()) > 0\n",
    "\n",
    "all_nodes = [val for sublist in [g.nodes() for g in list(graphs_train_docs.values()) + list(graphs_test_docs.values()) if g is not None] for val in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_wl_for_graphs(graphs, all_nodes = all_nodes,  h = 10, fn = WL_compute):\n",
    "    nodes = [g.nodes() for g in graphs]\n",
    "    adjs = [nx.adjacency_matrix(g).toarray() for g in graphs]\n",
    "    return fn(adjs, nodes, all_nodes = all_nodes, h = h)\n",
    "\n",
    "def get_wl_for_graph_names(graph_names, add_all_nodes = False, h = 10, fn = WL_compute):\n",
    "    graphs = [graphs_test_docs[x] for x in graph_names]\n",
    "    graphs[0] = graphs[0].copy()\n",
    "    if add_all_nodes:\n",
    "        for node in all_nodes:\n",
    "            graphs[0].add_node(node)\n",
    "    return get_wl_for_graphs(graphs, all_nodes, h = h, fn = fn)\n",
    "\n",
    "test_graph_names = list(sorted(graphs_test_docs.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate gram-matrix for WL kernel for the training concept-graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating WL_train: start\n",
      "Number of original labels 5529\n",
      "K original is computed\n",
      "Iteration 0: phi is computed\n",
      "Number of compressed labels 5187\n",
      "Itaration 0: phi sparse saved\n",
      "Iteration 0: K is computed\n",
      "Iteration 1: phi is computed\n",
      "Number of compressed labels 5187\n",
      "Itaration 1: phi sparse saved\n",
      "Iteration 1: K is computed\n",
      "Iteration 2: phi is computed\n",
      "Number of compressed labels 5187\n",
      "Itaration 2: phi sparse saved\n",
      "Iteration 2: K is computed\n",
      "Iteration 3: phi is computed\n",
      "Number of compressed labels 5187\n",
      "Itaration 3: phi sparse saved\n",
      "Iteration 3: K is computed\n",
      "Calculating WL_train: end\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "from sklearn import svm\n",
    "\n",
    "augmented_graph = graphs_train_docs[list(graphs_train_docs.keys())[0]]\n",
    "#for node in all_nodes:\n",
    "#    augmented_graph.add_node(node)\n",
    "adjs = []\n",
    "nodes = []\n",
    "for topic, graph in sorted(graphs_train_docs.items(), key = lambda x: x[0]):\n",
    "    adjs.append(nx.adjacency_matrix(graph).toarray())\n",
    "    nodes.append(graph.nodes())\n",
    "print('Calculating WL_train: start')\n",
    "K_train, phi_list_train, label_lookup_train, label_counters_train = WL_compute(adjs, nodes, 4, all_nodes = all_nodes, DEBUG = True)\n",
    "print('Calculating WL_train: end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10994, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_list_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SVM classifier on the gram-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto',\n",
       "  kernel='precomputed', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel = 'precomputed', verbose = True, probability=True, )\n",
    "clf.fit(K_train[-1], sorted(graphs_train_docs.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing graph:\tsoc.religion.christian                   (train)\n",
      "Predicted:\tsoc.religion.christian\n",
      "Predicted:\tsoc.religion.christian\n",
      "\n",
      "Testing graph:\tsci.electronics                          (train)\n",
      "Predicted:\tsci.electronics\n",
      "Predicted:\tsci.electronics\n",
      "\n",
      "Testing graph:\tcomp.os.ms-windows.misc                  (train)\n",
      "Predicted:\tcomp.os.ms-windows.misc\n",
      "Predicted:\tcomp.os.ms-windows.misc\n",
      "\n",
      "Testing graph:\tsci.crypt                                (train)\n",
      "Predicted:\tsci.crypt\n",
      "Predicted:\tsci.crypt\n",
      "\n",
      "Testing graph:\ttalk.politics.misc                       (train)\n",
      "Predicted:\ttalk.politics.misc\n",
      "Predicted:\ttalk.politics.misc\n",
      "\n",
      "Testing graph:\tcomp.windows.x                           (train)\n",
      "Predicted:\tcomp.windows.x\n",
      "Predicted:\tcomp.windows.x\n",
      "\n",
      "Testing graph:\tsci.med                                  (train)\n",
      "Predicted:\tsci.med\n",
      "Predicted:\tsci.med\n",
      "\n",
      "Testing graph:\ttalk.politics.mideast                    (train)\n",
      "Predicted:\ttalk.politics.mideast\n",
      "Predicted:\ttalk.politics.mideast\n",
      "\n",
      "Testing graph:\tcomp.sys.mac.hardware                    (train)\n",
      "Predicted:\tcomp.sys.mac.hardware\n",
      "Predicted:\tcomp.sys.mac.hardware\n",
      "\n",
      "Testing graph:\trec.sport.baseball                       (train)\n",
      "Predicted:\trec.sport.baseball\n",
      "Predicted:\trec.sport.baseball\n",
      "\n",
      "Testing graph:\trec.sport.hockey                         (train)\n",
      "Predicted:\trec.sport.hockey\n",
      "Predicted:\trec.sport.hockey\n",
      "\n",
      "Testing graph:\trec.motorcycles                          (train)\n",
      "Predicted:\trec.motorcycles\n",
      "Predicted:\trec.motorcycles\n",
      "\n",
      "Testing graph:\tcomp.graphics                            (train)\n",
      "Predicted:\tcomp.graphics\n",
      "Predicted:\tcomp.graphics\n",
      "\n",
      "Testing graph:\trec.autos                                (train)\n",
      "Predicted:\trec.autos\n",
      "Predicted:\trec.autos\n",
      "\n",
      "Testing graph:\tsci.space                                (train)\n",
      "Predicted:\tsci.space\n",
      "Predicted:\tsci.space\n",
      "\n",
      "Testing graph:\ttalk.politics.guns                       (train)\n",
      "Predicted:\ttalk.politics.guns\n",
      "Predicted:\ttalk.politics.guns\n",
      "\n",
      "Testing graph:\tcomp.sys.ibm.pc.hardware                 (train)\n",
      "Predicted:\tcomp.sys.ibm.pc.hardware\n",
      "Predicted:\tcomp.sys.ibm.pc.hardware\n",
      "\n",
      "Testing graph:\tmisc.forsale                             (train)\n",
      "Predicted:\tmisc.forsale\n",
      "Predicted:\tmisc.forsale\n",
      "\n",
      "Testing graph:\ttalk.religion.misc                       (train)\n",
      "Predicted:\ttalk.religion.misc\n",
      "Predicted:\ttalk.religion.misc\n",
      "\n",
      "Testing graph:\talt.atheism                              (train)\n",
      "Predicted:\talt.atheism\n",
      "Predicted:\talt.atheism\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RECOMPUTE = True\n",
    "all_graphs_test = [('test', topic, graph) for topic, graph in graphs_test_docs.items()]\n",
    "all_graphs_train = [('train', topic, graph) for topic, graph in graphs_train_docs.items()]\n",
    "\n",
    "def print_predict(X_test):\n",
    "    print('Predicted:\\t{}'.format(clf.predict(X_test)[0]))\n",
    "    \n",
    "vals = []\n",
    "for set_, test_topic, graph in sorted(all_graphs_train, key = lambda x: x[0]):\n",
    "    if graph is None: continue\n",
    "    print('Testing graph:\\t{:40} ({})'.format(test_topic, set_))\n",
    "    test_graph = graph\n",
    "    K_test, phi_list_test = WL_compute_new(\n",
    "        ad_list=[nx.adjacency_matrix(test_graph).toarray()],\n",
    "        node_label=[test_graph.nodes()],\n",
    "        all_nodes= all_nodes,\n",
    "        h = 4,\n",
    "        k_prev = np.copy(K_train),\n",
    "        phi_prev = np.copy(phi_list_train),\n",
    "        label_counters_prev = label_counters_train,\n",
    "        label_lookups_prev = np.copy(label_lookup_train)\n",
    "    )\n",
    "\n",
    "    X_test = K_test[-1][-1, :-1].reshape(1, -1)\n",
    "    vals.append((K_test, phi_list_test, X_test))\n",
    "    print_predict(X_test)\n",
    "    \n",
    "    if RECOMPUTE and True:\n",
    "        adjs_test =  adjs + [nx.adjacency_matrix(test_graph).toarray()]\n",
    "        nodes_test =  nodes + [test_graph.nodes()]\n",
    "        K_test, phi_list_test, label_lookup_test, label_counters_test = WL_compute(adjs_test, nodes_test, 4, all_nodes = all_nodes, DEBUG = False)\n",
    "        X_test = K_test[-1][-1, :-1].reshape(1, -1)\n",
    "        print_predict(X_test)\n",
    "        vals.append((K_test, phi_list_test, X_test))\n",
    "    \n",
    "\n",
    "    probs_test = clf.predict_proba(X_test)[0]\n",
    "    probs_zipped = list(zip(clf.classes_, probs_test))\n",
    "    print()\n",
    "    #for clazz, prob in sorted(probs_zipped, key = lambda x: x[1])[:5]:\n",
    "    #    print('\\t{:.3f}\\t{}'.format(prob, clazz))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 float32\n",
      "float32 float32\n",
      "float32 float32\n",
      "float32 float32\n",
      "float32 float32\n"
     ]
    }
   ],
   "source": [
    "K_test, phi_list_test, X_test = vals[-2]\n",
    "K_real, phi_list_real, X_real = vals[-1]\n",
    "\n",
    "for i, (a, b) in enumerate(zip(phi_list_test, phi_list_real)):\n",
    "    b = b.todense()[:a.shape[0]] #.astype(np.float32)\n",
    "    if not np.array_equal(a.astype(np.int32) - b.astype(np.int32), np.zeros(b.shape, dtype = np.int32)):\n",
    "        break\n",
    "        \n",
    "#print(lil_matrix(phi_list_test[0][:,5]), '\\n', phi_list_train[0][:,5])\n",
    "for i, (a, b) in enumerate(zip(K_test, K_real)):\n",
    "    print(a.dtype, b.dtype)\n",
    "    if not np.array_equal(a, b):\n",
    "        print(\"K different!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 0 == 1:\n",
    "    fig = plt.figure(figsize=(30, 30))\n",
    "    pos=nx.spring_layout(g_mult_dir)\n",
    "    nx.draw(g_mult_dir, pos = pos)\n",
    "\n",
    "    edge_labels=dict([((u,v,),d['name'])\n",
    "                 for u,v,d in g_mult_dir.edges(data=True)])\n",
    "    nx.draw_networkx_edge_labels(g_mult_dir,pos,edge_labels=edge_labels)\n",
    "    nx.draw_networkx_nodes(g_mult_dir, pos = pos, label='name', )\n",
    "    nx.draw_networkx_labels(g_mult_dir, pos = pos)\n",
    "    plt.show()\n",
    "\n",
    "    graphs = sorted(list(nx.weakly_connected_component_subgraphs(g_mult_dir)), key = len)#, reverse = True)\n",
    "\n",
    "    for graph in graphs[-4:]:\n",
    "        fig = plt.figure(figsize=(20, 20))\n",
    "        pos=nx.spring_layout(graph)\n",
    "        #nx.draw(graph, pos = pos)\n",
    "        edge_labels=dict([((u,v,),d['name'])\n",
    "                     for u,v,d in graph.edges(data=True)])\n",
    "        nx.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels)\n",
    "        nx.draw_networkx_edges(graph, pos, arrows = True)\n",
    "        nx.draw_networkx_nodes(graph, pos = pos, label='name')\n",
    "        nx.draw_networkx_labels(graph, pos = pos)\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "4px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
