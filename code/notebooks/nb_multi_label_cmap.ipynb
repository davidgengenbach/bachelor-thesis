{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_prelude import *\n",
    "import experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = collections.defaultdict(lambda: [])\n",
    "cmap_cache_files = dataset_helper.get_all_cached_graph_datasets(graph_type=TYPE_CONCEPT_MAP)\n",
    "for file in helper.log_progress(cmap_cache_files):\n",
    "    dataset = filename_utils.get_dataset_from_filename(file)\n",
    "    X, Y = dataset_helper.get_dataset_cached(file)\n",
    "    X = graph_helper.get_graphs_only(X)\n",
    "    \n",
    "    all_labels = set(graph_helper.get_all_node_labels(X))\n",
    "    data['dataset'] += [dataset] * len(all_labels)\n",
    "    data['labels'] += [str(x) for x in all_labels]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['num_words'] = df['labels'].str.split().apply(len)\n",
    "df = df.set_index(['dataset', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datasets = len(df.reset_index().dataset.unique())\n",
    "fig, axes = plt.subplots(ncols=2, nrows=int(np.ceil(num_datasets / 2)), sharex=False)\n",
    "\n",
    "for ax, (dataset, df_) in zip(axes.flatten()[:num_datasets], df.groupby('dataset')):\n",
    "    print(dataset)\n",
    "    df_.reset_index().set_index('labels').num_words.plot(kind='hist', bins=50, ax=ax, title=dataset)\n",
    "    ax.grid('off')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('dataset').num_words.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocessing\n",
    "\n",
    "df_ = df.reset_index()\n",
    "df_[(df_.dataset=='ng20') & (df_.num_words > 10)]\n",
    "\n",
    "df_['label_clean'] = df_['labels'].apply(preprocessing.preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_[(df_.dataset=='ng20') & (df_.num_words > 10)]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
