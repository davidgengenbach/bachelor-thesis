{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: _Combined text-/graph features vs. text-only features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_prelude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NA_VAL = '-'\n",
    "EXPERIMENT_NAME = 'experiment_combined'\n",
    "experiment_data = experiment_helper.get_experiment_config_for(EXPERIMENT_NAME)\n",
    "param_grid = experiment_data['params_per_type']\n",
    "\n",
    "#, EXPERIMENT_NAME + '_same_label', EXPERIMENT_NAME + '_with_splitted'\n",
    "df = results_helper.get_experiments_by_names([EXPERIMENT_NAME])\n",
    "df = df.fillna(NA_VAL)\n",
    "pipeline_helper.remove_complex_types(pipeline_helper.flatten_nested_params(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTORIZER_TFIDF = 'TfidfVectorizer'\n",
    "VECTORIZER_COUNT = 'CountVectorizer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df.columns: print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[np.isin(df.type, [TYPE_CONCEPT_MAP, TYPE_COOCCURRENCE, 'text'])].groupby(['dataset', 'features__fast_wl_pipeline__feature_extraction__graph_preprocessing', 'text__vectorizer', 'combined', 'type']).mean_test_f1_macro.max().to_frame().unstack().unstack()#.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, params in sorted(experiment_helper.get_all_param_grid_config_files().items(), key=lambda x: x[0]):\n",
    "    file = file.split('/')[-1]\n",
    "    print(file)\n",
    "    for task_name, params_ in params['params_per_type'].items():\n",
    "        if 'classifier__C' not in params_: continue\n",
    "        C = params_['classifier__C']\n",
    "        if not C: continue\n",
    "        print('\\t{:40} {}'.format(task_name, C))\n",
    "    #print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significance tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in results_helper.get_predictions_files() if EXPERIMENT_NAME in x and filename_utils.get_dataset_from_filename(x) == 'ng20' and 'graph_combined' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import significance_test_utils\n",
    "\n",
    "NUM_TRAILS = 10000\n",
    "metric = significance_test_utils.f1\n",
    "\n",
    "combinations = [\n",
    "    # TfidfVectorizer\n",
    "    (\n",
    "        # Combined\n",
    "        'result___experiment_combined__ng20__graph_combined__dataset_graph_concept_map_ng20-v3.npy',\n",
    "        \n",
    "        # Text-only\n",
    "        'result___experiment_combined__ng20__text.npy',\n",
    "    )\n",
    "]\n",
    "\n",
    "filenames = []\n",
    "for a, b in combinations:\n",
    "    filenames.append(a)\n",
    "    filenames.append(b)\n",
    "\n",
    "data = collections.defaultdict(lambda: [])\n",
    "\n",
    "predictions = {k.split('/')[-1]: v['results']['results'] for k, v in results_helper.get_predictions(filenames=filenames)}\n",
    "for filenames in combinations:\n",
    "    assert np.all([x in predictions for x in filenames])\n",
    "    models = [predictions[x] for x in filenames]\n",
    "    keys = ['Y_real', 'Y_pred', 'X_test']\n",
    "    assert np.all([len(models[0][key]) == len(models[1][key]) for key in keys])\n",
    "    y_true = models[0]['Y_real']\n",
    "    y_preds = [model['Y_pred'] for model in models]\n",
    "    y_pred_a, y_pred_b = y_preds\n",
    "    metric_real = [metric(y_true, y_pred) for y_pred in y_preds]\n",
    "    diff_global = metric_real[0] - metric_real[1]\n",
    "    \n",
    "    metrics = significance_test_utils.randomization_test(y_true, y_pred_a, y_pred_b, metric=significance_test_utils.f1, num_trails=NUM_TRAILS)\n",
    "    diffs = metrics[:, 0] - metrics[:, 1]\n",
    "    confidence = significance_test_utils.get_confidence(diff_global, diffs, num_trails=NUM_TRAILS, one_tail=True)\n",
    "\n",
    "    data['num_docs'].append(len(y_pred_a))\n",
    "    data['filename_a'].append(filenames[0])\n",
    "    data['filename_b'].append(filenames[1])\n",
    "    data['confidence'].append(confidence)\n",
    "    data['diffs'].append(diffs)\n",
    "    data['diff_global'].append(diff_global)\n",
    "    data['metric_a'].append(metric_real[0])\n",
    "    data['metric_b'].append(metric_real[1])\n",
    "    data['num_trails'].append(NUM_TRAILS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.DataFrame(data).set_index(['filename_a', 'filename_b'])\n",
    "df_[[x for x in df_.columns if x != 'diffs']].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (f_a, f_b), df__ in df_.iterrows():\n",
    "    diffs = df__.diffs\n",
    "    fig, ax = plt.subplots(figsize=(10, 3.4))\n",
    "    significance_test_utils.plot_randomization_test_distribution_(diffs, df__.diff_global, num_trails=df__.num_trails, p=df__.confidence, metric_name='f1 macro', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = collections.Counter()\n",
    "for idx, (a, b) in enumerate(zip(*y_preds)):\n",
    "    c['same' if a == b else 'not_same'] += 1\n",
    "c"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
