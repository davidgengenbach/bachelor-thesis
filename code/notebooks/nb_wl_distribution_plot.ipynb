{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WL phi feature map distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_prelude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(dataset_helper.get_dataset_names_with_concept_map())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FOLDER='tmp/wl_phi_distributions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGSIZE = (15, 12)\n",
    "\n",
    "def print_phi_distribution(title, X_phi, Y, sort_y = True, add_class_label = True, add_class_line = True, figsize = FIGSIZE, flip_axis = False, draw_vertice_count_line = True, h_lines = [], sns_color_palette = \"bright\", class_v_line_kwargs=dict(linestyle = 'solid', color = 'black', linewidth = 1, alpha = 0.1), class_h_line_kwargs = dict(linestyle ='solid', linewidth = 1, alpha = 0.6)):\n",
    "    if sort_y:\n",
    "        # Use a stable sort algorithm\n",
    "        Y_sorted_indices = np.argsort(Y, kind = 'mergesort')\n",
    "        Y = np.array(Y)[Y_sorted_indices]\n",
    "        X_phi = [phi[Y_sorted_indices] for phi in X_phi]\n",
    "\n",
    "    cmap_ = sns.color_palette(sns_color_palette, max(len(set(Y)), len(h_lines[0])))\n",
    "    clazz_2_color_map = dict()\n",
    "    \n",
    "    counter = 0\n",
    "    for clazz in Y:\n",
    "        if clazz not in clazz_2_color_map:\n",
    "            clazz_2_color_map[clazz] = counter\n",
    "            counter += 1\n",
    "    colors = [clazz_2_color_map[y] for y in Y]\n",
    "    occurences = {clazz: -1 for clazz in set(Y)}\n",
    "    \n",
    "    for idx, y in enumerate(Y):\n",
    "        if occurences[y] == -1: occurences[y] = idx\n",
    "\n",
    "    ax_labels = ['phi index', 'graph']\n",
    "    ax_line = 'v' if flip_axis else 'x'\n",
    "    \n",
    "    if flip_axis:\n",
    "        ax_labels = list(reversed(ax_labels))\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols = len(X_phi), figsize = figsize, sharey = True)\n",
    "    \n",
    "    axes[0].set_ylabel(ax_labels[1])\n",
    "    \n",
    "    num_graphs, num_vertices = X_phi[0].shape\n",
    "    \n",
    "    for h, (phi, ax) in enumerate(zip(X_phi, axes)):\n",
    "        non_zero = phi.nonzero()\n",
    "\n",
    "        if flip_axis:\n",
    "            non_zero = reversed(non_zero)\n",
    "\n",
    "        y, x = non_zero\n",
    "\n",
    "        # Plot hlines (eg. max phi index of class)\n",
    "        if len(h_lines):\n",
    "            for class_idx, hline in enumerate(h_lines[h]):\n",
    "                if isinstance(hline, tuple):\n",
    "                    hline, line_color = hline\n",
    "                else:\n",
    "                    line_color = cmap_[class_idx]\n",
    "                ax.axhline(hline, color = line_color, **class_h_line_kwargs)\n",
    "        \n",
    "        colors_ = [cmap_[colors[x_]] for x_ in x]\n",
    "        ax.scatter(x = x, y = y, c = colors_, cmap=cmap_, s = 1)\n",
    "        ax.set_title('Iteration: {}'.format(h))\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xlabel(ax_labels[0])\n",
    "        ax.grid('off')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "        # Add class occurrence lines\n",
    "        for clazz, occurence_idx in occurences.items():\n",
    "            if add_class_line:\n",
    "                getattr(ax, 'ax{}line'.format(ax_line))(occurence_idx, **class_v_line_kwargs)\n",
    "            if add_class_label:\n",
    "                x, y = 1, occurence_idx\n",
    "                if flip_axis:\n",
    "                    y, x = x, y\n",
    "                ax.text(x = 1, y = occurence_idx, s = clazz, color = 'red')\n",
    "\n",
    "        if draw_vertice_count_line:\n",
    "            ax.set_ylim(0, num_vertices * 1.03)\n",
    "            ax.axhline(num_vertices - (num_vertices / 100), color = 'red', linewidth=1)\n",
    "        \n",
    "    \n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top = .9)\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "def filter(cache_file):\n",
    "    is_split = 'splitted' in cache_file\n",
    "    is_ling_spam = 'ling-spam' in cache_file\n",
    "    is_dataset = lambda dataset: filename_utils.get_dataset_from_filename(cache_file) == dataset\n",
    "    is_concept_graph = 'concept-map' in cache_file\n",
    "    is_same_label = 'same-label' in cache_file\n",
    "    return is_split# and is_same_label #and is_dataset('webkb')# and is_concept_graph\n",
    "\n",
    "for cache_file in dataset_helper.get_all_cached_graph_phi_datasets():\n",
    "    if not filter(cache_file): continue\n",
    "    print(cache_file)\n",
    "    def plot(X_phi, Y, suffix = '', h_lines = [], plot_kwargs = dict()):\n",
    "        filename = '{}{}.png'.format(cache_file.split('/')[-1], suffix)\n",
    "        assert np.array_equal(np.sort(Y), Y)\n",
    "        print(filename)\n",
    "        kwargs = dict(dict(sort_y = False, add_class_label = False, flip_axis = True, add_class_line = True, h_lines = h_lines), **plot_kwargs)\n",
    "        fig, ax = print_phi_distribution('File: {} {} (#vertices: {})'.format(cache_file.split('/')[-1], suffix, X_phi[0].shape[1]), X_phi, Y, **kwargs)\n",
    "        save_fig(fig, filename, folder=SAVE_FOLDER)\n",
    "        plt.close(fig)\n",
    "\n",
    "    def get_hlines(phis, Y):\n",
    "        highest_per_class = []\n",
    "        for phi in phis:\n",
    "            non_zero = phi.nonzero()\n",
    "            non_zero_y, non_zero_x = non_zero \n",
    "            highest_per_class_ = collections.defaultdict(lambda: -1)\n",
    "            for non_zero_y, non_zero_x in zip(non_zero_y, non_zero_x):\n",
    "                clazz = Y[non_zero_y]\n",
    "                highest_per_class_[clazz] = max(highest_per_class_[clazz], non_zero_x)\n",
    "            highest_per_class.append(sorted(list(highest_per_class_.values())))\n",
    "        return highest_per_class\n",
    "        \n",
    "    phi_res = dataset_helper.get_dataset_cached(cache_file, check_validity=False)\n",
    "    if len(phi_res) == 2:\n",
    "        phi_train, Y_train = phi_res\n",
    "        h_lines = get_hlines(phi_train, Y_train)\n",
    "        plot(*phi_res, h_lines = h_lines)\n",
    "    elif len(phi_res) == 6:\n",
    "        phi_train, phi_test, X_train, X_test, Y_train, Y_test = phi_res\n",
    "        h_lines = get_hlines(phi_train, Y_train)\n",
    "        kwargs = dict()\n",
    "        if 'same-label' in cache_file:\n",
    "            kwargs['draw_vertice_count_line'] = False\n",
    "        if len(set(Y_train)) > 20:\n",
    "            kwargs['add_class_line'] = False\n",
    "        for res in [(phi_train, Y_train, '_train'), [phi_test, Y_test, '_test']]:\n",
    "            plot(*res, h_lines = h_lines, plot_kwargs=kwargs)\n",
    "    else:\n",
    "        assert False\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy saved figures into categorized folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PHI_DIST = 'tmp/phi-distributions'\n",
    "\n",
    "data = collections.defaultdict(lambda: [])\n",
    "for file in glob('{}/*.png'.format(FOLDER_PHI_DIST)):\n",
    "    data['file'].append(file)\n",
    "df = pd.DataFrame(data)\n",
    "df['dataset'] = df.file.apply(filename_utils.get_dataset_from_filename)\n",
    "df['same_label'] = df.file.str.contains('same-label') | df.file.str.contains('same_label')\n",
    "df['type'] = df.file.str.extract(r'dataset_graph_(.+?)_')\n",
    "df['window_size'] = df.file.str.extract(r'dataset_graph_cooccurrence_(.+?)_')\n",
    "df['split'] = df.file.str.contains('splitted')\n",
    "df['test_train'] = df.file.str.extract(r'phi.npy_(.+?).png$')\n",
    "df['original_file'] = df.file.str.extract(r'/([^/]+?\\.npy)').str.replace('.splitted', '')\n",
    "\n",
    "for idx, item in df.iterrows():\n",
    "    old_folder = item.file.rsplit(\"/\", 1)[0]\n",
    "    old_filename = item.file.rsplit(\"/\", 1)[1]\n",
    "    new_filename = '{old_folder}/_/{t.dataset}/{t.type}/{t.same_label}/{old_filename}'.format(t = item, old_folder = old_folder, old_filename = old_filename)\n",
    "    folder = new_filename.rsplit('/', 1)[0]\n",
    "    os.makedirs(folder, exist_ok = True)\n",
    "    shutil.copyfile(src = item.file, dst=new_filename)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
