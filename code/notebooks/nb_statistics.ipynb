{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "require(\"notebook/js/notebook\").Notebook.prototype.scroll_to_bottom = function () {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_prelude import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_folders = results_helper.get_result_folders()\n",
    "\n",
    "folder = all_folders[-2].split('/')[-1]\n",
    "folder = None\n",
    "\n",
    "df_all = results_helper.get_results(folder=folder, use_already_loaded=False, exclude_filter = 'relabeled', filter_out_non_complete_datasets = True)\n",
    "gc.collect()\n",
    "df_all = df_all[df_all.is_ana == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.groupby(['dataset', 'type', 'combined', 'kernel', 'vectorizer']).mean_test_f1_macro.max().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[(df_all.dataset == 'ng20') &\n",
    "(df_all.type == 'concept_map') &\n",
    "(df_all.kernel == 'wl') &\n",
    "(df_all.combined == False) &\n",
    "(df_all.filename.str.contains('__graph__'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df__ = df_all[(df_all.kernel == 'wl') & (df_all.combined == False)].groupby(['dataset', 'type']).mean_test_f1_macro.max().to_frame().unstack()\n",
    "#\n",
    "df__.columns = df__.columns.droplevel()\n",
    "df__['ratio'] = df__.concept_map / df__.cooccurrence\n",
    "print(df__.to_latex())\n",
    "df__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DummyClassifier performance per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all.type == 'dummy'].groupby('dataset').mean_test_f1_macro.max().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RENAME_COLS_MAPPING = {'mean_test_f1_macro': 'f1', 'mean_test_accuracy': 'accuracy', 'mean_test_precision_macro': 'precision', 'mean_test_recall_macro': 'recall'}\n",
    "METRICS_COLUMNS = ['f1', 'accuracy', 'precision', 'recall']\n",
    "\n",
    "UNINTERESTING_COLUMNS = [x for x in df_all.columns.tolist() if 'fit_time' in x or 'split' in x or 'std' in x or 'rank' in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for combined classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_decimals = -1\n",
    "\n",
    "classifier = 'LinearSVC'\n",
    "kernel = 'wl'\n",
    "wl_iteration = \"stacked\"\n",
    "text_vectorizer = 'TfidfVectorizer'\n",
    "text_vectorizer = 'CountVectorizer'\n",
    "stopwords = 'english'\n",
    "n_gram_range = (1, 1)\n",
    "window_size = '1'\n",
    "used_words = 'all'\n",
    "use_edges = True\n",
    "classifier_c = 0.1\n",
    "binary = False\n",
    "use_node_weighting = False\n",
    "\n",
    "default_filter = (df_all.classifier__C == classifier_c) & (df_all.classifier == classifier) & (df_all.same_label != True) & (df_all.vectorizer__vectorizer__binary != False)\n",
    "\n",
    "def get_text_result_for_graph(graph_item, text_vectorizer = text_vectorizer, stop_words = stopwords, classifier=classifier, n_gram_range = n_gram_range):\n",
    "    return df_all[\n",
    "        default_filter &\n",
    "        (df_all.dataset == graph_item.dataset) &\n",
    "        (df_all.type == 'text') &\n",
    "        (df_all.preprocessing.apply(lambda x: x is None)) &\n",
    "        (df_all.vectorizer == text_vectorizer) &\n",
    "        (df_all.vectorizer__ngram_range == n_gram_range) &\n",
    "        (df_all.vectorizer__binary == binary)\n",
    "    ]\n",
    "\n",
    "# Filter out specific combination of parameters\n",
    "df_graphs = df_all[\n",
    "    (\n",
    "        default_filter &\n",
    "        (df_all.kernel == kernel) &\n",
    "        (df_all.phi_picker__return_iteration == wl_iteration) &\n",
    "        (df_all.fast_wl__round_to_decimals == to_decimals) &\n",
    "        #(df_all.fast_wl__use_node_weight_factors == use_node_weighting) &\n",
    "        (df_all.apply(lambda x: x.type == 'concept_map' or (x.window_size == window_size and x.words == used_words), axis = 1)) \n",
    "    ) | (\n",
    "        default_filter &\n",
    "        (df_all.type == 'text') &\n",
    "        (df_all.preprocessing.apply(lambda x: x is None)) &\n",
    "        (df_all.vectorizer == text_vectorizer) &\n",
    "        #(df_all.vectorizer__stop_words == stopwords) &\n",
    "        (df_all.vectorizer__ngram_range == n_gram_range) &\n",
    "        (df_all.vectorizer__binary == binary)\n",
    "    )\n",
    "]\n",
    "\n",
    "def get_index_name(x):\n",
    "    if x.type == 'text':\n",
    "        return 'text only'\n",
    "    elif x.combined:\n",
    "        return 'combined' if not x.fast_wl__use_node_weight_factors else 'combined (with node weighting)'\n",
    "    elif x.fast_wl__use_node_weight_factors:\n",
    "        return '?'\n",
    "    else:\n",
    "        return \n",
    "\n",
    "df_graphs['index_readable'] = pd.Categorical(df_graphs.apply(get_index_name, axis = 1), ['text only', 'graph only', 'combined'])\n",
    "df_graphs['mean_test_f1_macro_with_std'] = df_graphs.apply(lambda x: '{:.3f} (+/- {:.3f})'.format(x.mean_test_f1_macro, x.std_test_f1_macro) ,axis = 1)\n",
    "df_grouped = df_graphs.groupby(['dataset', 'index_readable', 'type']).mean_test_f1_macro_with_std.max()\n",
    "display(df_grouped.unstack())\n",
    "\n",
    "for graph_type in ['cooccurrence', 'concept_map']:\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, sharey=True, figsize = EXPORT_FIG_SIZE)\n",
    "    df_graphs_f = df_graphs[(df_graphs.type == graph_type)]\n",
    "    for idx, (ax, (dataset, df)) in enumerate(zip(axes.flatten(), df_graphs_f.groupby('dataset'))):\n",
    "        el_text = get_text_result_for_graph(df.iloc[0])\n",
    "        df = df.append(el_text)\n",
    "\n",
    "        df['index_readable'] = df.apply(get_index_name, axis = 1)\n",
    "        df = df.set_index('index_readable').sort_index()\n",
    "\n",
    "        df.mean_test_f1_macro.plot(kind = 'barh', ax = ax, title = 'Dataset: {}'.format(dataset))\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylabel('Type')\n",
    "        ax.set_xlabel('f1 macro')\n",
    "\n",
    "    fig.suptitle('Graph: type={} kernel={}, wl_iterations={}\\nText: vectorizer={}, stopwords={}, ngram_range={}'.format(graph_type, kernel, wl_iteration, text_vectorizer, stopwords, n_gram_range))\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.78)\n",
    "    fig.subplots_adjust(wspace = 0.2, hspace = 0.7)\n",
    "    fig.savefig('tmp/result_combined_{}.png'.format(graph_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graphs_ = df_all[\n",
    "    (df_all.combined == False) &\n",
    "    (df_all.apply(lambda x: x.type == 'concept_map' or (x.window_size == window_size and x.words == used_words), axis = 1)) &\n",
    "    (df_all.vectorizer != 'TfidfVectorizer') &\n",
    "    (df_all.phi_picker__return_iteration != 0)\n",
    "    # &(df_all.vectorizer__binary != True)\n",
    "]\n",
    "\n",
    "for dataset, df_ in df_graphs_.groupby('dataset'):\n",
    "    fig, ax = plt.subplots()\n",
    "    df_.groupby(['type', 'kernel']).mean_test_f1_macro.max().plot(kind = 'barh', title = dataset)\n",
    "    for (t, k), df in df_.groupby(['type', 'kernel']):\n",
    "        if t != 'cooccurrence': continue\n",
    "        if k != 'wl': continue\n",
    "        best = df.mean_test_f1_macro.idxmax()\n",
    "        df_best = df.loc[best].to_frame()\n",
    "        #display(df_best.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for \"linearized\" graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_right_coo(x):\n",
    "    return (x.window_size == window_size) & (x.words == used_words)\n",
    "\n",
    "def get_right_g_2(x):\n",
    "    return x.kernel != 'text' or (\n",
    "        x.preprocessing is None and\n",
    "        x.vectorizer == text_vectorizer and\n",
    "        x.vectorizer__stop_words == stopwords and\n",
    "        x.vectorizer__ngram_range == n_gram_range and\n",
    "        x.graph_to_text__use_edges == use_edges\n",
    "    )\n",
    "\n",
    "def get_right_g(x):\n",
    "    return x.kernel != 'wl' or (x.phi_picker__return_iteration == wl_iteration and x.fast_wl__round_to_decimals == to_decimals)\n",
    "\n",
    "df_filtered = df_all[\n",
    "    (df_all.classifier == classifier) &\n",
    "    (df_all.classifier__C == classifier_c) &\n",
    "    #((df_all.kernel != 'wl') | (df_all.fast_wl__use_node_weight_factors == use_node_weighting)) &\n",
    "    (df_all.type != 'text') &\n",
    "    (df_all.type != 'dummy') &\n",
    "    ((df_all.kernel == 'wl') | ((df_all.kernel == 'text'))) &\n",
    "    (df_all.combined == False) &\n",
    "    #(df_all.same_label == False) & \n",
    "    (df_all.apply(get_right_g_2, axis = 1)) & \n",
    "    (df_all.apply(lambda x: get_right_g(x) and (x.type == 'concept_map' or get_right_coo(x)), axis = 1))\n",
    "]\n",
    "\n",
    "def get_index(df):\n",
    "    index = ''\n",
    "    if df.same_label:\n",
    "        index = 'structure only'\n",
    "    if df.kernel == 'wl':\n",
    "        index = 'combined'\n",
    "    else:\n",
    "        index = 'content'\n",
    "    if df.vectorizer__binary:\n",
    "        index += ' (binary)'\n",
    "    if df.fast_wl__use_node_weight_factors:\n",
    "        index += ' (node weights)'\n",
    "    return index\n",
    "    \n",
    "df_filtered['_label'] = df_filtered.apply(get_index, axis = 1)\n",
    "#df_filtered['_label'] = pd.Categorical(df_filtered._label, ['content only (binary)', 'content only (frequencies)', 'structure only', 'combined'])\n",
    "#, 'fast_wl__use_node_weight_factors'\n",
    "groups = ['dataset', 'type', '_label', 'vectorizer__binary']\n",
    "\n",
    "#groups = ['type', 'dataset', '_label']\n",
    "df__ = df_filtered.groupby(groups).mean_test_f1_macro.max().to_frame()\n",
    "#print(df__.unstack().rename(columns = {'mean_test_f1_macro': 'f1 macro', 'dataset': 'Dataset'}).to_latex())\n",
    "#display(df_filtered.fast_wl__use_node_weight_factors.value_counts())\n",
    "display(df_filtered[df_filtered.dataset == 'ng20'].groupby(['type', 'vectorizer__binary']).mean_test_f1_macro.max())\n",
    "\n",
    "for (graph_type, df_) in df_filtered.groupby('type'):\n",
    "    fig, axes = plt.subplots(nrows = 2, ncols=2, figsize = EXPORT_FIG_SIZE, sharey=True)\n",
    "    for ax, (dataset, df__) in zip(axes.flatten(), df_.groupby('dataset')):\n",
    "        title = 'Dataset: {}'.format(dataset)\n",
    "        df__.set_index('_label').sort_index().mean_test_f1_macro.plot(kind = 'barh', ax = ax, xerr = df__.std_test_f1_macro, title = title)\n",
    "        ax.set_ylabel('')\n",
    "        ax.set_xlabel('f1 macro')\n",
    "        \n",
    "    suptitle = 'graph={}, wl_iteration={}'.format(graph_type, 'stacked' if wl_iteration == -1 else wl_iteration)\n",
    "    \n",
    "    suptitle += ' text_vectorizer={}, ngram={}'.format(text_vectorizer, n_gram_range)\n",
    "    if graph_type == 'concept_map':\n",
    "        suptitle += ', concept_map_use_edges={}'.format(use_edges)\n",
    "    else:\n",
    "        suptitle += ', window_size={}'.format(window_size)\n",
    "        \n",
    "    fig.suptitle(suptitle)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top = 0.85)\n",
    "    fig.savefig('tmp/results_kernel_{}.png'.format(graph_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all.type == 'concept_map'].groupby(['dataset', 'combined']).mean_train_f1_macro.describe()#.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for concept vs. cooccurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 2, ncols = 2, sharey=True)\n",
    "\n",
    "for ax, (dataset, df_) in zip(axes.flatten(), df_graphs[(df_graphs.combined == False) & ((df_graphs.type == 'concept_map') | ((df_graphs.window_size == window_size) & (df_graphs.words == 'all')))].groupby('dataset')):\n",
    "    df_ = df_.rename(columns=RENAME_COLS_MAPPING)\n",
    "    df_.set_index('type').sort_index()[METRICS_COLUMNS].plot(kind = 'barh', ax = ax, title = 'Dataset: {}'.format(dataset), legend = False)\n",
    "    ax.set_xlabel('f1 macro')\n",
    "\n",
    "axes.flatten()[1].legend()\n",
    "fig.suptitle('Concept vs. Co-Occurrence\\nkernel={}, co-occurrence window_size={}'.format(kernel, window_size))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.88)\n",
    "fig.subplots_adjust(wspace = 0.2, hspace = 0.5)\n",
    "fig.savefig('tmp/result_graph_comparison.png'.format(graph_type))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best classifers per type per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_best_by_type(df_all, df, df_dataset, title = '', fontsize = 12, figsize = (6, 3), top = 0.85):\n",
    "    # Get best elements per dataset\n",
    "    els = df_all.iloc[df['mean_test_f1_macro'].idxmax()]\n",
    "    els = els.set_index('type')\n",
    "    els = els.rename(columns = RENAME_COLS_MAPPING)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize = figsize)\n",
    "    \n",
    "    std_errs = [els.std_test_f1_macro * 2,  els.std_test_accuracy * 2,  els.std_test_precision_macro * 2,  els.std_test_recall_macro * 2]\n",
    "\n",
    "    els[METRICS_COLUMNS].plot(kind = 'barh', ax = ax, xlim = (0, 1.5), xerr=std_errs)\n",
    "    ax.set_xticks(np.linspace(0, 1, 11))\n",
    "    \n",
    "    ax.grid(axis = 'y')\n",
    "    \n",
    "    display(els[[x for x in els.columns.tolist() if x not in UNINTERESTING_COLUMNS]])\n",
    "    \n",
    "    if title and title != '':\n",
    "        fig.suptitle(title, fontsize = fontsize)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if title and title != '':\n",
    "        fig.subplots_adjust(top = top)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "# Ignore 0th WL iteration\n",
    "for name, df_dataset in sorted(df_all[(df_all.phi_picker__return_iteration != 0) & (df_all.combined == False)].groupby('dataset'), key = lambda x: x[0]):\n",
    "    df_dataset_grouped_by_type = df_dataset.groupby('type')\n",
    "    print('################# {}'.format(name))\n",
    "    use_title = False\n",
    "    fig, ax = plot_best_by_type(df_all, df_dataset_grouped_by_type, df_dataset, 'Dataset: {}'.format(name) if use_title else None)\n",
    "    fig.savefig('tmp/results/dataset-{}-best.png'.format(name), dpi = 150)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for with/without labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph_type, df_ in df_all[\n",
    "    (df_all.combined == False) &\n",
    "    (df_all.classifier == 'LinearSVC') &\n",
    "    (df_all.kernel == 'wl') &\n",
    "    (df_all.wl_iteration == wl_iteration) &\n",
    "    (df_all.param_feature_extraction__fast_wl__round_to_decimals == to_decimals)\n",
    "].groupby('type'):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, sharey=True, figsize = EXPORT_FIG_SIZE_BIG)\n",
    "    for (dataset, df), ax in zip(df_.groupby('dataset'), axes.flatten()):\n",
    "        if graph_type == 'cooccurrence':\n",
    "            df = df[(df.window_size == window_size) & (df.words == used_words)]\n",
    "        df = df.set_index('same_label')\n",
    "        std_errs = [df.std_test_f1_macro,  df.std_test_accuracy, df.std_test_precision_macro,  df.std_test_recall_macro]\n",
    "\n",
    "        df = df.rename(columns = RENAME_COLS_MAPPING).sort_index()\n",
    "        df[['accuracy', 'f1', 'precision', 'recall']].plot(kind = 'barh', ax = ax, legend = False, xerr = std_errs)\n",
    "        ax.set_title('Dataset: {}'.format(dataset))\n",
    "        ax.set_ylabel('Ignoring labels')\n",
    "    axes.flatten()[0].legend(loc=\"upper right\")\n",
    "    title = 'graph={}'.format(graph_type)\n",
    "    if graph_type == 'cooccurrence':\n",
    "        title += ' window_size={}'.format(window_size)\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.85)\n",
    "    plt.show()\n",
    "    fig.savefig('tmp/classification_same_label_{}.png'.format(graph_type))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_filter_name, data_filter in [('only-concept-graphs', df_all.type == 'concept_map'), ('only-coocurrence', df_all.type == 'cooccurrence'), ('all', df_all.type != 'YES')]:\n",
    "    for dataset_name, df in df_all[df_all.combined == False][data_filter].groupby('dataset'):\n",
    "        for attr in ['type', 'kernel']:\n",
    "            # Filter out DummyClassifier\n",
    "            df = df[(df.classifier != 'DummyClassifier')]\n",
    "\n",
    "            # Ignore entries that have only one category\n",
    "            if len(df[attr].value_counts().tolist()) <= 1:\n",
    "                continue\n",
    "            \n",
    "            f1_min, f1_max = df.mean_test_f1_macro.min(), df.mean_test_f1_macro.max()\n",
    "            fig, axes = plt.subplots(figsize = EXPORT_FIG_SIZE)\n",
    "            df = df.sort_values(attr)\n",
    "            ax = sns.violinplot(x = attr, y = 'mean_test_f1_macro', data=df, cut = 0, split = True, inner = 'quartile')\n",
    "            ax.set_ylim((0, f1_max + 0.1))\n",
    "            ax.set_ylabel('f1 macro')\n",
    "            fig.suptitle('Result distribution ({})'.format(data_filter_name));\n",
    "            ax.set_title('Dataset: {}, Attribute: {}'.format(dataset_name, attr))\n",
    "            fig.tight_layout()\n",
    "            fig.subplots_adjust(top = 0.85)\n",
    "            fig.savefig('tmp/result-distributions/{}-{}-{}.png'.format(dataset_name, data_filter_name, attr), dpi = EXPORT_DPI)\n",
    "            plt.show()\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot best per parameter value per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs_grouped_by_plot(df_all, groupby):\n",
    "    df_graphs_grouped = df_all[df_all.type != 'text'].groupby('dataset')\n",
    "    \n",
    "    axes = []\n",
    "    for idx, (dataset_name, df_dataset) in enumerate(df_graphs_grouped):\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize = EXPORT_FIG_SIZE)\n",
    "        # Print violinplot of f1, with graph_type as hue\n",
    "        hue = groupby if df_dataset[groupby].value_counts().count() > 1 else None\n",
    "        sns.violinplot(x = 'type', y = 'mean_test_f1_macro', hue= hue , data=df_dataset, cut = 0, split = True, inner = 'quartile', title = dataset_name, ax = ax, legend = True)\n",
    "        ax.set_title('{}'.format(dataset_name))\n",
    "        ax.set_ylabel('f1')\n",
    "        ax.set_xlabel(groupby)\n",
    "        ax.grid('off')\n",
    "        fig.suptitle('')\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(top = 0.86)\n",
    "        fig.savefig('tmp/results/label-importance-{}.png'.format(dataset_name), dpi = EXPORT_DPI)\n",
    "        plt.show()\n",
    "\n",
    "if 1 == 1:\n",
    "    graphs_grouped_by_plot(df_all, 'combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def add(acc, item):\n",
    "    acc += item\n",
    "    return acc\n",
    "\n",
    "def get_vals_for_col(col):\n",
    "    return sorted(df_tmp[col].value_counts().index.tolist())\n",
    "\n",
    "cols = ['combined', 'kernel', 'lemmatized', 'relabeled', 'threshold', 'type', 'window_size', 'wl_iteration', 'words', 'classifier', 'same_label', 'topn']\n",
    "cols = ['type', 'combined', 'kernel', 'wl_iteration', 'same_label', 'dataset']\n",
    "\n",
    "df_tmp = df_all[df_all.dataset == 'ling-spam']\n",
    "\n",
    "vals = [get_vals_for_col(col) for col in cols]\n",
    "val_lenghts = [len(vals_) for vals_ in vals]\n",
    "dim = sum(val_lenghts)\n",
    "vals_flattened = functools.reduce(add, vals, [])\n",
    "\n",
    "best_of_mat = np.zeros((dim, dim), dtype=np.float32)\n",
    "\n",
    "col_counter = 0\n",
    "row_counter = 0\n",
    "\n",
    "for col_idx1, col1 in enumerate(cols):\n",
    "    vals_1 = get_vals_for_col(col1)\n",
    "    col_counter = 0\n",
    "    for col_idx2, col2 in enumerate(cols):\n",
    "        vals_2 = get_vals_for_col(col2)\n",
    "        for idx1, val1 in enumerate(vals_1):\n",
    "            for idx2, val2 in enumerate(vals_2):\n",
    "                best_of = df_tmp[(df_tmp[col1] == val1) & (df_tmp[col2] == val2)]\n",
    "                best_f1 = best_of.mean_test_f1_macro.max()\n",
    "                best_of_mat[row_counter + idx1, col_counter + idx2] = best_f1\n",
    "        col_counter += len(vals_2)\n",
    "    row_counter += len(vals_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(best_of_mat, vals, cols, ax = None, cmap='Blues', divider_color = '#FFFFFF', divider_linewidth = 6, fontdict = {'fontsize': 14, 'weight': 'bold'}):\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    vals_lengths = [len(val) for val in vals]\n",
    "    \n",
    "    # Add labels to graph\n",
    "    for idx, s in enumerate(np.cumsum(val_lenghts)):\n",
    "        for x in ['v' , 'h']:\n",
    "            getattr(plt, 'ax{}line'.format(x))(s - 0.5, color = divider_color, linewidth = divider_linewidth)\n",
    "        \n",
    "        text_offset = ((val_lenghts[idx]) / 2)\n",
    "        \n",
    "        # Add the col labels to the right\n",
    "        ax.text(dim + 0.5, s - text_offset - 0.5, cols[idx], horizontalalignment = 'left', verticalalignment = 'center', fontdict=fontdict)\n",
    "        # Add the col labels to the top\n",
    "        ax.text(s - text_offset - 0.2, - 1, cols[idx], horizontalalignment = 'center', verticalalignment = 'center', fontdict=fontdict)\n",
    "\n",
    "    # Add x- and y-ticks\n",
    "    for x in ['x' , 'y']:\n",
    "        getattr(plt, x + 'ticks')(range(len(vals_flattened)), vals_flattened)\n",
    "\n",
    "    # Rotate x-ticks\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(90)\n",
    "\n",
    "    # Mark cells where no values are available\n",
    "    for row, cell in (zip(*list(np.where(np.isnan(best_of_mat))))):\n",
    "        ax.text(row, cell, 'X', horizontalalignment = 'center', verticalalignment = 'center', fontdict=fontdict)\n",
    "\n",
    "    plt.grid('off')\n",
    "    plt.imshow(best_of_mat, cmap=cmap)\n",
    "    plt.colorbar(fraction=0.04, pad=0.2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (30, 30))\n",
    "#plot(np.tril(best_of_mat), vals, cols, ax)\n",
    "plot(best_of_mat, vals, cols, ax)\n",
    "fig.tight_layout()\n",
    "fig.savefig('tmp/correlations.png', dpi = EXPORT_DPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot performance per dataset and wl_iteration and graph_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gap_to_violin_plot(ax, delta = 0.03):\n",
    "    import matplotlib\n",
    "    # offset stuff\n",
    "    delta = 0.03\n",
    "    for ii, item in enumerate(ax.collections):\n",
    "        # axis contains PolyCollections and PathCollections\n",
    "        if isinstance(item, matplotlib.collections.PolyCollection):\n",
    "            # get path\n",
    "            path, = item.get_paths()\n",
    "            vertices = path.vertices\n",
    "\n",
    "            if ii % 2: # -> to right\n",
    "                vertices[:,0] += delta\n",
    "            else: # -> to left\n",
    "                vertices[:,0] -= delta\n",
    "\n",
    "is_combined = df_all.combined == True\n",
    "\n",
    "for dataset, df_tmp in df_all[(df_all.type != 'text') & (df_all.lemmatized != True) & (is_combined == False)].sort_values('wl_iteration').groupby('dataset'):\n",
    "    fig, ax = plt.subplots()\n",
    "    inner = 'quartile'\n",
    "    ax = sns.violinplot(x = 'wl_iteration', y = 'mean_test_f1_macro', hue = 'type', split = True, data = df_tmp, cut = True, inner = inner, figsize = EXPORT_FIG_SIZE)\n",
    "    \n",
    "    add_gap_to_violin_plot(ax)\n",
    "    \n",
    "    ax.set_ylabel('f1')\n",
    "    ax.set_title(dataset)\n",
    "    ax.figure.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot by parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(df, df_all, title = None, figsize = (10, 8)):\n",
    "    fig, axes_indexed = plt.subplots(nrows = 2, ncols=2, figsize = figsize)\n",
    "\n",
    "    axes = []\n",
    "    for ax_row in axes_indexed:\n",
    "        axes += list(ax_row)\n",
    "    #, 'relabeled'\n",
    "    for val, ax in zip(['wl_iteration', 'window_size', 'words', 'type'], axes):\n",
    "        if len(df.groupby(val).size()) == 0:\n",
    "            continue\n",
    "        grouped = df.groupby(val)\n",
    "        els = df_all.iloc[grouped['mean_test_f1_macro'].idxmax()]\n",
    "        els = els.set_index(val)\n",
    "        els = els.rename(columns = RENAME_COLS_MAPPING)\n",
    "        els[['f1', 'accuracy', 'precision', 'recall']].plot(kind = 'barh', ax = ax, xlim=(0, 2))\n",
    "        ax.set_xticks(np.linspace(0, 1, 11))\n",
    "        ax.grid(axis = 'y')\n",
    "        ax.set_xlim((0, 1.5))\n",
    "    \n",
    "    plt.suptitle(title, size = 18)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.90)\n",
    "    return fig, axes\n",
    "    \n",
    "dpi = 150\n",
    "\n",
    "if 1 == 1:\n",
    "    fig, _  = plot_distributions(df_all, df_all, title = 'Mean over all datasets')\n",
    "    fig.savefig('tmp/results/all.png', dpi = dpi)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    for name, df_dataset in df_all.groupby('dataset'):\n",
    "        if len(df_dataset.type.value_counts()) < 3:\n",
    "            continue\n",
    "        fig, _ = plot_distributions(df_dataset, df_all, title = 'Dataset: {}'.format(name))\n",
    "        fig.savefig('tmp/results/dataset-{}.png'.format(name), dpi = dpi)\n",
    "        plt.show()\n",
    "        plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
