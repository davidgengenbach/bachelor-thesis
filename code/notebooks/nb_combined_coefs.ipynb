{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_prelude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiments\n",
    "import experiments.task_runner\n",
    "from experiments import task_runner, task_helper\n",
    "import sklearn.model_selection\n",
    "from transformers.pipelines.classifiers import get_classifier_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type = 'graph_combined'\n",
    "dataset = 'ng20'\n",
    "graph_type = 'concept-map'\n",
    "version = 'v2'\n",
    "\n",
    "tasks = experiments.get_filtered_tasks(task_type=task_type, dataset=dataset, task_name_filter=version)\n",
    "filtered_tasks = [t for t in tasks if version in t.name]\n",
    "assert len(filtered_tasks) == 1\n",
    "\n",
    "task = filtered_tasks[0]\n",
    "X, Y, estimator, param_grid = task.fn()\n",
    "X, Y = np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, stratify = Y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "param_grid = task_helper.add_classifier_to_params(param_grid)\n",
    "param_grid = dict(param_grid, **dict(\n",
    "    classifier=[sklearn.linear_model.Perceptron()],\n",
    "    classifier__penalty=['l1', 'l2'],\n",
    "    classifier__C=[1e-2, 1e-1],\n",
    "    features__text__vectorizer__vectorizer__binary=[True],\n",
    "    features__fast_wl_pipeline__feature_extraction__feature_extraction__fast_wl__ignore_label_order=[True],\n",
    "    features__fast_wl_pipeline__feature_extraction__feature_extraction__fast_wl__use_early_stopping=[False],\n",
    "    features__fast_wl_pipeline__feature_extraction__feature_extraction__fast_wl__h=[5],\n",
    "))\n",
    "\n",
    "del param_grid['classifier__C']\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "gscv = sklearn.model_selection.GridSearchCV(estimator, param_grid=param_grid, scoring='f1_macro', cv=cv, verbose=2)\n",
    "gscv_result = gscv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.pipelines import pipeline_helper\n",
    "estimators = []\n",
    "NUM_ELEMENTS = len(X_train)\n",
    "#NUM_ELEMENTS = 100\n",
    "\n",
    "for params in sklearn.model_selection.ParameterGrid(param_grid):\n",
    "    print('Starting classification: ')\n",
    "    pprint(pipeline_helper.remove_complex_types_simple(params))\n",
    "    clf = sklearn.base.clone(estimator)\n",
    "    clf.set_params(**params)\n",
    "    clf.fit(X_train[:NUM_ELEMENTS], Y_train[:NUM_ELEMENTS])\n",
    "    print('Predicting')\n",
    "    Y_test_pred = clf.predict(X_test)\n",
    "    f1_score = sklearn.metrics.f1_score(Y_test, Y_test_pred, average='macro')\n",
    "    print(params['classifier__penalty'], f1_score)\n",
    "    estimators.append((params, clf, np.copy(clf.named_steps['classifier'].coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_estimator=estimators[1][1]\n",
    "#clf = used_estimator.named_steps['classifier']\n",
    "# one-vs-rest\n",
    "used_coefs = estimators[1][2]\n",
    "coefs = np.sum(used_coefs, axis = 0)\n",
    "coefs_idx = np.argsort(coefs)\n",
    "\n",
    "def get_fast_wl_vectorizer(pipeline):\n",
    "    return get_feature_transformer(pipeline, 'fast_wl_pipeline').named_steps['feature_extraction'].named_steps['feature_extraction'].named_steps['fast_wl']\n",
    "\n",
    "def get_feature_transformer(pipeline, transformer_name):\n",
    "    return [pipe for name, pipe in pipeline.named_steps['features'].transformer_list if name == transformer_name][0]\n",
    "\n",
    "def get_text_vectorizer(pipeline):\n",
    "    return get_feature_transformer(pipeline, 'text').named_steps['vectorizer'].named_steps['vectorizer']\n",
    "\n",
    "def get_text_features(pipeline):\n",
    "    return get_text_vectorizer(pipeline).vocabulary_\n",
    "\n",
    "text_features = get_text_features(used_estimator)\n",
    "trans_fast_wl = get_fast_wl_vectorizer(used_estimator)\n",
    "len_features_combined = coefs.shape[0]\n",
    "len_text_features = len(text_features)\n",
    "len_graph_features_simple = trans_fast_wl.phi_list[-1].shape[1]\n",
    "len_graph_features = len_features_combined - len_text_features\n",
    "len_graph_fast_wl_iterations = len(trans_fast_wl.phi_list) - 1\n",
    "assert (len_graph_fast_wl_iterations * len_graph_features_simple) == len_graph_features\n",
    "assert len_graph_features + len_text_features == len_features_combined\n",
    "\n",
    "idx_2_text = {idx: text for text, idx in text_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coefs_(coefs, top=100):\n",
    "    coefs_idx = np.argsort(coefs)\n",
    "    highest = coefs_idx[-top - 1:]\n",
    "    lowest = coefs_idx[:top]\n",
    "    highest_vals = coefs[highest]\n",
    "    lowest_vals = coefs[lowest]\n",
    "    fig, ax = plt.subplots()\n",
    "    labels = np.concatenate((highest, lowest))\n",
    "    #labels = ['g' if x > len(text_features) else idx_2_text[x] for x in labels]\n",
    "    labels = ['G' if x > len(text_features) else 'T' for x in labels]\n",
    "    pd.DataFrame(dict(idx=labels, vals=list(highest_vals) + list(lowest_vals))).set_index('idx').sort_values('vals').vals.plot(kind = 'bar', ax = ax)\n",
    "    ax.grid('off')\n",
    "    return fig, ax\n",
    "\n",
    "plot_coefs_(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmaps = ['viridis', 'plasma', 'inferno', 'magma', 'Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds', 'YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu', 'GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn',  'binary', 'gist_yarg', 'gist_gray', 'gray', 'bone', 'pink', 'spring', 'summer', 'autumn', 'winter', 'cool', 'Wistia', 'hot', 'afmhot', 'gist_heat', 'copper']\n",
    "\n",
    "def plot_coefs_heatmap(coefs, log=False, lines = [], cmap = None, fig = None, ax = None):\n",
    "    _coefs = np.copy(coefs)\n",
    "    \n",
    "    size = _coefs.shape[0]\n",
    "    new_size = int(np.floor(np.sqrt(_coefs.shape[0]))) + 1\n",
    "    added = np.power(new_size, 2) - size\n",
    "    _coefs = np.append(_coefs, [0] * added)\n",
    "    _coefs = _coefs.reshape(new_size, -1)\n",
    "    \n",
    "    \n",
    "    if log:\n",
    "        _coefs = np.log(_coefs)\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    fig = ax.get_figure()\n",
    "    img = ax.imshow(_coefs, cmap=plt.get_cmap(cmap))\n",
    "    ax.grid('off')\n",
    "    \n",
    "    for line_y in lines:\n",
    "        ax.axhline(line_y / new_size)\n",
    "    \n",
    "    fig.colorbar(img)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "lines = []\n",
    "lines.append(len_text_features)\n",
    "lines += [len_text_features + ((i + 1) * len_graph_features_simple) for i in range(len_graph_fast_wl_iterations)]\n",
    "for cmap in cmaps:\n",
    "    ax = plot_coefs_heatmap(coefs, lines = lines, cmap=cmap)\n",
    "    ax.set_title(cmap)\n",
    "    ax.get_figure().tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lens = [0] + lines\n",
    "df_features = pd.DataFrame(columns = ['label', 'coef'])\n",
    "for idx, (start, end) in enumerate(zip(features_lens[:-1], features_lens[1:])):\n",
    "    label = 'text' if idx == 0 else 'graph'#'graph_{}'.format(idx)\n",
    "    els = coefs[start:end]\n",
    "    df_ = pd.DataFrame(dict(label = [label] * len(els), coef = els))\n",
    "    df_features = pd.concat([df_features, df_])\n",
    "\n",
    "hist, bin_edges = np.histogram(df_features.coef, bins = 300)\n",
    "#fig, axes = plt.subplots(ncols = len(df_features.groupby('label')))\n",
    "fig, ax = plt.subplots(figsize = (EXPORT_FIG_WIDTH_BIG, EXPORT_FIG_HEIGHT_BIG - 2))\n",
    "for (feature_label, df_) in df_features.groupby('label'):\n",
    "    df_.coef.plot(kind='hist', ax = ax, label = feature_label, logy = True, alpha = 0.7, bins = bin_edges, legend = True, stacked = True)\n",
    "ax.set_xlabel('SVM coefficient value')\n",
    "#ax.set_title('Histogram of SVM coefficients trained with combined features (text + graph)\\n(Dataset: {})'.format(dataset))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum_of_coefs(indices):\n",
    "    vals = coefs[indices]\n",
    "    vals_plus = vals[vals > 0]\n",
    "    vals_minus = vals[vals < 0]\n",
    "    return np.sum(vals_plus), np.sum(vals_minus)\n",
    "\n",
    "feature_range = [('text', len_text_features)] + [('graph_{}'.format(i + 1), len_graph_features_simple) for i in range(len_graph_fast_wl_iterations)]\n",
    "\n",
    "for params, clf, coefs in estimators:\n",
    "    current = 0\n",
    "    vals = []\n",
    "    for name, num_features in feature_range:\n",
    "        num_features -= 1\n",
    "        end = current + num_features\n",
    "        vals.append(((current, end), get_sum_of_coefs(range(current, end))))\n",
    "        current = end\n",
    "\n",
    "    data = collections.defaultdict(lambda: [])\n",
    "    for (name, num_features), ((start, end), (val_plus, val_minus)) in zip(feature_range, vals):\n",
    "        data['type'].append(params['classifier__'])\n",
    "        data['label'].append(name)\n",
    "        data['plus'].append(val_plus)\n",
    "        data['minus'].append(val_minus)\n",
    "        data['start'].append(start)\n",
    "        data['end'].append(end)\n",
    "        data['num_features'].append(num_features)\n",
    "    \n",
    "df_vals = pd.DataFrame(data).set_index('label')\n",
    "df_vals['absolute'] = df_vals.minus.abs() + df_vals.plus\n",
    "df_vals['val_per_feature'] = df_vals.absolute / df_vals.num_features\n",
    "df_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2)\n",
    "\n",
    "\n",
    "for ax, title, df_ in zip(axes, ['l1 regularization', 'l2 regularization'], [df_vals_l1, df_vals_l2]):\n",
    "    if len(df_[df_.index == 'graph_all']): continue\n",
    "    graph_features = df_[df_.index.str.contains('graph')]\n",
    "    sum_ = graph_features.sum().to_frame().T\n",
    "    #display(df_.append(graph_features.sum(), ignore_index=False))\n",
    "    sum_.index = ['graph_all']\n",
    "    display()\n",
    "    df_ = df_.append(sum_).sort_index()\n",
    "    df_.absolute.plot(kind='barh', ax = ax, log=True, title=title)\n",
    "    for idx, (label, df__) in enumerate(df_.iterrows()):\n",
    "        val = df__.absolute\n",
    "        ax.text(val * 1.2, idx, '{:.2f}'.format(val), fontdict=dict(horizontalalignment='left', verticalalignment='center'))\n",
    "    \n",
    "for ax in axes:\n",
    "    ax.set_xlabel('sum of absolute coefs values (log)')\n",
    "\n",
    "fig.suptitle('Sum of absolute coef values per feature type (Classifier: Perceptron)')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.87, hspace=0.6)\n",
    "save_fig(fig, 'combined_coefs_l1_l2_regularization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text, Y_text = dataset_helper.get_dataset('ling-spam')\n",
    "features = [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]\n",
    "labels = [1, 2, 3, 4]\n",
    "clf = sklearn.svm.LinearSVC(penalty='l1')\n",
    "clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.groupby('label').coef.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steps(e):\n",
    "    for x in ['steps', 'transformer_list']:\n",
    "        if hasattr(e, x):\n",
    "            return getattr(e, x)\n",
    "    return []\n",
    "\n",
    "def print_pipeline(pipeline, depth = 0, delim = ' ' * 3, print_type = True):\n",
    "    steps = get_steps(pipeline)\n",
    "    for name, step in steps:\n",
    "        print('{} {:40} {}'.format(delim * (depth + 1), name, '({})'.format(type(step).__name__) if print_type else ''))\n",
    "        print_pipeline(step, depth = depth + 1, delim = delim)\n",
    "\n",
    "print_pipeline(estimator)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
