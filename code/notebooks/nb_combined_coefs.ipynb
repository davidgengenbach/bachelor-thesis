{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_prelude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiments\n",
    "import experiments.task_runner\n",
    "import sklearn.model_selection\n",
    "from transformers.pipelines.classifiers import get_classifier_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type = 'graph_combined'\n",
    "dataset = 'ng20'\n",
    "graph_type = 'concept-map'\n",
    "version = 'v2'\n",
    "\n",
    "tasks = experiments.get_filtered_tasks(task_type=task_type, dataset='ng20')\n",
    "filtered_tasks = [t for t in tasks if version in t.name]\n",
    "assert len(filtered_tasks) == 1\n",
    "\n",
    "task = filtered_tasks[0]\n",
    "X, Y, estimator, param_grid = task.fn()\n",
    "X, Y = np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = add_classifier_to_params(param_grid)\n",
    "params = list(sklearn.model_selection.ParameterGrid(param_grid))\n",
    "param = [x for x in params if x['features__text__vectorizer__vectorizer__binary']][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, stratify = Y, test_size = 0.2, random_state = 42)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_params(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = sklearn.model_selection.StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "result = sklearn.model_selection.cross_val_score(estimator, X, y=Y, cv=cv, scoring = 'f1_macro')\n",
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = estimator.named_steps['classifier']\n",
    "# one-vs-rest\n",
    "coefs = np.sum(clf.coef_, axis = 0)\n",
    "coefs_idx = np.argsort(coefs)\n",
    "\n",
    "def get_fast_wl_vectorizer(estimator):\n",
    "    return get_feature_transformer(estimator, 'fast_wl_pipeline').named_steps['feature_extraction'].named_steps['feature_extraction'].named_steps['fast_wl']\n",
    "\n",
    "def get_feature_transformer(estimator, transformer_name):\n",
    "    return [pipe for name, pipe in estimator.named_steps['features'].transformer_list if name == transformer_name][0]\n",
    "\n",
    "def get_text_vectorizer(pipeline):\n",
    "    return get_feature_transformer(estimator, 'text').named_steps['vectorizer'].named_steps['vectorizer']\n",
    "\n",
    "def get_text_features(pipeline):\n",
    "    return get_text_vectorizer(pipeline).vocabulary_\n",
    "\n",
    "text_features = get_text_features(estimator)\n",
    "trans_fast_wl = get_fast_wl_vectorizer(estimator)\n",
    "\n",
    "len_features_combined = coefs.shape[0]\n",
    "len_text_features = len(text_features)\n",
    "len_graph_features_simple = trans_fast_wl.phi_list[-1].shape[1]\n",
    "len_graph_fast_wl_iterations = len(trans_fast_wl.phi_list) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_2_text = {idx: text for text, idx in text_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 100\n",
    "highest = coefs_idx[-top - 1:]\n",
    "lowest = coefs_idx[:top]\n",
    "highest_vals = coefs[highest]\n",
    "lowest_vals = coefs[lowest]\n",
    "fig, ax = plt.subplots()\n",
    "labels = np.concatenate((highest, lowest))\n",
    "labels = ['g' if x > len(text_features) else idx_2_text[x] for x in labels]\n",
    "pd.DataFrame(dict(idx=labels, vals=list(highest_vals) + list(lowest_vals))).set_index('idx').sort_values('vals').vals.plot(kind = 'bar', ax = ax)\n",
    "ax.grid('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmaps = ['viridis', 'plasma', 'inferno', 'magma', 'Greys', 'Purples', 'Blues', 'Greens', 'Oranges', 'Reds', 'YlOrBr', 'YlOrRd', 'OrRd', 'PuRd', 'RdPu', 'BuPu', 'GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn',  'binary', 'gist_yarg', 'gist_gray', 'gray', 'bone', 'pink', 'spring', 'summer', 'autumn', 'winter', 'cool', 'Wistia', 'hot', 'afmhot', 'gist_heat', 'copper']\n",
    "\n",
    "def plot_coefs(coefs, log=False, lines = [], cmap = None, fig = None, ax = None):\n",
    "    _coefs = np.copy(coefs)\n",
    "    \n",
    "    size = _coefs.shape[0]\n",
    "    new_size = int(np.floor(np.sqrt(_coefs.shape[0]))) + 1\n",
    "    added = np.power(new_size, 2) - size\n",
    "    _coefs = np.append(_coefs, [0] * added)\n",
    "    _coefs = _coefs.reshape(new_size, -1)\n",
    "    \n",
    "    \n",
    "    if log:\n",
    "        _coefs = np.log(_coefs)\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    fig = ax.get_figure()\n",
    "    img = ax.imshow(_coefs, cmap=plt.get_cmap(cmap))\n",
    "    ax.grid('off')\n",
    "    \n",
    "    for line_y in lines:\n",
    "        ax.axhline(line_y / new_size)\n",
    "    \n",
    "    fig.colorbar(img)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "lines = []\n",
    "lines.append(len_text_features)\n",
    "lines += [len_text_features + ((i + 1) * len_graph_features_simple) for i in range(len_graph_fast_wl_iterations)]\n",
    "for cmap in cmaps:\n",
    "    ax = plot_coefs(coefs, lines = lines, cmap=cmap)\n",
    "    ax.set_title(cmap)\n",
    "    ax.get_figure().tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lens = [0] + lines\n",
    "df_features = pd.DataFrame(columns = ['label', 'coef'])\n",
    "for idx, (start, end) in enumerate(zip(features_lens[:-1], features_lens[1:])):\n",
    "    label = 'text' if idx == 0 else 'graph'#'graph_{}'.format(idx)\n",
    "    els = coefs[start:end]\n",
    "    df_ = pd.DataFrame(dict(label = [label] * len(els), coef = els))\n",
    "    df_features = pd.concat([df_features, df_])\n",
    "\n",
    "hist, bin_edges = np.histogram(df_features.coef, bins = 300)\n",
    "#fig, axes = plt.subplots(ncols = len(df_features.groupby('label')))\n",
    "fig, ax = plt.subplots(figsize = (EXPORT_FIG_WIDTH_BIG, EXPORT_FIG_HEIGHT_BIG - 2))\n",
    "for (feature_label, df_) in df_features.groupby('label'):\n",
    "    df_.coef.plot(kind='hist', ax = ax, label = feature_label, logy = True, alpha = 0.7, bins = bin_edges, legend = True, stacked = True)\n",
    "ax.set_xlabel('SVM coefficient value')\n",
    "#ax.set_title('Histogram of SVM coefficients trained with combined features (text + graph)\\n(Dataset: {})'.format(dataset))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum_of_coefs(indices):\n",
    "    vals = coefs[indices]\n",
    "    vals_plus = vals[vals > 0]\n",
    "    vals_minus = vals[vals < 0]\n",
    "    return np.sum(vals_plus), np.sum(vals_minus)\n",
    "\n",
    "# Text\n",
    "vals_plus_t, vals_minus_t = get_sum_of_coefs(range(len_text_features))\n",
    "vals_plus_g, vals_minus_g = get_sum_of_coefs(range(len_text_features, len(coefs)))\n",
    "\n",
    "df_vals = pd.DataFrame([\n",
    "    dict(label = 'text', plus = vals_plus_t, minus = vals_minus_t, num_features = len_text_features),\n",
    "    dict(label = 'graph', plus = vals_plus_g, minus = vals_minus_g, num_features = len_features_combined - len_text_features)\n",
    "]).set_index('label')\n",
    "df_vals['absolute'] = df_vals.minus.abs() + df_vals.plus\n",
    "df_vals['val_per_feature'] = df_vals.absolute / df_vals.num_features\n",
    "df_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.groupby('label').coef.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steps(e):\n",
    "    for x in ['steps', 'transformer_list']:\n",
    "        if hasattr(e, x):\n",
    "            return getattr(e, x)\n",
    "    return []\n",
    "\n",
    "def print_pipeline(pipeline, depth = 0, delim = ' ' * 3, print_type = True):\n",
    "    steps = get_steps(pipeline)\n",
    "    for name, step in steps:\n",
    "        print('{} {:40} {}'.format(delim * (depth + 1), name, '({})'.format(type(step).__name__) if print_type else ''))\n",
    "        print_pipeline(step, depth = depth + 1, delim = delim)\n",
    "\n",
    "print_pipeline(estimator)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
