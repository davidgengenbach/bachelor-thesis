{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics about WL similarities per iteration\n",
    "\n",
    "Following are statistics about concept maps WL similarities, ie. how many matches there have been per iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_prelude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob('data/CACHE/*splitted*.npy'):\n",
    "    filename = file.split('/')[-1]\n",
    "    if filename in data: continue\n",
    "    with open(file, 'rb') as f:\n",
    "        res = pickle.load(f)\n",
    "    assert len(res) == 6\n",
    "    data[filename] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_data = collections.defaultdict(dict)\n",
    "for file, res in helper.log_progress(data.items()):\n",
    "    phi_train, phi_test, X_train, X_test, Y_train, Y_test = res\n",
    "    num_iterations = len(phi_train)\n",
    "    assert len(phi_train) == len(phi_test)\n",
    "    print(file)\n",
    "    for h, (phi_te, phi_tr) in enumerate(zip(phi_test, phi_train)):\n",
    "        assert phi_te.shape[1] == phi_tr.shape[1]\n",
    "        sum_data[file][h] = phi_te.dot(phi_tr.T).sum()\n",
    "        gc.collect()\n",
    "        print('\\th={}'.format(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(sum_data).unstack().to_frame('gram_sum').unstack()\n",
    "for a, b in [(1, 0), (2, 1)]:\n",
    "    df['ratio_{}_{}'.format(a, b)] = df['gram_sum', a] / df['gram_sum', b]\n",
    "df['same_label'] = df.index.str.contains('same-label')\n",
    "df['dataset'] = df.index.map(filename_utils.get_dataset_from_filename)\n",
    "df.set_index(['dataset', 'same_label'], inplace=True)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
