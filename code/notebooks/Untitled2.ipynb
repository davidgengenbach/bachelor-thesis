{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_prelude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_timestamps(t, width=30, only_total=False):\n",
    "    from utils import time_utils\n",
    "    timestamps = sorted(t.items(), key=lambda x: x[1])\n",
    "    print('Total: {}'.format(time_utils.seconds_to_human_readable(timestamps[-1][1] - timestamps[0][1])))\n",
    "    if only_total: return\n",
    "    for idx, (name, time_) in enumerate(timestamps[:-1]):\n",
    "        next_time = timestamps[idx + 1][1]\n",
    "        print(name.center(width))\n",
    "        print('|'.center(width))\n",
    "        print(time_utils.seconds_to_human_readable(next_time - time_).center(width))\n",
    "        print('|'.center(width))\n",
    "    print(timestamps[-1][0].center(width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "for idx, df_ in df[(df.type == 'concept_map')].iterrows():\n",
    "    filename = df_.filename\n",
    "    if filename in filenames: continue\n",
    "    filenames.append(filename)\n",
    "    print(str(idx).center(4), filename)\n",
    "    timestamps = df_.timestamps\n",
    "    print_timestamps(timestamps, only_total=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_timestamps(df.loc[252].timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_helper.save_experiment_params_as_experiment_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_files = glob('data/results/201*/*nested*.npy')\n",
    "for f in nested_files:\n",
    "    filename = filename_utils.get_filename_only(f)\n",
    "    print(filename)\n",
    "    res = dataset_helper.get_dataset_cached(f, check_validity=False)['results']\n",
    "    keys = [k for k in res.keys() if k.startswith('test_') or k.startswith('train_') or k.startswith('fit_')]\n",
    "    other_keys = [k for k in res.keys() if k not in keys]\n",
    "    for k in keys:\n",
    "        if 'test' not in k or 'f1' not in k: continue\n",
    "        val = res[k]\n",
    "        assert isinstance(val, np.ndarray)\n",
    "        assert len(val)\n",
    "        print('{:30} {:.3f} {:.3f}'.format(k, np.mean(val), np.std(val)))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
