{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_prelude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_data(prediction_file):\n",
    "    prediction = list(results_helper.get_predictions(filenames=[prediction_file]))\n",
    "    assert len(prediction) == 1\n",
    "    filename, prediction = prediction[0]\n",
    "    prediction = prediction['results']\n",
    "    return pd.DataFrame(prediction)\n",
    "\n",
    "def get_graph_prediction_data(file):\n",
    "    df = get_prediction_data(file)\n",
    "    df['X_test_undirected'] = df.X_test.apply(nx.Graph)\n",
    "    df['edge_labels'] = df.X_test.apply(lambda x: [data['name'] for _, _, data in x.edges(data=True)])\n",
    "    df['node_labels'] = df.X_test.apply(nx.nodes)\n",
    "    df['num_nodes'] = df.X_test.apply(nx.number_of_nodes)\n",
    "    df['num_edges'] = df.X_test.apply(nx.number_of_edges)\n",
    "    df['num_nodes_plus_edges'] = df.num_nodes + df.num_edges\n",
    "    df['num_nodes_div_num_edges'] =  df.num_nodes / df.num_edges\n",
    "    df['num_connected_components'] = df.X_test_undirected.apply(nx.number_connected_components)\n",
    "    df['num_nodes_div_num_connected_components'] = df.num_nodes / df.num_connected_components\n",
    "    df['accuracy'] = df.apply(lambda x: 1 if x.Y_pred == x.Y_real else 0, axis=1)\n",
    "    return df\n",
    "\n",
    "def get_text_prediction_data(file):\n",
    "    df_text = get_prediction_data(file)\n",
    "    df_text['num_words'] = df_text.X_test.apply(lambda x: len(x.split()))\n",
    "    df_text['doc_length'] = df_text.X_test.apply(lambda x: len(x))\n",
    "    df_text['accuracy'] = df.apply(lambda x: 1 if x.Y_pred == x.Y_real else 0, axis=1)\n",
    "    return df_text\n",
    "\n",
    "def get_corr(df, columns, method='spearman'):\n",
    "    mat = df[columns].corr(method='spearman').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "    return mat\n",
    "\n",
    "\n",
    "data = collections.defaultdict(list)\n",
    "for DATASET in dataset_helper.get_dataset_names_with_concept_map():\n",
    "    GRAPH_FILE = 'result___{}__graph__dataset_graph_concept_map_{}-v3.npy'.format(DATASET, DATASET)\n",
    "    TEXT_FILE = 'result___{}__text.npy'.format(DATASET)\n",
    "\n",
    "    df = get_graph_prediction_data(GRAPH_FILE)\n",
    "    df['dataset'] = DATASET\n",
    "    df_text = get_text_prediction_data(TEXT_FILE)\n",
    "    df_text['dataset'] = DATASET\n",
    "    \n",
    "    mat = get_corr(df, columns=['num_nodes', 'num_connected_components', 'accuracy'])\n",
    "    mat_text = get_corr(df_text, columns=['num_words', 'accuracy'])\n",
    "    \n",
    "    correlation_graph = mat.loc['num_nodes', 'accuracy']\n",
    "    correlation_text = mat_text.loc['num_words', 'accuracy']\n",
    "    \n",
    "    data['dataset'].append(DATASET)\n",
    "    data['correlation_graph'].append(correlation_graph)\n",
    "    data['correlation_text'].append(correlation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = pd.DataFrame(data).set_index('dataset')\n",
    "print(df_corr.to_latex())\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMAP = 'inferno_r'\n",
    "\n",
    "columns=['num_nodes', 'num_connected_components', 'accuracy']\n",
    "mat = df[columns].corr(method='spearman').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "im = ax.matshow(mat, cmap=plt.get_cmap(CMAP))\n",
    "\n",
    "label_lookup = [\n",
    "    '# nodes', '# c. components', 'accuracy'\n",
    "]\n",
    "\n",
    "for x in ['x', 'y']:\n",
    "    getattr(ax, 'set_{}ticks'.format(x))([i for i in range(len(label_lookup))])\n",
    "    rotation = 0 if x == 'x' else 0\n",
    "    getattr(ax, 'set_{}ticklabels'.format(x))(label_lookup, rotation=rotation)\n",
    "ax.grid('off')\n",
    "fig.colorbar(im, fraction=0.0456, pad=0.04)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['num_nodes', 'num_connected_components', 'acurracy']\n",
    "mat = df[columns].corr(method='spearman').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_per_quantile(df, attr, q=10, title=None, ax = None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize = (11, 4))\n",
    "    df[attr + '_bins'] = pd.qcut(df[attr], q=q, duplicates='drop')\n",
    "    data = collections.defaultdict(list)\n",
    "    for interval, df_ in df.groupby(attr + '_bins'):\n",
    "        score = get_score(df_)\n",
    "        data['interval'].append(interval)\n",
    "        data['f1'].append(score)\n",
    "    df_ = pd.DataFrame(data).set_index('interval')\n",
    "    df_['interval_mean'] = df_.index.map(lambda x: x.mid)\n",
    "    df_.set_index('interval_mean').plot(kind='bar', ax = ax, legend=False)\n",
    "    labels = df_.interval_mean.values\n",
    "    ax.set_xticklabels(['{:.0f}'.format(x) for x in labels])\n",
    "    #ax.set_xticklabels(labels, rotation=0)\n",
    "    ax.set_xlabel('Decile')\n",
    "    ax.set_ylabel('F1 macro')\n",
    "    ax.set_title(attr if title is None else title)\n",
    "    ax.get_figure().tight_layout()\n",
    "    return ax\n",
    "\n",
    "def get_score(df_):\n",
    "    y_true, y_pred = df_.Y_real.values, df_.Y_pred.values\n",
    "    f1 = sklearn.metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    return f1\n",
    "\n",
    "\n",
    "for attr in ['num_edges', 'num_nodes', 'num_nodes_div_num_connected_components', 'num_nodes_div_num_edges', 'num_connected_components', 'num_nodes_plus_edges']:\n",
    "    ax = get_score_per_quantile(df, attr)\n",
    "    fig = ax.get_figure()\n",
    "    save_fig(fig, 'graph_binning_{}'.format(attr), folder='tmp/graph_sizes')\n",
    "\n",
    "for attr in ['num_words']:\n",
    "    ax = get_score_per_quantile(df_text, attr)\n",
    "    fig = ax.get_figure()\n",
    "    save_fig(fig, 'text_binning_{}'.format(attr), folder='tmp/graph_sizes')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
