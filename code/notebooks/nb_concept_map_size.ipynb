{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_prelude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_helper.get_dataset_names_with_concept_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_data(prediction_file):\n",
    "    prediction = list(results_helper.get_predictions(filenames=[prediction_file]))\n",
    "    assert len(prediction) == 1\n",
    "    filename, prediction = prediction[0]\n",
    "    prediction = prediction['results']['results']\n",
    "    return pd.DataFrame(prediction)\n",
    "\n",
    "DATASET = 'ng20'\n",
    "\n",
    "GRAPH_FILE = 'result___{}__graph__dataset_graph_concept_map_{}-v3.npy'.format(DATASET, DATASET)\n",
    "TEXT_FILE = 'result___{}__text.npy'.format(DATASET)\n",
    "\n",
    "df = get_prediction_data(GRAPH_FILE)\n",
    "df['X_test_undirected'] = df.X_test.apply(nx.Graph)\n",
    "df['num_nodes'] = df.X_test.apply(nx.number_of_nodes)\n",
    "df['num_edges'] = df.X_test.apply(nx.number_of_edges)\n",
    "df['num_nodes_plus_edges'] = df.num_nodes + df.num_edges\n",
    "df['num_nodes_div_num_edges'] =  df.num_nodes / df.num_edges\n",
    "df['num_connected_components'] = df.X_test_undirected.apply(nx.number_connected_components)\n",
    "df['num_nodes_div_num_connected_components'] = df.num_nodes / df.num_connected_components\n",
    "\n",
    "df_text = get_prediction_data(TEXT_FILE)\n",
    "df_text['num_words'] = df_text.X_test.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_per_quantile(df, attr, q=10, ax = None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize = (11, 4))\n",
    "    df[attr + '_bins'] = pd.qcut(df[attr], q=q, duplicates='drop')\n",
    "    data = collections.defaultdict(list)\n",
    "    for interval, df_ in df.groupby(attr + '_bins'):\n",
    "        score = get_score(df_)\n",
    "        data['interval'].append(interval)\n",
    "        data['f1'].append(score)\n",
    "    df_ = pd.DataFrame(data).set_index('interval')\n",
    "    df_['interval_mean'] = df_.index.map(lambda x: x.mid)\n",
    "    df_.set_index('interval_mean').plot(kind='bar', ax = ax, legend=False)\n",
    "    labels = df_.interval_mean.values\n",
    "    ax.set_xticklabels(['{:.0f}'.format(x) for x in labels])\n",
    "    #ax.set_xticklabels(labels, rotation=0)\n",
    "    ax.set_xlabel('Decile')\n",
    "    ax.set_ylabel('F1 macro')\n",
    "    ax.set_title(attr)\n",
    "    ax.get_figure().tight_layout()\n",
    "    return ax\n",
    "\n",
    "def get_score(df_):\n",
    "    y_true, y_pred = df_.Y_real.values, df_.Y_pred.values\n",
    "    f1 = sklearn.metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    return f1\n",
    "\n",
    "for attr in ['num_edges', 'num_nodes', 'num_nodes_div_num_connected_components', 'num_nodes_div_num_edges', 'num_connected_components', 'num_nodes_plus_edges']:\n",
    "    get_score_per_quantile(df, attr)\n",
    "    \n",
    "for attr in ['num_words']:\n",
    "    get_score_per_quantile(df_text, attr)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
