{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_prelude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_data(prediction_file):\n",
    "    prediction = list(results_helper.get_predictions(filenames=[prediction_file]))\n",
    "    assert len(prediction) == 1, 'Could not find prediction file: {}'.format(prediction_file)\n",
    "    filename, prediction = prediction[0]\n",
    "    prediction = prediction['results']\n",
    "    return pd.DataFrame(prediction)\n",
    "\n",
    "def get_graph_prediction_data(file):\n",
    "    df = get_prediction_data(file)\n",
    "    df['X_test_undirected'] = df.X_test.apply(nx.Graph)\n",
    "    df['edge_labels'] = df.X_test.apply(lambda x: [data['name'] for _, _, data in x.edges(data=True)])\n",
    "    df['node_labels'] = df.X_test.apply(nx.nodes)\n",
    "    df['num_nodes'] = df.X_test.apply(nx.number_of_nodes)\n",
    "    df['num_edges'] = df.X_test.apply(nx.number_of_edges)\n",
    "    df['num_nodes_plus_edges'] = df.num_nodes + df.num_edges\n",
    "    df['num_nodes_div_num_edges'] =  df.num_nodes / df.num_edges\n",
    "    df['num_connected_components'] = df.X_test_undirected.apply(nx.number_connected_components)\n",
    "    df['num_nodes_div_num_connected_components'] = df.num_nodes / df.num_connected_components\n",
    "    df['accuracy'] = df.apply(lambda x: 1 if x.Y_pred == x.Y_real else 0, axis=1)\n",
    "    return df\n",
    "\n",
    "def get_text_prediction_data(file):\n",
    "    df_text = get_prediction_data(file)\n",
    "    df_text['num_words'] = df_text.X_test.apply(lambda x: len(x.split()))\n",
    "    df_text['doc_length'] = df_text.X_test.apply(lambda x: len(x))\n",
    "    df_text['accuracy'] = df.apply(lambda x: 1 if x.Y_pred == x.Y_real else 0, axis=1)\n",
    "    return df_text\n",
    "\n",
    "def get_corr(df, columns, method='spearman'):\n",
    "    mat_spearman = df[columns].corr(method='spearman').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "    mat_pearson = df[columns].corr(method='pearson').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "    return mat_spearman, mat_pearson\n",
    "\n",
    "\n",
    "data = collections.defaultdict(list)\n",
    "for DATASET in dataset_helper.get_dataset_names_with_concept_map():\n",
    "    GRAPH_FILE = 'result___experiment_graphs_plain__{}__graph__dataset_graph_concept_map_{}-v3.npy'.format(DATASET, DATASET)\n",
    "    TEXT_FILE = 'result___experiment_text_plain__{}__text__text_{}.npy'.format(DATASET, DATASET)\n",
    "    df = get_graph_prediction_data(GRAPH_FILE)\n",
    "    df['dataset'] = DATASET\n",
    "    df_text = get_text_prediction_data(TEXT_FILE)\n",
    "    df_text['dataset'] = DATASET\n",
    "    \n",
    "    mat, mat_pearson = get_corr(df, columns=['num_nodes', 'num_connected_components', 'accuracy'])\n",
    "    mat_text, mat_text_pearson = get_corr(df_text, columns=['num_words', 'accuracy'])\n",
    "    \n",
    "    correlation_graph = mat.loc['num_nodes', 'accuracy']\n",
    "    correlation_graph_pearson = mat_pearson.loc['num_nodes', 'accuracy']\n",
    "    correlation_text = mat_text.loc['num_words', 'accuracy']\n",
    "    correlation_text_pearson = mat_text_pearson.loc['num_words', 'accuracy']\n",
    "    \n",
    "    data['dataset'].append(DATASET)\n",
    "    data['correlation_graph'].append(correlation_graph)\n",
    "    data['correlation_text'].append(correlation_text)\n",
    "    data['correlation_graph_pearson'].append(correlation_graph_pearson)\n",
    "    data['correlation_text_pearson'].append(correlation_text_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = pd.DataFrame(data).set_index('dataset')\n",
    "print(df_corr.to_latex())\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMAP = 'inferno_r'\n",
    "\n",
    "columns=['num_nodes', 'num_connected_components', 'accuracy']\n",
    "mat = df[columns].corr(method='spearman').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "im = ax.matshow(mat, cmap=plt.get_cmap(CMAP))\n",
    "\n",
    "label_lookup = [\n",
    "    '# nodes', '# c. components', 'accuracy'\n",
    "]\n",
    "\n",
    "for x in ['x', 'y']:\n",
    "    getattr(ax, 'set_{}ticks'.format(x))([i for i in range(len(label_lookup))])\n",
    "    rotation = 0 if x == 'x' else 0\n",
    "    getattr(ax, 'set_{}ticklabels'.format(x))(label_lookup, rotation=rotation)\n",
    "ax.grid('off')\n",
    "fig.colorbar(im, fraction=0.0456, pad=0.04)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['num_nodes', 'num_connected_components', 'acurracy']\n",
    "mat = df[columns].corr(method='spearman').dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_score_per_quantile(df_, attr, q=10, title=None, ax = None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize = (11, 4))\n",
    "    df_.plot(kind='bar', ax = ax, legend=False)\n",
    "    labels = df_.interval_mean.values\n",
    "    ax.set_xticklabels(['{:.0f}'.format(x) for x in labels])\n",
    "    #ax.set_xticklabels(labels, rotation=0)\n",
    "    ax.set_xlabel('Decile')\n",
    "    ax.set_ylabel('F1 macro')\n",
    "    ax.set_title(attr if title is None else title)\n",
    "    ax.get_figure().tight_layout()\n",
    "    return ax\n",
    "\n",
    "def get_score_per_quantile(df, attr, q=10, title=None, ax = None):\n",
    "    df[attr + '_bins'] = pd.qcut(df[attr], q=q, duplicates='drop')\n",
    "    data = collections.defaultdict(list)\n",
    "    for interval, df_ in df.groupby(attr + '_bins'):\n",
    "        score = get_score(df_)\n",
    "        data['interval'].append(interval)\n",
    "        data['f1'].append(score)\n",
    "    df_ = pd.DataFrame(data).set_index('interval')\n",
    "    df_['interval_mean'] = df_.index.map(lambda x: x.mid)\n",
    "    #df_ = df_.set_index('interval_mean')\n",
    "    return df_\n",
    "\n",
    "def get_score(df_):\n",
    "    y_true, y_pred = df_.Y_real.values, df_.Y_pred.values\n",
    "    f1 = sklearn.metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    return f1\n",
    "\n",
    "ATTRS = ['num_edges', 'num_nodes', 'num_nodes_div_num_connected_components', 'num_nodes_div_num_edges', 'num_connected_components', 'num_nodes_plus_edges']\n",
    "ATTRS = ['num_nodes']\n",
    "\n",
    "TEXT_ATTRS = ['num_words']\n",
    "\n",
    "Q = 4\n",
    "\n",
    "def print_latex(df, float_format='%.3f'):\n",
    "    text = df.to_latex(float_format=float_format)\n",
    "    return text.replace('.999', '')\n",
    "\n",
    "data = collections.defaultdict(list)\n",
    "for DATASET in dataset_helper.get_dataset_names_with_concept_map():\n",
    "    GRAPH_FILE = 'result___experiment_graphs_plain__{}__graph__dataset_graph_concept_map_{}-v3.npy'.format(DATASET, DATASET)\n",
    "    TEXT_FILE = 'result___experiment_text_plain__{}__text__text_{}.npy'.format(DATASET, DATASET)\n",
    "    df = get_graph_prediction_data(GRAPH_FILE)\n",
    "    df['dataset'] = DATASET\n",
    "    df_text = get_text_prediction_data(TEXT_FILE)\n",
    "    df_text['dataset'] = DATASET\n",
    "    print(DATASET)\n",
    "    data['dataset'].append(DATASET)\n",
    "    \n",
    "    for attr in ATTRS:\n",
    "        df_ = get_score_per_quantile(df, attr, q=Q)\n",
    "        df_ = df_.T.loc['f1']\n",
    "        data['graph_bins'].append(df_.index.values)\n",
    "        data['graph_vals'].append(df_.values)\n",
    "        print(print_latex(df_.to_frame().T).replace('\\\\', ''))\n",
    "\n",
    "    for attr in TEXT_ATTRS:\n",
    "        df_ = get_score_per_quantile(df_text, attr, q=Q)\n",
    "        df_ = df_.T.loc['f1']\n",
    "        data['text_bins'].append(df_.index.values)\n",
    "        data['text_vals'].append(df_.values)\n",
    "        print(print_latex(df_.to_frame().T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).set_index('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'\n",
    "'"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
