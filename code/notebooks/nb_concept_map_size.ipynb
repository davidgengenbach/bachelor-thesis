{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_prelude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n- '.join(sorted(dataset_helper.get_dataset_names_with_concept_map())))\n",
    "#experiment_helper.save_experiment_params_as_experiment_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=nx.Graph()\n",
    "\n",
    "\n",
    "for file in dataset_helper.get_all_cached_graph_datasets(graph_type=TYPE_CONCEPT_MAP):\n",
    "    dataset = filename_utils.get_dataset_from_filename(file)\n",
    "    X, Y = dataset_helper.get_dataset_cached(file)\n",
    "    X = graph_helper.get_graphs_only(X)\n",
    "    directed = X[0].is_directed()\n",
    "    print('{:30} directed: {}'.format(dataset, directed))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = X[0]\n",
    "adj, labels = graph_helper.convert_graphs_to_adjs_tuples([g], copy=True)[0]\n",
    "#np.array_equiv(adj, adj.T), np.array_equal(adj, adj.T)\n",
    "adj = np.maximum(adj, adj.T)\n",
    "adj.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_data(prediction_file):\n",
    "    prediction = list(results_helper.get_predictions(filenames=[prediction_file]))\n",
    "    assert len(prediction) == 1\n",
    "    filename, prediction = prediction[0]\n",
    "    prediction = prediction['results']['results']\n",
    "    return pd.DataFrame(prediction)\n",
    "\n",
    "def get_graph_prediction_data(file):\n",
    "    df = get_prediction_data(file)\n",
    "    df['X_test_undirected'] = df.X_test.apply(nx.Graph)\n",
    "    df['edge_labels'] = df.X_test.apply(lambda x: [data['name'] for _, _, data in x.edges(data=True)])\n",
    "    df['node_labels'] = df.X_test.apply(nx.nodes)\n",
    "    df['num_nodes'] = df.X_test.apply(nx.number_of_nodes)\n",
    "    df['num_edges'] = df.X_test.apply(nx.number_of_edges)\n",
    "    df['num_nodes_plus_edges'] = df.num_nodes + df.num_edges\n",
    "    df['num_nodes_div_num_edges'] =  df.num_nodes / df.num_edges\n",
    "    df['num_connected_components'] = df.X_test_undirected.apply(nx.number_connected_components)\n",
    "    df['num_nodes_div_num_connected_components'] = df.num_nodes / df.num_connected_components\n",
    "    return df\n",
    "\n",
    "def get_text_prediction_data(file):\n",
    "    df_text = get_prediction_data(file)\n",
    "    df_text['num_words'] = df_text.X_test.apply(lambda x: len(x.split()))\n",
    "    return df_text\n",
    "\n",
    "DATASET = 'ng20'\n",
    "\n",
    "GRAPH_FILE = 'result___{}__graph__dataset_graph_concept_map_{}-v3.npy'.format(DATASET, DATASET)\n",
    "TEXT_FILE = 'result___{}__text.npy'.format(DATASET)\n",
    "\n",
    "df = get_graph_prediction_data(GRAPH_FILE)\n",
    "df['dataset'] = DATASET\n",
    "df_text = get_text_prediction_data(TEXT_FILE)\n",
    "df_text['dataset'] = DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, df_ in df.iterrows():\n",
    "    dataset = df_.dataset\n",
    "    X = df_.X_test\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_per_quantile(df, attr, q=10, ax = None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize = (11, 4))\n",
    "    df[attr + '_bins'] = pd.qcut(df[attr], q=q, duplicates='drop')\n",
    "    data = collections.defaultdict(list)\n",
    "    for interval, df_ in df.groupby(attr + '_bins'):\n",
    "        score = get_score(df_)\n",
    "        data['interval'].append(interval)\n",
    "        data['f1'].append(score)\n",
    "    df_ = pd.DataFrame(data).set_index('interval')\n",
    "    df_['interval_mean'] = df_.index.map(lambda x: x.mid)\n",
    "    df_.set_index('interval_mean').plot(kind='bar', ax = ax, legend=False)\n",
    "    labels = df_.interval_mean.values\n",
    "    ax.set_xticklabels(['{:.0f}'.format(x) for x in labels])\n",
    "    #ax.set_xticklabels(labels, rotation=0)\n",
    "    ax.set_xlabel('Decile')\n",
    "    ax.set_ylabel('F1 macro')\n",
    "    ax.set_title(attr)\n",
    "    ax.get_figure().tight_layout()\n",
    "    return ax\n",
    "\n",
    "def get_score(df_):\n",
    "    y_true, y_pred = df_.Y_real.values, df_.Y_pred.values\n",
    "    f1 = sklearn.metrics.f1_score(y_true, y_pred, average='macro')\n",
    "    return f1\n",
    "\n",
    "for attr in ['num_edges', 'num_nodes', 'num_nodes_div_num_connected_components', 'num_nodes_div_num_edges', 'num_connected_components', 'num_nodes_plus_edges']:\n",
    "    ax = get_score_per_quantile(df, attr)\n",
    "    fig = ax.get_figure()\n",
    "    save_fig(fig, 'graph_binning_{}'.format(attr), folder='tmp/graph_sizes')\n",
    "    \n",
    "for attr in ['num_words']:\n",
    "    ax = get_score_per_quantile(df_text, attr)\n",
    "    fig = ax.get_figure()\n",
    "    save_fig(fig, 'text_binning_{}'.format(attr), folder='tmp/graph_sizes')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
