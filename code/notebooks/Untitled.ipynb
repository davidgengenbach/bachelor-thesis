{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_prelude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = dataset_helper.get_dataset('nyt_small', use_cached=False)\n",
    "collections.Counter(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PER_CLASS = 25\n",
    "\n",
    "per_class = collections.defaultdict(list)\n",
    "for x, y in zip(X, Y):\n",
    "    per_class[y].append(x)\n",
    "per_class_count = {k: len(v) for k, v in per_class.items()}\n",
    "\n",
    "out = {}\n",
    "for y, xs in per_class.items():\n",
    "    out[y] = np.random.choice(xs, size=NUM_PER_CLASS)\n",
    "\n",
    "assert np.all([len(xs) == NUM_PER_CLASS for xs in out.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "for y, xs in out.items():\n",
    "    Y += [y] * len(xs)\n",
    "    X += xs.tolist()\n",
    "assert len(X) == len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_u, Y_u = dataset_helper.get_dataset('ted_talks_unclassified')\n",
    "X, Y = dataset_helper.get_dataset('ted_talks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[0], X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_u_cmap, Y_u_cmap = dataset_helper.get_dataset_cached(dataset_helper.get_all_cached_graph_datasets(dataset_name='ted_talks_unclassified', graph_type=TYPE_CONCEPT_MAP)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Y_u_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = dataset_helper.get_concept_map_combined_dataset_for_dataset('ted_talks')\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.datasets.ted_talks import dataset as ted_talks\n",
    "\n",
    "df = ted_talks.get_df()\n",
    "url_2_label = {url: df_.label for url, df_ in df.iterrows()}\n",
    "\n",
    "url__2_label = {url: idx for idx, url in enumerate(Y_u_cmap)}\n",
    "\n",
    "c = collections.Counter()\n",
    "X_cmap_new, Y_cmap_new = [], []\n",
    "for url, df_ in df.iterrows():\n",
    "    if url not in url__2_label:\n",
    "        print('No graph found for:', url, df_.transcript)\n",
    "        continue\n",
    "    graph, _ = X_u_cmap[url__2_label[url]]\n",
    "    other_url = Y_u_cmap[url__2_label[url]]\n",
    "    assert other_url == url\n",
    "    label = df_.label\n",
    "    X_cmap_new.append((graph, str(c[label]).zfill(4)))\n",
    "    Y_cmap_new.append(label)\n",
    "    c[label] += 1\n",
    "    \n",
    "with open('data/CACHE/dataset_graph_concept_map_ted_talks-v3.npy', 'wb') as f:\n",
    "    pickle.dump((X_cmap_new, Y_cmap_new), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cmap, Y_cmap = dataset_helper.get_dataset_cached(dataset_helper.get_all_cached_graph_datasets(dataset_name='ted_talks', graph_type=TYPE_CONCEPT_MAP)[0])\n",
    "X_cmap[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in dataset_helper.get_all_cached_graph_datasets(graph_type=TYPE_COOCCURRENCE):\n",
    "    print(file)\n",
    "    X, Y = dataset_helper.get_dataset_cached(file)\n",
    "    print(X[0].nodes())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = dataset_helper.get_dataset('ng20')\n",
    "\n",
    "X = list(map(preprocessing.preprocess, X))\n",
    "t = sklearn.feature_extraction.text.CountVectorizer()\n",
    "t.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = list(t.vocabulary_.keys())\n",
    "\n",
    "words_len_2 = [x for x in all_words if len(x) <= 3]\n",
    "for word in words_len_2:\n",
    "    assert word in t.vocabulary_\n",
    "    \n",
    "words_len_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "all_text = list(chain.from_iterable(X))\n",
    "all_text = ''.join(all_text)\n",
    "word_counts_ = t.transform([all_text])\n",
    "word_count_indices = word_counts_.nonzero()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = word_counts_.sum()\n",
    "word_counts = {}\n",
    "idx_2_word = {idx: word for word, idx in t.vocabulary_.items()}\n",
    "print(total_words)\n",
    "for idx in word_count_indices:\n",
    "    word = idx_2_word[idx]\n",
    "    count = word_counts_[0, idx]\n",
    "    frequency = count / total_words\n",
    "    print(word, count)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_ = all_text.lower().split()\n",
    "word_counter = collections.Counter(all_words_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_word_counts = list(word_counter.values())\n",
    "s = pd.Series(all_word_counts)\n",
    "#.plot(kind='hist', bins=300)\n",
    "s[(s > s.quantile(0.01)) & (s < s.quantile(0.99))].plot(kind='hist', bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s[s == 1]) / len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in results_helper.get_result_filenames_from_folder():\n",
    "    if 'result___ling-spam__graph_gram__dataset_graph_cooccurrence_1_only-nouns_un-lemmatized_ling-spam.spgk-1.gram.npy' not in file: continue\n",
    "    with open(file, 'rb') as f:\n",
    "        res = pickle.load(f)\n",
    "    pprint(res['results']['param_classifier'][0].dual_coef_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPHS = {}\n",
    "cmaps = dataset_helper.get_all_cached_graph_datasets(graph_type=TYPE_CONCEPT_MAP)\n",
    "for cache_file in cmaps:\n",
    "    dataset = filename_utils.get_dataset_from_filename(cache_file)\n",
    "    X, Y = dataset_helper.get_dataset_cached(cache_file=cache_file)\n",
    "    X_g = graph_helper.get_graphs_only(X)\n",
    "    GRAPHS[dataset] = (X_g, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = dataset_helper.get_all_cached_graph_datasets(dataset_name='ted_talks', graph_type=TYPE_CONCEPT_MAP)[0]\n",
    "X_, Y = dataset_helper.get_dataset_cached(cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize=(13, 13)\n",
    "\n",
    "X = graph_helper.get_graphs_only(X_)\n",
    "candidates = [idx for idx, g in enumerate(X) if len(g.nodes()) < 15 and len(g.nodes()) > 5]\n",
    "idx = np.random.choice(candidates)\n",
    "g = X[idx]\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "pos = nx.layout.circular_layout(G=g)#, iterations=100)\n",
    "nx.draw_networkx(g, node_size=4, pos=pos, ax = ax)\n",
    "edges = {(s, t): data['name'] for s, t, data in g.edges(data=True)}\n",
    "nx.draw_networkx_edge_labels(g, pos=pos, edge_labels=edges)\n",
    "cleanup_axes(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiments\n",
    "from experiments import experiment_helper\n",
    "experiment_helper.save_experiment_params_as_experiment_config()\n",
    "print('\\n'.join([filename_utils.get_dataset_from_filename(x) for x in dataset_helper.get_all_cached_graph_datasets(graph_type=TYPE_CONCEPT_MAP)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = dataset_helper.get_dataset('imsdb')\n",
    "word_counts = [len(x.split()) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(word_counts, columns = ['word_counts']).plot(kind='hist', bins=120)\n",
    "len(word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIG_SIZE = (30, 30)\n",
    "#FIG_SIZE = (5, 5)\n",
    "g = nx.read_gml('tmp/concept-graph.graph')\n",
    "\n",
    "node_mapping = {}\n",
    "for node, data in g.nodes(data=True):\n",
    "    node_mapping[node] = data['name']\n",
    "node_labels = list(node_mapping.values())\n",
    "assert len(node_labels) == len(set(node_labels))\n",
    "\n",
    "\n",
    "nx.relabel_nodes(g, node_mapping, copy=False)\n",
    "edges = g.edges(data=True)\n",
    "edge_labels = {(k, v): data['name'] for k, v, data in edges}\n",
    "\n",
    "for layout in [nx.layout.circular_layout, nx.layout.fruchterman_reingold_layout, nx.layout.random_layout, nx.layout.shell_layout, nx.layout.spectral_layout, nx.layout.spring_layout]:\n",
    "    fig, ax = plt.subplots(figsize=FIG_SIZE)\n",
    "    pos = layout(g)\n",
    "    nx.draw_networkx(g, ax=ax, pos=pos, node_size=10)\n",
    "    nx.draw_networkx_edge_labels(g, pos, edge_labels=edge_labels)\n",
    "    ax.grid(False)\n",
    "    ax.set_title(layout.__name__)\n",
    "    fig.tight_layout()\n",
    "    save_fig(fig, 'concept_map_{}'.format(layout.__name__), folder='tmp/concept_map_example')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
