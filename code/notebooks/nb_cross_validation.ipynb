{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_prelude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "\n",
    "CV_FIRST = 3\n",
    "CV_SECOND = 3\n",
    "SHUFFLE = True\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "def get_k_fold_splitter(n_splits, shuffle = SHUFFLE, random_state = RANDOM_STATE):\n",
    "    return model_selection.StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "# Initial splitter into train/validation and test set\n",
    "cv_first = get_k_fold_splitter(n_splits=CV_FIRST)\n",
    "\n",
    "# Splitter for parameter tuning\n",
    "cv_second = get_k_fold_splitter(n_splits=CV_SECOND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiments\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from transformers.pipelines.classifiers import get_classifier_params\n",
    "\n",
    "tasks = experiments.get_all_tasks()\n",
    "classifier_params = get_classifier_params()\n",
    "\n",
    "cv = get_k_fold_splitter(3)\n",
    "\n",
    "TEST_FIT = True\n",
    "\n",
    "done = collections.defaultdict(lambda: False)\n",
    "\n",
    "results = {}\n",
    "all_params = {}\n",
    "for task in tasks:\n",
    "    assert task\n",
    "    if done[task.type]: continue\n",
    "    if task.type == 'dummy': continue\n",
    "    if 'v1' in task.name: continue\n",
    "    print('STARTING {:30} ({})'.format(task.type, task.name))\n",
    "\n",
    "    X, Y, estimator, params = task.fn()\n",
    "\n",
    "    params = dict(classifier_params, **params)\n",
    "    \n",
    "    # Remove \"voided\" params\n",
    "    params = {k: v for k, v in params.items() if v is not None}\n",
    "    \n",
    "    all_params[task.type] = params\n",
    "    \n",
    "    if TEST_FIT:\n",
    "        try:\n",
    "            gscv = GridSearchCV(estimator=estimator, param_grid=params, n_jobs=2, cv = cv, verbose = 2, scoring = 'f1_macro')\n",
    "            result = gscv.fit(X, Y)\n",
    "            results[task] = result\n",
    "            print(result)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    break\n",
    "    print('FINISHED', task.type)\n",
    "    done[task.type] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task, result in results.items():\n",
    "    print(task, result.best_score_, result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(a = 2, b = 3):\n",
    "    c = 'abc'\n",
    "    print(locals())\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.pipelines import pipeline_helper\n",
    "for task_type, params in all_params.items():\n",
    "    params_ = sklearn.model_selection.ParameterGrid(params)\n",
    "    print('{:24} #Params: {:4}'.format(task_type, len(params_)))\n",
    "    params_clean = pipeline_helper.remove_complex_types(params)\n",
    "    for k, v in params_clean.items():\n",
    "        print('\\t{:90} {}'.format(k, v))\n",
    "    print('\\n'*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(tasks).type.value_counts().sort_index().to_frame()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
