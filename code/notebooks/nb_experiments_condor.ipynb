{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_prelude import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create condor scheduling jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import time_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiments = glob('{}/*/*.yaml'.format(EXPERIMENT_CONFIG_FOLDER))\n",
    "\n",
    "priorities = dict(\n",
    "    split_multi_words=3,\n",
    "    edge_labels=2,\n",
    "    relabel=1,\n",
    "    remove_infrequent=1,\n",
    "    content_vs_structure=1,\n",
    "    combined=0,\n",
    "    use_directed=0,\n",
    "    node_weights=-1,\n",
    "    dimensionality_reduction=-999,\n",
    "    ngrams=-2\n",
    ")\n",
    "\n",
    "verbose = 1\n",
    "cores = 16\n",
    "extra = '--use_nested'\n",
    "extra = ''\n",
    "create_predictions='true'\n",
    "\n",
    "tmpl = 'condor_submit priority=\"{prio}\" batch_name=\"{name}\" Args=\"--n_jobs {cores} --verbose {verbose} --create_predictions {create_predictions} --task_name concept --experiment_config /home/david/bachelor-thesis/code/{experiment} {extra}\" classification_job.condor'\n",
    "\n",
    "outs = []\n",
    "for experiment in sorted(all_experiments):\n",
    "    name, name_ = experiment.split('/')[2:]\n",
    "    assert name in priorities, 'Missing priority for experiment: {}'.format(name)\n",
    "    prio = priorities.get(name)\n",
    "    cmd = tmpl.format(name=name_, cores=cores, verbose=verbose, experiment=experiment, prio=prio, extra=extra, create_predictions=create_predictions)\n",
    "    outs.append((prio, cmd))\n",
    "\n",
    "cmd = 'condor_submit priority=\"{prio}\" batch_name=\"{name}\" Args=\"--n_jobs {cores} --verbose {verbose} --task_name concept --create_predictions {create_predictions}\" classification_job.condor'.format(prio=-2, name='normal_concept_maps', cores=cores, verbose=verbose, create_predictions=create_predictions)\n",
    "outs.append((-2, cmd))\n",
    "\n",
    "cmd = 'condor_submit priority=\"{prio}\" batch_name=\"{name}\" Args=\"--n_jobs {cores} --verbose {verbose} --task_type_include text --create_predictions {create_predictions}\" classification_job.condor'.format(prio=-1, name='text', cores=cores, verbose=verbose, create_predictions=create_predictions)\n",
    "outs.append((-1, cmd))\n",
    "\n",
    "for t in ['dummy_most_frequent', 'dummy_stratified', 'dummy_uniform']:\n",
    "    cmd = ('condor_submit priority=\"{prio}\" batch_name=\"{name}\" Args=\"--n_jobs {cores} --verbose {verbose} --task_type_include {task_type}\" classification_job.condor'.format(prio=10, name=t, task_type=t, cores=cores, verbose=verbose))\n",
    "    outs.append((10, cmd))\n",
    "\n",
    "cmds = ';\\n\\n'.join([cmd for prio, cmd in sorted(outs, key=lambda x: x[0], reverse=True)])\n",
    "with open('tmp/start_classifaction_jobs.sh', 'w') as f:\n",
    "    f.write('# Created: {}\\n\\n{}\\n\\n'.format(time_utils.get_time_formatted(), cmds))\n",
    "\n",
    "print('# Jobs: {}'.format(len(outs)))\n",
    "\n",
    "print('Uploading')\n",
    "!chmod +x tmp/start_classifaction_jobs.sh\n",
    "!scp tmp/start_classifaction_jobs.sh pe:condor_scripts/\n",
    "print('Finished')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
