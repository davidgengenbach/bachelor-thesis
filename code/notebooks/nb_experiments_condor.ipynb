{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create condor scheduling jobs\n",
    "\n",
    "... and upload them to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_prelude import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import time_utils, git_utils\n",
    "\n",
    "all_experiments = glob('{}/*/*.yaml'.format(EXPERIMENT_CONFIG_FOLDER))\n",
    "\n",
    "all_experiments = [x for x in all_experiments if '.disabled.' not in x]\n",
    "\n",
    "priorities = [\n",
    "    #'min_df',\n",
    "    'dummy',\n",
    "    'text',\n",
    "    'graphs',\n",
    "    'split_multi_words',\n",
    "    'edge_labels',\n",
    "    'content_vs_structure',\n",
    "    'use_directed',\n",
    "    'remove_unseen_nodes',\n",
    "    'relabel',\n",
    "    'remove_infrequent',\n",
    "    'node_weights',\n",
    "    'graph_extra',\n",
    "    'combined',\n",
    "#    'ngrams',\n",
    "    'fast_wl_normalization',\n",
    "#    'dimensionality_reduction',\n",
    "]\n",
    "\n",
    "experiment_filter = dict(\n",
    "    text=[\n",
    "        'min_df',\n",
    "        'ngrams',\n",
    "        'dummy',\n",
    "        'text'\n",
    "    ],\n",
    "    TYPE_COOCCURRENCE=[],\n",
    "    TYPE_CONCEPT_MAP=[\n",
    "        'remove_infrequent',\n",
    "        'remove_unseen_nodes',\n",
    "        'split_multi_words',\n",
    "        'edge_labels',\n",
    "        'use_directed',\n",
    "        'relabel'\n",
    "    ],\n",
    "    graph_extra=[\n",
    "        'graph_extra'\n",
    "    ]\n",
    ")\n",
    "\n",
    "exclusive = ['text', 'graph_extra']\n",
    "\n",
    "verbose = 1\n",
    "cores = 16\n",
    "extra = '--use_nested'\n",
    "extra = ''\n",
    "create_predictions='true'\n",
    "\n",
    "tmpl = 'condor_submit priority=\"{prio}\" batch_name=\"{task_name}__{name}\" Args=\"--task_name {task_name} --experiment_config /home/david/bachelor-thesis/code/{experiment} {extra}\" classification_job.condor'\n",
    "\n",
    "\n",
    "\n",
    "outs = []\n",
    "for t in [TYPE_CONCEPT_MAP, TYPE_COOCCURRENCE, 'text', 'graph_extra']:\n",
    "    for experiment in sorted(all_experiments):\n",
    "        name, name_ = experiment.split('/')[2:]\n",
    "        if name not in priorities:\n",
    "            print('Missing priority for experiment: \"{}\". Skipping.'.format(name))\n",
    "            continue\n",
    "        prio = 100 - priorities.index(name)\n",
    "        is_in_text = name in experiment_filter['text']\n",
    "        is_exclusive = t in exclusive\n",
    "        if is_exclusive and (name not in experiment_filter[t]):\n",
    "            continue\n",
    "        is_in_specific = len([l for t_, l in experiment_filter.items() if name in l and t_ != t])\n",
    "        if is_in_specific or (t == 'text' and not is_in_text) or (t != 'text' and is_in_text) or (t == 'graph_extra' and name not in experiment_filter[t]):\n",
    "            continue\n",
    "        if t == TYPE_COOCCURRENCE:\n",
    "            prio -= 30\n",
    "        cmd = tmpl.format(name=name_, cores=cores, verbose=verbose, experiment=experiment, prio=prio, extra=extra, create_predictions=create_predictions, task_name=t)\n",
    "        outs.append((prio, cmd))\n",
    "\n",
    "PRELUDE = '''#!/usr/bin/env bash\n",
    "\n",
    "# Created: {}\n",
    "# Commit:  {}\n",
    "\n",
    "{}\n",
    "'''\n",
    "outs = sorted(outs, key=lambda x: x[0], reverse=True)\n",
    "cmds = ';\\n\\n'.join([cmd for prio, cmd in outs])\n",
    "with open('tmp/start_classifaction_jobs.sh', 'w') as f:\n",
    "    f.write(PRELUDE.format(time_utils.get_time_formatted(), git_utils.get_current_commit(), cmds))\n",
    "\n",
    "print('# Jobs: {}'.format(len(outs)))\n",
    "print('Uploading')\n",
    "!chmod +x tmp/start_classifaction_jobs.sh\n",
    "!scp tmp/start_classifaction_jobs.sh pe:condor_scripts/\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat tmp/start_classifaction_jobs.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save experiment configs with all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_params = experiment_helper.get_all_task_type_params()\n",
    "all_tasks = experiments.get_all_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = {}\n",
    "for task in all_tasks:\n",
    "    if task.name in tasks: continue\n",
    "    tasks[task.type] = task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiments = experiment_helper.get_all_param_grid_config_files()\n",
    "experiments = collections.defaultdict(dict)\n",
    "for name, experiment_config in all_experiments.items():\n",
    "    if '/all' in name: continue\n",
    "    print(name)\n",
    "    for task_name, task in tasks.items():\n",
    "        if task.type not in experiment_config['params_per_type']: continue\n",
    "        _, _, _, params = task.fn()\n",
    "        merged_param_grid = experiment_helper.prepare_param_grid(task, params, experiment_config)\n",
    "        experiments[name][task.type] = merged_param_grid\n",
    "    print('-' * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_helper.save_all_experiment_params()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
