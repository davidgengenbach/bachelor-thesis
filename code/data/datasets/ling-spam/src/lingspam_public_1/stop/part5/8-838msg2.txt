Subject: muc - 7 call participation

* * * call participation * * * seventh message understanding system evaluation message understanding conference ( muc - 7 ) evaluation : 2 - 6 march 1998 conference : april 1998 washington , d . c . area sponsored : human language systems tipster text program defense advanced research projects agency information technology office ( darpa / ito ) message understanding conferences provided ongoing forum assessing state art practice text analysis technology exchanging information innovative computational techniques context fully implemented systems perform realistic tasks . evaluations provided researchers potential sponsors customers quantitative means appreciate strengths weaknesses technologies , results reported conferences sparked customer interest potential utility technologies . seventh message understanding conference ( muc - 7 ) provide opportunity both experienced muc participants participate flexible evaluation , suited development needs abilities . provide : * opportunity select among variety tasks : named entity ( ne ) , coreference ( co ) , template element ( te ) , template relationship ( tr ) scenario template ( st ) . * two tasks evaluating component technologies ( ne co ) , standard generalized markup language ( sgml ) output format * redesigned information extraction ( ie ) task , two domain-independent subtasks ( te tr ) separated domain-dependent subtask ( st ) . * emphases st task portability minimizing human resources required participate evaluation . * three experimental tracks explore data sets tasks . participation muc - 7 is actively sought both veteran organizations . redesigned evaluation tasks , muc - 7 offers opportunity organizations try ideas handling nlp problems are both scientific practical interest without having participate entire range tasks . conference itself consist primarily presentations discussions innovative techniques , system design , test results . opportunity participants demo evaluation systems . attendance conference is limited evaluation participants guests invited darpa tipster text program . conference proceedings , including test results , published . schedule : 1 july 97 : application deadline participation 15 july 97 : release ne , co , te , tr , example st training data scorer 8 september 97 : release dry run st task definition , training data , scorer 29 sept - 3 oct 97 : muc - 7 dry run ( participants ) 6 february 98 : release formal test st task definition , training data , scorer 2 - 6 march 98 : muc - 7 formal run 7 - 9 april 98 : 7th message understanding conference ( tentative dates ) data task description : texts used system development testing are news service articles york times news service , supplied linguistic data consortium ( ldc ) [ ldc @ ldc . upenn . edu ] . training , dry run , test data tasks are extracted corpus approximately 158 , 000 articles . sets articles used muc - 7 evaluation distributed via ftp upon payment one fee $ 100 upon signing user agreement texts . user agreement retrieved ldc catalog ( evaluation agreements ) . url ldc home page is : http : / / www . ldc . upenn . edu . five separate evaluations conducted part muc - 7 . definition evaluations has been worked since late 1996 members muc - 7 planning committee . evaluations viewed capturing results text analysis various levels aggregation information : * named entity ( ne ) requires system under evaluation identify each bit pertinent information isolation others . * coreference ( co ) requires connecting references " identical " entities . * template element ( te ) requires grouping entity attributes together entity " objects . " * template relationship ( tr ) requires identifying relationships between template elements . * scenario template ( st ) requires identifying instances task-specific event identifying event attributes , including entities fill role event ; overall information content is captured via interlinked " objects . " * experimental tracks using data sets are variants ne task . task definition is same basic ne task , texts are different . * experimental track involving task is simplified version te task . key things note each evaluation task : * ne covers named organizations , , locations , along date / expressions monetary percentage expressions ; requires production sgml tags output . * co covers noun phrases ( common proper ) personal pronouns are " identical " reference ; requires production sgml tags output ; tags coreferring strings form " equivalance " classes , are used scoring . * te covers organizations , persons , artifacts , are captured form template " objects " consisting predefined set attributes . * tr covers relationships among template elements , including location relationships , are captured form template " relations " consisting relationship template elements participating relationship . tr is task muc - 7 . * st covers particular scenario , is kept secret until one month prior testing order focus system portability ; however , generalized structure scenario template is predefined , example scenarios are available participants examine . task is domain dependent . * tasks experimental tracks are derived ne te . is world wide web site allows automated testing following rules muc - 6 . particular value participants . website is password protected need licensed access acl / dci disk ldc obtain password chinchor @ gso . saic . com . muc - 6 articles were taken acl / dci disk . anonymous ftp site available downloading muc - 7 related material . cfp muc - 7 participant agreement are available public ftp site . each participant ( after signing ldc user agreement muc - 7 participation agreement ) receive password download muc - 7 data , definitions , scoring software release times noted above . url website is http : / / muc . saic . com . ftp site is ftp . muc . saic . com . test protocol evaluation criteria : muc - 7 participants elect one combination tasks experimental tracks . participants access shared resources training texts annotations / templates , task documentation , scoring software . muc - 7 participants are encouraged participate dry run advantage material available . formal test conducted during first week march . carried participants own sites accordance prepared test procedure results submitted ftp site official scoring software prepared saic muc - 7 . test sets used evaluations consist 100 texts , subsets tasks . different data sets dry run formal test . systems evaluated using recall precision metrics ( tasks ) , f - measure ( tasks ) , error-based metrics ( tasks except co ) . computation metrics is based scoring categories correct , partial , incorrect , spurious , missing , noncommittal . muc - 7 participants able familiarize themselves evaluation criteria through usage evaluation software , released along training data . instructions responding call participation : organizations within outside u . s . are invited respond call participation . actual testing phase evaluation , systems must able accept texts without manual preprocessing , process without human intervention , output annotations ( ne , co ) templates ( te , tr , st ) expected format . organizations plan allocating approximately two person-months effort participation evaluation conference . is understood organizations vary respect experience sgml text annotation , information extraction , domain expertise / engineering , resources , contractual demands / expectations , etc . recognition factors made analyses results . organizations wishing participate evaluation conference must respond july 1 , 1997 submitting short statement interest via email signed copy muc - 7 participation agreement via surface mail . 1 . statement interest submitted via email marsh @ aic . nrl . navy . mil include following : . evaluation task ( s ) ( choose one ) * named entity * coreference * template element * template relationship * scenario template b . primary point contact . please include name , surface email addresses , phone fax numbers . c . does site copy muc - 6 proceedings ? 2 . participation agreement downloaded anonymous ftp site ( ftp . muc . saic . com ) . signed copy sent surface mail elaine marsh , nrl - code 5512 , 4555 overlook ave . sw , washington , d . c . 20375-5337 , usa . questions cannot deferred until deadline responding call participation has passed , send email elaine marsh ( marsh @ aic . nrl . navy . mil ) , copies ralph grishman ( grishman @ cs . nyu . edu ) nancy chinchor ( chinchor @ gso . saic . com ) ensure message receives timely response one us . muc - 7 planning committee : ralph grishman , york university , program co-chair elaine marsh , naval research laboratory , program co-chair chinatsu aone , systems research applications lois childs , lockheed martin nancy chinchor , science applications international jim cowie , mexico state university rob gaizauskas , university sheffield megumi kameyama , sri international tom keenan , u . s . department defense boyan onyshkevych , u . s . department defense martha palmer , university pennsylvania beth sundheim , nccosc nrad marc vilain , mitre ralph weischedel , bbn systems technologies
