Date: Tue, 05 Nov 1996 00:26:42 GMT
Server: NCSA/1.5
Content-type: text/html
Last-modified: Wed, 31 May 1995 20:57:45 GMT
Content-length: 4310

<html>
<head>
<title>Blizzard & Paradyn WWW Status Report</title>
</head>
<body>
<hr>
<h1>
Blizzard and Paradyn:
Infrastructure and Scalable Tools for Multi-Paradigm Parallel Computers
</h1>
<h2>
WWW Status Report as of January 1995
</h2>
<hr>
<h3>
<!WA0><!WA0><!WA0><!WA0><!WA0><!WA0><!WA0><!WA0><!WA0><!WA0><!WA0><!WA0><!WA0><!WA0><!WA0><!WA0><IMG SRC="http://www.cs.wisc.edu/~blz-pdn/cow3.gif" ALT="Wisconsin COW" ALIGN=MIDDLE>
Wisconsin COW
</h3>
<h3>
Recent Accomplishments:
</h3>
<ul>
<li>

Acquired and deployed a Cluster of Workstations (COW) consisting of 40
dual-processor Sun SPARCstation20s workstations (see photo).  The COW
and our previously-acquired Thinking Machines CM-5 allow us to develop
solutions that scale from off-the-shelf hardware to large parallel
computers.

<li>
Implemented a preliminary version of shared memory across COW
workstation nodes that supports coarse-grain sharing as a precursor to
our upcoming fine-grain shared memory system.

<li>
Implemented a preliminary version of "dynamic instrumentation" that
allows the focus of measurement to change as different "information
traffic jam" locations are investigated.

</ul>

<address>
Last Update: January 1994; Contact Barton Miller (<kbd>bart@cs.wisc.edu</kbd>)
</address>

<h3>
Background:
</h3>
The national defense and other key sectors--such as education, health
care, and commerce--increasingly benefit from and relying upon massive
computational power.  Parallel computers constructed from an array of
conventional computers offer a cost-effective approach to buying CPU
cycles.  Although the cost advantage is clear, getting the computers
to work together effectively requires better methods for:
<ol>
<li>
cooperatively sharing information, and
<li>
identifying and mitigating "information traffic jams."
</ol>

<h3>
Goals:
</h3>

This project addresses both concerns.  Effective information sharing
must permit programmers to tailor a program's sharing to the problem
being solved--rather than being constrain by the limit options built
into a system.  Our system supports message passing (like postal
mail), fine-grain shared memory (like reading over each other's
shoulders), and hybrid combinations of the two.  Our system can be
implemented on low- to high-end parallel computers, so programs can be
reused across a wide range of system.  For more information on this
part of the project, <!WA1><!WA1><!WA1><!WA1><!WA1><!WA1><!WA1><!WA1><!WA1><!WA1><!WA1><!WA1><!WA1><!WA1><!WA1><!WA1><A href="http://www.cs.wisc.edu/~wwt">click
here.</A>

<p>
The second goal of project is to improve techniques for mitigating
information traffic jams--what computer specialists call "performance
debugging."  Traditional tools for performance debugging have not
scaled to large parallel machines because it is difficult to decide in
advance what to measure and in what detail.  Our tools transcend this
problem by supporting "dynamic instrumentation" that allows
measurement activity to adapt to the tool's current hypothesis for the
information traffic jam's location.  For more information on this part
of the project, <!WA2><!WA2><!WA2><!WA2><!WA2><!WA2><!WA2><!WA2><!WA2><!WA2><!WA2><!WA2><!WA2><!WA2><!WA2><!WA2><A href="http://www.cs.wisc.edu/~paradyn">click
here.</A>

<h3>
Participants & Support:
</h3>

The principal investigators are
<!WA3><!WA3><!WA3><!WA3><!WA3><!WA3><!WA3><!WA3><!WA3><!WA3><!WA3><!WA3><!WA3><!WA3><!WA3><!WA3><A HREF="http://www.cs.wisc.edu/~bart/bart.html">Barton P. Miller,</a>
<!WA4><!WA4><!WA4><!WA4><!WA4><!WA4><!WA4><!WA4><!WA4><!WA4><!WA4><!WA4><!WA4><!WA4><!WA4><!WA4><A HREF="http://www.cs.wisc.edu/~markhill/markhill.html">Mark D. Hill,</a>
<!WA5><!WA5><!WA5><!WA5><!WA5><!WA5><!WA5><!WA5><!WA5><!WA5><!WA5><!WA5><!WA5><!WA5><!WA5><!WA5><A HREF="http://www.cs.wisc.edu/~larus/larus.html">James R. Larus,</a> and
<!WA6><!WA6><!WA6><!WA6><!WA6><!WA6><!WA6><!WA6><!WA6><!WA6><!WA6><!WA6><!WA6><!WA6><!WA6><!WA6><A HREF="http://www.cs.wisc.edu/~david/david.html">David A. Wood</a>
in <!WA7><!WA7><!WA7><!WA7><!WA7><!WA7><!WA7><!WA7><!WA7><!WA7><!WA7><!WA7><!WA7><!WA7><!WA7><!WA7><a href="http://www.cs.wisc.edu/"> Computer Sciences </a>
at the <!WA8><!WA8><!WA8><!WA8><!WA8><!WA8><!WA8><!WA8><!WA8><!WA8><!WA8><!WA8><!WA8><!WA8><!WA8><!WA8><A HREF="http://wiscinfo.wisc.edu">University of Wisconsin.</A>

<p>
This work is supported in part by Wright Laboratory Avionics Directorate,
Air Force Material Command, USAF, under grant #F33615-94-1-1525 and
ARPA order no. B550, NSF PYI/NYI Awards CCR-9157366, MIPS- 8957278,
and CCR-9357779, NSF Grants CCR-9101035 and MIP- 9225097, DOE Grant
DE-FG02-93ER25176, University of Wisconsin Graduate School Grant,
Wisconsin Alumni Research Foundation Fellowship and donations
from A.T.&T. Bell Laboratories, Digital Equipment Corporation, Sun
Microsystems, Thinking Machines Corporation, and Xerox Corporation. Our
Thinking Machines CM-5 and Cluster of Sun Workstations were purchased
through NSF Institutional Infrastructure Grant No. CDA-9024618 with
matching funding from the University of Wisconsin Graduate School.
<p>
<address>
Last Update: January 1994; Contact Barton Miller (<kbd>bart@cs.wisc.edu</kbd>)
</address>

</body>
</html>
