Date: Tue, 05 Nov 1996 00:23:52 GMT
Server: NCSA/1.4.1
Content-type: text/html

<HEAD>
<TITLE>UW-Madison Robotics Lab Research Summary</TITLE>
</HEAD>

<H3> UW-Madison Robotics Lab Research Summary </H3>

<p>
Our research activities lie at the intersection of intelligence and motion. 
We are interested in analysis and design of systems, both in humans and in 
machines, that lie behind one of the most complex behavioral functions found 
in nature - sensing-based motion planning. How does one combine sensing, 
spatial reasoning, prior experience, and the sense of goal to produce 
purposeful motion in a complex, uncertain, and time-changing environment? 
By its nature, this is multi-disciplinary research: members of the Lab include
researchers from Engineering, Computer Science, Mathematics, Psychology.
<p>
In the area of robotics, our projects cover mobile robots, manipulators, 
and human-guided teleoperated systems; different types of sensing, from a 
simple sonar to vision to whole-body sensing; various kinematic systems 
including highly redundant structures like snakes and multi-finger wrists; 
static and dynamic systems. In the cognitive science area, we study human 
skills in motion planning, with the purpose of developing (a) hybrid 
machinery in which human and machine intelligences are utilized together 
in a synergistic manner, and (b) virtual human-centered interactive 
computer systems.
<p>
Our research can be divided into three groups: 
<DL>
   <DD>Theory and algorithms; 
   <DD>Graphics simulation/animation; 
   <DD>Experimental work. 
</DL>
Our theoretical tools come from geometry, topology, and control theory. We 
have shown that, in spite of the formidable complexity and uncertainties of 
the robot environment, even simple sensory feedback is often sufficient to 
guarantee purposeful collision-free motion. Our computer graphics projects 
concentrate on visualization and animation of motion. Our experimental work, 
which is carried out both here at UW and with industry, focuses on hardware 
prototypes of sensor-based motion planning systems. One example here is our
whole-sensitive arm manipulator project: the system's strong capacity for
spatial reasoning (often exceeding that of humans) is made possible by 
sensitive skin that includes many hundreds of proximity sensors and
covers the arm's whole body, similar to human skin.
<p>
The gist of our research is perhaps best expressed in a project where a 
professional ballerina dances with a robot arm manipulator. It is a naturally 
symmetric act - one partner can turn her/his/its back to the other and expect 
a friendly half-learned, half-improvized motion. They can count on each other.
