Date: Thu, 21 Nov 1996 20:43:02 GMT
Server: NCSA/1.5.2
Last-modified: Tue, 24 Sep 1996 23:26:33 GMT
Content-type: text/html
Content-length: 3104

<html><title>Rich Sutton's Home Page</title>
<body>
<!WA0><IMG align=right SRC="http://envy.cs.umass.edu/People/sutton/sutton-head.gif">
<h1>Richard S. Sutton</h1>
<STRONG>
Senior Research Scientist<BR>
<!WA1><A HREF="http://www.cs.umass.edu/">Department of Computer Science</A><BR>
<!WA2><A HREF="http://www.cs.umass.edu/rcfdocs/newhome/">University of Massachusetts</A><BR>
<!WA3><A HREF="http://www-astro.phast.umass.edu/guest/amherst.html">Amherst</A>, MA 01003  USA<P>

Co-director, <!WA4><A HREF="http://envy.cs.umass.edu/">Adaptive Networks Laboratory</A><BR>
</STRONG>
<BR>

email: <!WA5><A HREF="mailto:rich@cs.umass.edu">rich@cs.umass.edu</A><BR>
office: Lederle A225 (413-545-0609) (Mondays and Fridays)<BR>
office hours: 1-2:00 Monday<br>
phone: 508-897-6174, fax:508-897-1842

<UL>
<LI><!WA6><A HREF="http://envy.cs.umass.edu/People/sutton/BriefBio.html">Brief Biography</A> 
<LI><!WA7><A HREF="http://envy.cs.umass.edu/People/sutton/publications.html">Recent Publications</A>
<LI><!WA8><A HREF="http://envy.cs.umass.edu/People/sutton/course/course.html">Reinforcement Learning Course at UMass this Fall</A>
<LI>Reinforcement Learning Software
    <UL>
    <li><!WA9><a href="http://envy.cs.umass.edu/People/sutton/RLinterface/RLinterface.html">Proposed Standard for RL Software</a> -- New!
    <li>CMACs, CMACs, CMACs! (<!WA10><a href="http://www.ece.unh.edu/robots/cmac/cmac.htm">Univ New Hampshire</a>, 
          <!WA11><a href="http://www.math.clemson.edu/~peterson/books.html">Clemson</a>)
    <li><!WA12><a href="http://envy.cs.umass.edu/People/singh/Demo.html">Java Demo of RL 
        Dynamic Channel Assignment</a> (Singh &amp; Bersekas)
         <LI><!WA13><A HREF="ftp://ftp.cs.umass.edu/pub/anw/pub/sutton/Mountain-Car-in-C++/Everything.tar">
        C++ Code for the Mountain Car</A> (S. Mahadevan)
    <LI><!WA14><A HREF="http://envy.cs.umass.edu/People/sutton/acrobot-code.lisp">Lisp code for Acrobot</A> (a code fragment, FYI)
    <LI><!WA15><A HREF="ftp://ftp.cs.umass.edu/pub/anw/pub/sutton/TDmodel.c">TD Model of 
        Classical Conditioning in C++</a>
        and <!WA16><A HREF="ftp://ftp.cs.umass.edu/pub/anw/pub/sutton/TDmodel.lisp">Lisp</a>  
    <li><!WA17><A HREF="http://envy.cs.umass.edu/People/sutton/RL-software.html">More...</A>
    </UL>
<LI><!WA18><A HREF="http://envy.cs.umass.edu/People/sutton/the-book.html">The Book</A>
<LI><!WA19><A HREF="ftp://ftp.cs.umass.edu/pub/anw/pub/sutton/">My ftp site</A>
<LI><!WA20><A HREF="http://envy.cs.umass.edu/People/sutton/RLIA/rlia.html">Talk on Reinforcement Learning and The Web</A>
<LI><!WA21><A HREF="http://envy.cs.umass.edu/People/sutton/research-ideas.html#EG">Exponentiated-Gradient Methods for Reinforcement Learning</A>
<li>Documentation on <!WA22><A HREF="http://envy.cs.umass.edu/People/sutton/G/g.html">G</A>, a graphics package for Mac Common Lisp
</ul>

<BR>
The long term goal of my research is to identify general computational principles underlying what
we mean by intelligence and goal-directed behavior.  My starting place is the
<EM>interaction</EM>  between the intelligent agent and its environment.  Goals, choices, and
sources of information are all defined in terms of this interaction.  In some sense it is the
only thing that is real, and from it all our sense of the world is created.  How is this done? 
How can interaction lead to better behavior, better perception, better models of the world?  What
are the computational issues in doing this efficiently and in realtime?  These are the sort of
questions that I ask in trying to understand what it means to be intelligent, to predict and
influence the world, to learn, perceive, act, and think.
</Body>
</html>
