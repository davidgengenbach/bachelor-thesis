{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graph_helper\n",
    "import dataset_helper\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "for graph_cache_file in dataset_helper.get_all_cached_graph_datasets():\n",
    "    if 'ana' in graph_cache_file: continue\n",
    "    if 'gml' not in graph_cache_file: continue\n",
    "    cache_filename = graph_cache_file.split('/')[-1]\n",
    "    print('{} {}'.format('#' * 20, cache_filename))\n",
    "    X, Y = dataset_helper.get_dataset_cached(graph_cache_file)\n",
    "    num_classes = min(len(set(X)), 20)\n",
    "    #dataset_helper.plot_dataset_class_distribution(X, Y, title = graph_cache_file, figsize=(12, num_classes * 0.8))\n",
    "    df = graph_helper.get_graph_stats(X, Y)\n",
    "    \n",
    "    ax = df['num_graphs'].plot.barh(title = 'Graphs per topic\\n(Dataset: {})'.format(cache_filename.replace('.npy', '')), legend = True, figsize = (14, 8))\n",
    "    ax.set_xlabel('# graphs')\n",
    "    display(df)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import pickle\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set('notebook', 'white')\n",
    "\n",
    "df_all = None\n",
    "for result_file in glob('data/results/*.npy'):\n",
    "    with open(result_file, 'rb') as f:\n",
    "        result = pickle.load(f)\n",
    "    dataset = result_file.split('/')[-1].rsplit('.', 4)[0]\n",
    "    is_graph_dataset = 'graph' in dataset\n",
    "    is_cooccurrence_dataset = 'cooccurrence' in dataset\n",
    "    dataset_name = dataset\n",
    "    if is_graph_dataset:\n",
    "        result['wl_iteration'] = int(dataset.split('.')[-1])\n",
    "        parts = dataset.split('_')\n",
    "        if is_cooccurrence_dataset:\n",
    "            dataset_name = parts[-1].split('_')[0].split('.')[0]\n",
    "            result['words'] = parts[4]\n",
    "            result['window_size'] = parts[3]\n",
    "        # GML\n",
    "        else:\n",
    "            #result['window_size'] = -1\n",
    "            dataset_name = parts[3].split('.')[0]\n",
    "        result['type'] = 'cooccurrence' if is_cooccurrence_dataset else 'concept-graph'\n",
    "    else:\n",
    "        result['type'] = 'text'\n",
    "        dataset_name = dataset.split('_')[1]\n",
    "    for param in result['params']:\n",
    "        del param['clf']\n",
    "    if dataset_name.endswith('-single'):\n",
    "        dataset_name = dataset_name.rsplit('-', 1)[0]\n",
    "    del result['param_clf']\n",
    "    result['dataset'] = dataset_name\n",
    "    result_df = pd.DataFrame(result).sort_values(by = 'dataset', ascending = False)\n",
    "    \n",
    "    if df_all is None:\n",
    "        df_all = result_df\n",
    "    else:\n",
    "        df_all = df_all.append(result_df)\n",
    "\n",
    "#df_all['window_size'].fillna('concept-graph', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set('notebook', 'white')\n",
    "def plot_distributions(df, title = None, figsize = (8, 5)):\n",
    "    fig, axes_indexed = plt.subplots(nrows = 2, ncols=2, figsize = figsize)\n",
    "\n",
    "    axes = []\n",
    "    for ax_row in axes_indexed:\n",
    "        axes += list(ax_row)\n",
    "    for val, ax in zip(['wl_iteration', 'window_size', 'words', 'type'], axes):\n",
    "        df.groupby(val).mean_test_score.mean().plot(kind = 'barh', ax = ax, xlim = (0, 1))\n",
    "        ax.set_xlabel('f1 macro score')\n",
    "    plt.suptitle(title, size = 18)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.90)\n",
    "    return fig, axes\n",
    "    \n",
    "df_all = df_all.groupby('dataset').filter(lambda x: len(x.type.value_counts()) == 3).reset_index(drop=True)\n",
    "fig, _  = plot_distributions(df_all, title = 'Mean over all datasets')\n",
    "fig.savefig('tmp/results/all.png', dpi = 100)\n",
    "plt.show()\n",
    "plt.close(fig)\n",
    "for name, df_dataset in df_all.groupby('dataset'):\n",
    "    if len(df_dataset.type.value_counts()) < 3:\n",
    "        continue\n",
    "    fig, _ = plot_distributions(df_dataset, title = 'Dataset: {}'.format(name))\n",
    "    fig.savefig('tmp/results/dataset-{}.png'.format(name), dpi = 100)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_best_by_type(df, title = '', figsize = (8, 3)):\n",
    "    fig, ax = plt.subplots(figsize = figsize)\n",
    "    df['mean_test_score'].max().plot(kind = 'barh', ax = ax, xlim = (0, 1))\n",
    "    fig.suptitle(title, fontsize = 16)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top = 0.9)\n",
    "    return fig, ax\n",
    "\n",
    "for name, df_dataset in df_all.groupby('dataset'):\n",
    "    df_dataset_grouped_by_type = df_dataset.groupby('type')\n",
    "    fig, ax = plot_best_by_type(df_dataset_grouped_by_type, 'Dataset: {} (best)'.format(name))\n",
    "    fig.savefig('tmp/results/dataset-{}-best.png'.format(name), dpi = 100)\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/check-w2v-results.json') as f:\n",
    "    w2v_results = json.load(f)\n",
    " \n",
    "per_embedding_type = {}\n",
    "for dataset, value in w2v_results.items():\n",
    "    print(dataset)\n",
    "    for embedding_raw, cache_files in sorted(value.items(), key = lambda x: x[0]):\n",
    "        embedding = embedding_raw.split('/')[-1].rsplit('.', 2)[0]\n",
    "        if len(cache_files.keys()) != 2: continue\n",
    "        print('\\t{}'.format(embedding))\n",
    "        if embedding not in per_embedding_type:\n",
    "            per_embedding_type[embedding] = {}\n",
    "        per_embedding_type[embedding][dataset] = []\n",
    "        for dataset_file, counts in sorted(cache_files.items(), key = lambda x: x[0]):\n",
    "            not_found_ratio = int(counts['counts']['not_found'] / counts['num_labels'] * 100)\n",
    "            if embedding == 'trained' and 'coo' in  dataset_file:\n",
    "                print('Yes', counts['counts']['not_found'], not_found_ratio, '%', counts['not_found_sample'])\n",
    "            is_gml = 'dataset_graph_gml' in dataset_file\n",
    "            per_embedding_type[embedding][dataset].append((is_gml, not_found_ratio))\n",
    "            print('\\t\\t{:4} missing  {:3>}%'.format('gml' if is_gml else 'co', not_found_ratio))\n",
    "        per_embedding_type[embedding][dataset] = per_embedding_type[embedding][dataset][0][1]  #sum(y for x, y in per_embedding_type[embedding][dataset]) / 2\n",
    "df = pd.DataFrame(per_embedding_type)\n",
    "df#[df.index == \"ng20\"]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "38px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
