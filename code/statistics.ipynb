{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "require(\"notebook/js/notebook\").Notebook.prototype.scroll_to_bottom = function () {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from glob import glob \n",
    "import pickle\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import dummy\n",
    "import sys\n",
    "import os\n",
    "import helper\n",
    "\n",
    "EXPORT_DPI = 100\n",
    "EXPORT_FIG_SIZE = (8, 4)\n",
    "EXPORT_FIG_SIZE_BIG = (10, 7)\n",
    "EXPORT_FIG_WIDTH, EXPORT_FIG_HEIGHT = EXPORT_FIG_SIZE\n",
    "EXPORT_FIG_WIDTH_BIG, EXPORT_FIG_HEIGHT_BIG = EXPORT_FIG_SIZE_BIG\n",
    "\n",
    "plt.rcParams['figure.figsize'] = EXPORT_FIG_SIZE_BIG\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set('notebook', 'whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USED_FOLDER = '2017-09-13_21:33'\n",
    "USED_FOLDER = None\n",
    "\n",
    "result_folders = [x for x in glob('data/results/2017*') if os.path.isdir(x)]\n",
    "\n",
    "folder = 'data/results/{}'.format(USED_FOLDER) if USED_FOLDER else result_folders[-1]\n",
    "\n",
    "print('Using result folder: {}'.format(folder))\n",
    "\n",
    "df_all_ = None\n",
    "for result_file in helper.log_progress(glob('{}/*.npy'.format(folder))):\n",
    "    with open(result_file, 'rb') as f:\n",
    "        result = pickle.load(f)\n",
    "    dataset = result_file.split('/')[-1].rsplit('.', 2)[0]\n",
    "    is_graph_dataset = 'graph' in dataset\n",
    "    is_cooccurrence_dataset = 'cooccurrence' in dataset\n",
    "    dataset_name = dataset\n",
    "    \n",
    "    result['combined'] = 'combined' in result_file\n",
    "    if is_graph_dataset:\n",
    "        is_lemmatized = '_lemmatized_' in result_file\n",
    "        result['lemmatized'] = is_lemmatized\n",
    "        \n",
    "        result['same_label'] = 'same-label' in result_file\n",
    "        is_simple_kernel = '.simple.' in result_file\n",
    "        if is_simple_kernel:\n",
    "            result['kernel'] = 'simple_set_matching'\n",
    "        else:\n",
    "            result['kernel'] = 'spgk' if 'spgk' in result_file else 'wl'\n",
    "        is_relabeled = 'relabeled' in result_file\n",
    "        result['relabeled'] = is_relabeled\n",
    "        if is_relabeled:\n",
    "            topn = result_file.split('topn-')[1].split('_')[0]\n",
    "            threshold = result_file.split('threshold-')[1].split('_')[0]\n",
    "            result['topn'] = int(topn)\n",
    "            result['threshold'] = float(threshold)\n",
    "        if result['kernel'] == 'wl':\n",
    "            result['wl_iteration'] = dataset.split('.')[-1]\n",
    "        parts = dataset.split('_')\n",
    "        if is_cooccurrence_dataset:\n",
    "            dataset_name = parts[-1].split('_')[0].split('.')[0]\n",
    "            result['words'] = parts[4]\n",
    "            result['window_size'] = parts[3]\n",
    "        # GML\n",
    "        else:\n",
    "            dataset_name = parts[-1].split('.')[0]\n",
    "            result['words'] = 'concepts'\n",
    "        result['type'] = 'cooccurrence' if is_cooccurrence_dataset else 'concept-graph'\n",
    "    else:\n",
    "        result['type'] = 'text'\n",
    "        dataset_name = dataset.split('_')[1]\n",
    "        result['words'] = ['all' for x in result['params']]\n",
    "\n",
    "    result['classifier'] = [None] * len(result['params'])\n",
    "    for idx, param in enumerate(result['params']):\n",
    "        result['classifier'][idx] = type(param['clf']).__name__\n",
    "        del param['clf']\n",
    "    \n",
    "    dataset_name = dataset_name.replace('-single', '').replace('-ana', '').strip()\n",
    "\n",
    "    if '-ana' in result_file:\n",
    "        result['is_ana'] = True\n",
    "    \n",
    "    if dataset_name.endswith('-single') or dataset_name.endswith('-ana'):\n",
    "        dataset_name = dataset_name.rsplit('-', 1)[0]\n",
    "        \n",
    "    result['filename'] = result_file\n",
    "    result['dataset'] = dataset_name\n",
    "\n",
    "    del result['param_clf']\n",
    "    \n",
    "    result_df = pd.DataFrame(result).sort_values(by = 'dataset', ascending = False)\n",
    "    df_all_ = result_df if df_all_ is None else df_all_.append(result_df)\n",
    "\n",
    "assert df_all_ is not None\n",
    "assert df_all_.shape[0]\n",
    "    \n",
    "# Only keep datasets where there are all three types (text, co-occurence and concept-graph) of results\n",
    "df_all = df_all_.groupby('dataset').filter(lambda x: len(x.type.value_counts()) == 3).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame([(folder.split('/')[-1], len(glob('{}/*.npy'.format(folder)))) for folder in result_folders], columns = ['result_folder', 'num_results']).set_index('result_folder').sort_index()\n",
    "df_results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set('notebook', 'whitegrid', palette='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DummyClassifier performance per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all.classifier == 'DummyClassifier'].groupby('dataset').mean_test_f1_macro.max().to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for data_filter_name, data_filter in [('only-concept-graphs', df_all.type == 'concept-graph'), ('only-coocurrence', df_all.type == 'cooccurrence'), ('all', df_all.type != 'YES')]:\n",
    "    for dataset_name, df in df_all[data_filter].groupby('dataset'):\n",
    "        for attr in ['type', 'kernel']:\n",
    "            # Filter out DummyClassifier\n",
    "            df = df[(df.classifier != 'DummyClassifier')]\n",
    "            f1_min, f1_max = df.mean_test_f1_macro.min(), df.mean_test_f1_macro.max()\n",
    "            fig, axes = plt.subplots(figsize = EXPORT_FIG_SIZE)\n",
    "            ax = sns.violinplot(x = attr, y = 'mean_test_f1_macro', data=df, cut = 0, split = True, inner = 'quartile')\n",
    "            ax.set_ylim((0, f1_max + 0.1))\n",
    "            ax.set_ylabel('f1 macro')\n",
    "            ax.set_title('Result distribution ({})'.format(data_filter_name));\n",
    "            fig.tight_layout()\n",
    "            fig.savefig('tmp/result-distributions/{}-{}-{}.png'.format(dataset_name, data_filter_name, attr), dpi = EXPORT_DPI)\n",
    "            plt.show()\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best classifers per type per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "COLUMNS_OF_INTEREST = ['classifier', 'dataset', 'filename', 'lemmatized', 'accuracy', 'f1', 'precision', 'recall', 'mean_train_f1_macro', 'param_scaler', 'params', 'relabeled', 'same_label',\n",
    "                       #, 'std_test_accuracy', 'std_test_f1_macro', 'std_test_precision_macro', 'std_test_recall_macro',\n",
    "                       'threshold', 'topn', 'window_size', 'wl_iteration', 'words']\n",
    "\n",
    "def plot_best_by_type(df_all, df, df_dataset, title = '', fontsize = 12, figsize = (6, 3), top = 0.85):\n",
    "    fig, ax = plt.subplots(figsize = figsize)\n",
    "    els = df_all.iloc[df['mean_test_f1_macro'].idxmax()]\n",
    "    els = els.set_index('type')\n",
    "    els = els.rename(columns = {'mean_test_f1_macro': 'f1', 'mean_test_accuracy': 'accuracy', 'mean_test_precision_macro': 'precision', 'mean_test_recall_macro': 'recall'})\n",
    "    els[['f1', 'accuracy', 'precision', 'recall']].plot(kind = 'barh', ax = ax, xlim = (0, 1.5), xerr=[els.std_test_f1_macro * 2,  els.std_test_accuracy * 2,  els.std_test_precision_macro * 2,  els.std_test_recall_macro * 2])\n",
    "    ax.set_xticks(np.linspace(0, 1, 11))\n",
    "    ax.grid(axis = 'y')\n",
    "    \n",
    "    display(els[COLUMNS_OF_INTEREST])\n",
    "    \n",
    "    if title and title != '':\n",
    "        fig.suptitle(title, fontsize = fontsize)\n",
    "    fig.tight_layout()\n",
    "    if title and title != '':\n",
    "        fig.subplots_adjust(top = top)\n",
    "    return fig, ax\n",
    "\n",
    "for name, df_dataset in sorted(df_all[df_all.wl_iteration != 0].groupby('dataset'), key = lambda x: x[0]):\n",
    "    df_dataset_grouped_by_type = df_dataset.groupby('type')\n",
    "    print('################# {}'.format(name))\n",
    "    use_title = False\n",
    "    fig, ax = plot_best_by_type(df_all, df_dataset_grouped_by_type, df_dataset, 'Dataset: {}'.format(name) if use_title else None)\n",
    "    fig.savefig('tmp/results/dataset-{}-best.png'.format(name), dpi = 150)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot best per parameter value per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs_grouped_by_plot(df_all, groupby):\n",
    "    df_graphs_grouped = df_all[df_all.type != 'text'].groupby('dataset')\n",
    "\n",
    "    for idx, (dataset_name, df_dataset) in enumerate(df_graphs_grouped):\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize = EXPORT_FIG_SIZE)\n",
    "        # Print violinplot of f1, with graph_type as hue\n",
    "        hue = groupby if df_dataset[groupby].value_counts().count() > 1 else None\n",
    "        sns.violinplot(x = 'type', y = 'mean_test_f1_macro', hue= hue , data=df_dataset, cut = 0, split = True, inner = 'quartile', title = dataset, ax = ax)\n",
    "        #ax.set_ylim((0, 1.1))\n",
    "        ax.set_title('Dataset: {}'.format(dataset_name))\n",
    "        ax.set_ylabel('f1')\n",
    "        ax.set_xlabel('Labels ignored')\n",
    "        ax.grid('off')\n",
    "        fig.tight_layout()\n",
    "        fig.suptitle('Importance of labels per graph type')\n",
    "        fig.subplots_adjust(top = 0.86)\n",
    "        fig.savefig('tmp/results/label-importance-{}.png'.format(dataset_name), dpi = EXPORT_DPI)\n",
    "        plt.show()\n",
    "\n",
    "if 1 == 1:\n",
    "    graphs_grouped_by_plot(df_all, 'combined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def add(acc, item):\n",
    "    acc += item\n",
    "    return acc\n",
    "\n",
    "def get_vals_for_col(col):\n",
    "    return sorted(df_tmp[col].value_counts().index.tolist())\n",
    "\n",
    "cols = ['combined', 'kernel', 'lemmatized', 'relabeled', 'threshold', 'type', 'window_size', 'wl_iteration', 'words', 'classifier', 'same_label', 'topn']\n",
    "cols = ['type', 'combined', 'kernel', 'wl_iteration', 'same_label']\n",
    "\n",
    "df_tmp = df_all[df_all.dataset == 'ling-spam'][cols + ['mean_test_f1_macro']]\n",
    "\n",
    "vals = [get_vals_for_col(col) for col in cols]\n",
    "val_lenghts = [len(vals_) for vals_ in vals]\n",
    "dim = sum(val_lenghts)\n",
    "vals_flattened = functools.reduce(add, vals, [])\n",
    "\n",
    "best_of_mat = np.zeros((dim, dim), dtype=np.float32)\n",
    "\n",
    "col_counter = 0\n",
    "row_counter = 0\n",
    "\n",
    "for col_idx1, col1 in enumerate(cols):\n",
    "    vals_1 = get_vals_for_col(col1)\n",
    "    col_counter = 0\n",
    "    for col_idx2, col2 in enumerate(cols):\n",
    "        vals_2 = get_vals_for_col(col2)\n",
    "        for idx1, val1 in enumerate(vals_1):\n",
    "            for idx2, val2 in enumerate(vals_2):\n",
    "                best_of = df_tmp[(df_tmp[col1] == val1) & (df_tmp[col2] == val2)]\n",
    "                best_f1 = best_of.mean_test_f1_macro.max()\n",
    "                best_of_mat[row_counter + idx1, col_counter + idx2] = best_f1\n",
    "        col_counter += len(vals_2)\n",
    "    row_counter += len(vals_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(best_of_mat, vals, cols, ax = None, cmap='Blues', divider_color = '#FFFFFF', divider_linewidth = 6, fontdict = {'fontsize': 14, 'weight': 'bold'}):\n",
    "    if not ax:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    vals_lengths = [len(val) for val in vals]\n",
    "    \n",
    "    # Add labels to graph\n",
    "    for idx, s in enumerate(np.cumsum(val_lenghts)):\n",
    "        for x in ['v' , 'h']:\n",
    "            getattr(plt, 'ax{}line'.format(x))(s - 0.5, color = divider_color, linewidth = divider_linewidth)\n",
    "        \n",
    "        text_offset = ((val_lenghts[idx]) / 2)\n",
    "        \n",
    "        # Add the col labels to the right\n",
    "        ax.text(dim + 0.5, s - text_offset - 0.5, cols[idx], horizontalalignment = 'left', verticalalignment = 'center', fontdict=fontdict)\n",
    "        # Add the col labels to the top\n",
    "        ax.text(s - text_offset - 0.2, - 1, cols[idx], horizontalalignment = 'center', verticalalignment = 'center', fontdict=fontdict)\n",
    "\n",
    "    # Add x- and y-ticks\n",
    "    for x in ['x' , 'y']:\n",
    "        getattr(plt, x + 'ticks')(range(len(vals_flattened)), vals_flattened)\n",
    "\n",
    "    # Rotate x-ticks\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(90)\n",
    "\n",
    "    # Mark cells where no values are available\n",
    "    for row, cell in (zip(*list(np.where(np.isnan(best_of_mat))))):\n",
    "        ax.text(row, cell, 'X', horizontalalignment = 'center', verticalalignment = 'center', fontdict=fontdict)\n",
    "\n",
    "    plt.grid('off')\n",
    "    plt.imshow(best_of_mat, cmap=cmap)\n",
    "    plt.colorbar(fraction=0.04, pad=0.2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (30, 30))\n",
    "#plot(np.tril(best_of_mat), vals, cols, ax)\n",
    "plot(best_of_mat, vals, cols, ax)\n",
    "fig.tight_layout()\n",
    "fig.savefig('tmp/correlations.png', dpi = EXPORT_DPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(y = 'classifier', x = 'mean_test_f1_macro', data = df_all, cut = 0, split = True, inner = 'quartile', figsize = EXPORT_FIG_SIZE)\n",
    "#for classifier, df_classifier in df_all[df_all.dataset == 'ling-spam'].groupby('classifier'):\n",
    "#    print(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot performance per dataset and wl_iteration and graph_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, df_tmp in df_all[(df_all.type != 'text') & (df_all.lemmatized != True)].sort_values('wl_iteration').groupby('dataset'):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = sns.violinplot(x = 'wl_iteration', y = 'mean_test_f1_macro', hue = 'type', split = True, data = df_tmp, cut = True, inner = 'quartile', figsize = EXPORT_FIG_SIZE)\n",
    "    ax.set_ylabel('f1')\n",
    "    ax.set_title(dataset)\n",
    "    ax.figure.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "#.groupby('wl_iteration').mean_test_f1_macro.plot(kind = 'hist', alpha = 0.5, legend = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot by parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_distributions(df, df_all, title = None, figsize = (10, 8)):\n",
    "    fig, axes_indexed = plt.subplots(nrows = 2, ncols=2, figsize = figsize)\n",
    "\n",
    "    axes = []\n",
    "    for ax_row in axes_indexed:\n",
    "        axes += list(ax_row)\n",
    "    #, 'relabeled'\n",
    "    for val, ax in zip(['wl_iteration', 'window_size', 'words', 'type'], axes):\n",
    "        if len(df.groupby(val).size()) == 0:\n",
    "            continue\n",
    "        grouped = df.groupby(val)\n",
    "        els = df_all.iloc[grouped['mean_test_f1_macro'].idxmax()]\n",
    "        els = els.set_index(val)\n",
    "        els = els.rename(columns = {'mean_test_f1_macro': 'f1', 'mean_test_accuracy': 'accuracy', 'mean_test_precision_macro': 'precision', 'mean_test_recall_macro': 'recall'})\n",
    "        els[['f1', 'accuracy', 'precision', 'recall']].plot(kind = 'barh', ax = ax, xlim=(0, 2))\n",
    "        ax.set_xticks(np.linspace(0, 1, 11))\n",
    "        ax.grid(axis = 'y')\n",
    "        ax.set_xlim((0, 1.6))\n",
    "    \n",
    "    plt.suptitle(title, size = 18)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.90)\n",
    "    return fig, axes\n",
    "    \n",
    "dpi = 150\n",
    "\n",
    "if 1 == 1:\n",
    "    fig, _  = plot_distributions(df_all, df_all, title = 'Mean over all datasets')\n",
    "    fig.savefig('tmp/results/all.png', dpi = dpi)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "    for name, df_dataset in df_all.groupby('dataset'):\n",
    "        if len(df_dataset.type.value_counts()) < 3:\n",
    "            continue\n",
    "        fig, _ = plot_distributions(df_dataset, df_all, title = 'Dataset: {}'.format(name))\n",
    "        fig.savefig('tmp/results/dataset-{}.png'.format(name), dpi = dpi)\n",
    "        plt.show()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "with open('data/check-w2v-results.json') as f:\n",
    "    w2v_results = json.load(f)\n",
    " \n",
    "per_embedding_type = {}\n",
    "for dataset, value in w2v_results.items():\n",
    "    print(dataset)\n",
    "    for embedding_raw, cache_files in sorted(value.items(), key = lambda x: x[0]):\n",
    "        embedding = embedding_raw.split('/')[-1].rsplit('.', 2)[0]\n",
    "        if len(cache_files.keys()) != 2: continue\n",
    "        print('\\t{}'.format(embedding))\n",
    "        if embedding not in per_embedding_type:\n",
    "            per_embedding_type[embedding] = {}\n",
    "        per_embemdding_type[embedding][dataset] = []\n",
    "        for dataset_file, counts in sorted(cache_files.items(), key = lambda x: x[0]):\n",
    "            not_found_ratio = int(counts['counts']['not_found'] / counts['num_labels'] * 100)\n",
    "            if embedding == 'trained' and 'coo' in  dataset_file:\n",
    "                print('Yes', counts['counts']['not_found'], not_found_ratio, '%', counts['not_found_sample'])\n",
    "            is_gml = 'dataset_graph_gml' in dataset_file\n",
    "            per_embedding_type[embedding][dataset].append((is_gml, not_found_ratio))\n",
    "            print('\\t\\t{:4} missing  {:3>}%'.format('gml' if is_gml else 'co', not_found_ratio))\n",
    "        per_embedding_type[embedding][dataset] = per_embedding_type[embedding][dataset][0][1]  #sum(y for x, y in per_embedding_type[embedding][dataset]) / 2\n",
    "df = pd.DataFrame(per_embedding_type)\n",
    "df#[df.index == \"ng20\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import dataset_helper\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "currently = ['ling-spam', 'webkb', 'ng20', 'reuters-21578']\n",
    "\n",
    "for dataset in dataset_helper.get_all_available_dataset_names():\n",
    "    if dataset not in currently: continue\n",
    "    X, Y = dataset_helper.get_dataset(dataset)\n",
    "    unique_classes = set(Y)\n",
    "    fig, ax = plt.subplots(figsize = (12, min(14, len(unique_classes) / 3)))\n",
    "    print('{}\\n#Docs:\\t{}\\t# Classes:\\t{}'.format(dataset, len(X), len(unique_classes)))\n",
    "    dataset_helper.plot_dataset_class_distribution(X, Y, 'Class distribution: {}'.format(dataset), ax = ax)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "38px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
